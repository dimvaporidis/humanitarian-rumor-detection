{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from geotext import GeoText\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "import tweepy\n",
    "from tweepy import API\n",
    "import datetime\n",
    "import urllib\n",
    "import face_recognition\n",
    "from difflib import SequenceMatcher\n",
    "import gender_guesser.detector as gender\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "favourite_count = []\n",
    "\n",
    "tweet_age = []\n",
    "\n",
    "retweet_count = []\n",
    "\n",
    "profile_age = []\n",
    "\n",
    "user_description = []\n",
    "\n",
    "followers = []\n",
    "\n",
    "friends = []\n",
    "\n",
    "following = []\n",
    "\n",
    "geo_enabled = []\n",
    "\n",
    "extended_profile = []\n",
    "\n",
    "user_location = []\n",
    "\n",
    "name = []\n",
    "\n",
    "profile_image = []\n",
    "\n",
    "statuses_count = []\n",
    "\n",
    "user_time_zone = []\n",
    "\n",
    "verified = []\n",
    "\n",
    "is_translator_enabled = []\n",
    "\n",
    "listed_count = []\n",
    "\n",
    "user_id = []\n",
    "\n",
    "protected = [] \n",
    "\n",
    "screen_name = []\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "\n",
    "time_rate = time_now\n",
    "\n",
    "image_exists = []\n",
    "\n",
    "gender_binary = []\n",
    "\n",
    "name_male = []\n",
    "\n",
    "user_lang = []\n",
    "\n",
    "deleted_tweets = []\n",
    "\n",
    "deleted_ids = []\n",
    "\n",
    "notifications = []\n",
    "\n",
    "text=[]\n",
    "\n",
    "default_profile_picture = []\n",
    "\n",
    "requests = 0\n",
    "\n",
    "error_objects = []\n",
    "\n",
    "rumor = []\n",
    "\n",
    "event=[]\n",
    "\n",
    "text=[]\n",
    "\n",
    "rumor=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = Path('tweets_json')\n",
    "    \n",
    "file_list = [f for f in rootdir.resolve().glob('**/*') if f.is_file()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting only the Text of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n",
      "37000\n",
      "37100\n",
      "37200\n",
      "37300\n",
      "37400\n",
      "37500\n",
      "37600\n",
      "37700\n",
      "37800\n",
      "37900\n",
      "38000\n",
      "38100\n",
      "38200\n",
      "38300\n",
      "38400\n",
      "38500\n",
      "38600\n",
      "38700\n",
      "38800\n",
      "38900\n",
      "39000\n",
      "39100\n",
      "39200\n",
      "39300\n",
      "39400\n",
      "39500\n",
      "39600\n",
      "39700\n",
      "39800\n",
      "39900\n",
      "40000\n",
      "40100\n",
      "40200\n",
      "40300\n",
      "40400\n",
      "40500\n",
      "40600\n",
      "40700\n",
      "40800\n",
      "40900\n",
      "41000\n",
      "41100\n",
      "41200\n",
      "41300\n",
      "41400\n",
      "41500\n",
      "41600\n",
      "41700\n",
      "41800\n",
      "41900\n",
      "42000\n",
      "42100\n",
      "42200\n",
      "42300\n",
      "42400\n",
      "42500\n",
      "42600\n",
      "42700\n",
      "42800\n",
      "42900\n",
      "43000\n",
      "43100\n",
      "43200\n",
      "43300\n",
      "43400\n",
      "43500\n",
      "43600\n",
      "43700\n",
      "43800\n",
      "43900\n",
      "44000\n",
      "44100\n",
      "44200\n",
      "44300\n",
      "44400\n",
      "44500\n",
      "44600\n",
      "44700\n",
      "44800\n",
      "44900\n",
      "45000\n",
      "45100\n",
      "45200\n",
      "45300\n",
      "45400\n",
      "45500\n",
      "45600\n",
      "45700\n",
      "45800\n",
      "45900\n",
      "46000\n",
      "46100\n",
      "46200\n",
      "46300\n",
      "46400\n",
      "46500\n",
      "46600\n",
      "46700\n",
      "46800\n",
      "46900\n",
      "47000\n",
      "47100\n",
      "47200\n",
      "47300\n",
      "47400\n",
      "47500\n",
      "47600\n",
      "47700\n",
      "47800\n",
      "47900\n",
      "48000\n",
      "48100\n",
      "48200\n",
      "48300\n",
      "48400\n",
      "48500\n",
      "48600\n",
      "48700\n",
      "48800\n",
      "48900\n",
      "49000\n",
      "49100\n",
      "49200\n",
      "49300\n",
      "49400\n",
      "49500\n",
      "49600\n",
      "49700\n",
      "49800\n",
      "49900\n",
      "50000\n",
      "50100\n",
      "50200\n",
      "50300\n",
      "50400\n",
      "50500\n",
      "50600\n",
      "50700\n",
      "50800\n",
      "50900\n",
      "51000\n",
      "51100\n",
      "51200\n",
      "51300\n",
      "51400\n",
      "51500\n",
      "51600\n",
      "51700\n",
      "51800\n",
      "51900\n",
      "52000\n",
      "52100\n",
      "52200\n",
      "52300\n",
      "52400\n",
      "52500\n",
      "52600\n",
      "52700\n",
      "52800\n",
      "52900\n",
      "53000\n",
      "53100\n",
      "53200\n",
      "53300\n",
      "53400\n",
      "53500\n",
      "53600\n",
      "53700\n",
      "53800\n",
      "53900\n",
      "54000\n",
      "54100\n",
      "54200\n",
      "54300\n",
      "54400\n",
      "54500\n",
      "54600\n",
      "54700\n",
      "54800\n",
      "54900\n",
      "55000\n",
      "55100\n",
      "55200\n",
      "55300\n",
      "55400\n",
      "55500\n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n",
      "69500\n",
      "69600\n",
      "69700\n",
      "69800\n",
      "69900\n",
      "70000\n",
      "70100\n",
      "70200\n",
      "70300\n",
      "70400\n",
      "70500\n",
      "70600\n",
      "70700\n",
      "70800\n",
      "70900\n",
      "71000\n",
      "71100\n",
      "71200\n",
      "71300\n",
      "71400\n",
      "71500\n",
      "71600\n",
      "71700\n",
      "71800\n",
      "71900\n",
      "72000\n",
      "72100\n",
      "72200\n",
      "72300\n",
      "72400\n",
      "72500\n",
      "72600\n",
      "72700\n",
      "72800\n",
      "72900\n",
      "73000\n",
      "73100\n",
      "73200\n",
      "73300\n",
      "73400\n",
      "73500\n",
      "73600\n",
      "73700\n",
      "73800\n",
      "73900\n",
      "74000\n",
      "74100\n",
      "74200\n",
      "74300\n",
      "74400\n",
      "74500\n",
      "74600\n",
      "74700\n",
      "74800\n",
      "74900\n",
      "75000\n",
      "75100\n",
      "75200\n",
      "75300\n",
      "75400\n",
      "75500\n",
      "75600\n",
      "75700\n",
      "75800\n",
      "75900\n",
      "76000\n",
      "76100\n",
      "76200\n",
      "76300\n",
      "76400\n",
      "76500\n",
      "76600\n",
      "76700\n",
      "76800\n",
      "76900\n",
      "77000\n",
      "77100\n",
      "77200\n",
      "77300\n",
      "77400\n",
      "77500\n",
      "77600\n",
      "77700\n",
      "77800\n",
      "77900\n",
      "78000\n",
      "78100\n",
      "78200\n",
      "78300\n",
      "78400\n",
      "78500\n",
      "78600\n",
      "78700\n",
      "78800\n",
      "78900\n",
      "79000\n",
      "79100\n",
      "79200\n",
      "79300\n",
      "79400\n",
      "79500\n",
      "79600\n",
      "79700\n",
      "79800\n",
      "79900\n",
      "80000\n",
      "80100\n",
      "80200\n",
      "80300\n",
      "80400\n",
      "80500\n",
      "80600\n",
      "80700\n",
      "80800\n",
      "80900\n",
      "81000\n",
      "81100\n",
      "81200\n",
      "81300\n",
      "81400\n",
      "81500\n",
      "81600\n",
      "81700\n",
      "81800\n",
      "81900\n",
      "82000\n",
      "82100\n",
      "82200\n",
      "82300\n",
      "82400\n",
      "82500\n",
      "82600\n",
      "82700\n",
      "82800\n",
      "82900\n",
      "83000\n",
      "83100\n",
      "83200\n",
      "83300\n",
      "83400\n",
      "83500\n",
      "83600\n",
      "83700\n",
      "83800\n",
      "83900\n",
      "84000\n",
      "84100\n",
      "84200\n",
      "84300\n",
      "84400\n",
      "84500\n",
      "84600\n",
      "84700\n",
      "84800\n",
      "84900\n",
      "85000\n",
      "85100\n",
      "85200\n",
      "85300\n",
      "85400\n",
      "85500\n",
      "85600\n",
      "85700\n",
      "85800\n",
      "85900\n",
      "86000\n",
      "86100\n",
      "86200\n",
      "86300\n",
      "86400\n",
      "86500\n",
      "86600\n",
      "86700\n",
      "86800\n",
      "86900\n",
      "87000\n",
      "87100\n",
      "87200\n",
      "87300\n",
      "87400\n",
      "87500\n",
      "87600\n",
      "87700\n",
      "87800\n",
      "87900\n",
      "88000\n",
      "88100\n",
      "88200\n",
      "88300\n",
      "88400\n",
      "88500\n",
      "88600\n",
      "88700\n",
      "88800\n",
      "88900\n",
      "89000\n",
      "89100\n",
      "89200\n",
      "89300\n",
      "89400\n",
      "89500\n",
      "89600\n",
      "89700\n",
      "89800\n",
      "89900\n",
      "90000\n",
      "90100\n",
      "90200\n",
      "90300\n",
      "90400\n",
      "90500\n",
      "90600\n",
      "90700\n",
      "90800\n",
      "90900\n",
      "91000\n",
      "91100\n",
      "91200\n",
      "91300\n",
      "91400\n",
      "91500\n",
      "91600\n",
      "91700\n",
      "91800\n",
      "91900\n",
      "92000\n",
      "92100\n",
      "92200\n",
      "92300\n",
      "92400\n",
      "92500\n",
      "92600\n",
      "92700\n",
      "92800\n",
      "92900\n",
      "93000\n",
      "93100\n",
      "93200\n",
      "93300\n",
      "93400\n",
      "93500\n",
      "93600\n",
      "93700\n",
      "93800\n",
      "93900\n",
      "94000\n",
      "94100\n",
      "94200\n",
      "94300\n",
      "94400\n",
      "94500\n",
      "94600\n",
      "94700\n",
      "94800\n",
      "94900\n",
      "95000\n",
      "95100\n",
      "95200\n",
      "95300\n",
      "95400\n",
      "95500\n",
      "95600\n",
      "95700\n",
      "95800\n",
      "95900\n",
      "96000\n",
      "96100\n",
      "96200\n",
      "96300\n",
      "96400\n",
      "96500\n",
      "96600\n",
      "96700\n",
      "96800\n",
      "96900\n",
      "97000\n",
      "97100\n",
      "97200\n",
      "97300\n",
      "97400\n",
      "97500\n",
      "97600\n",
      "97700\n",
      "97800\n",
      "97900\n",
      "98000\n",
      "98100\n",
      "98200\n",
      "98300\n",
      "98400\n",
      "98500\n",
      "98600\n",
      "98700\n",
      "98800\n",
      "98900\n",
      "99000\n",
      "99100\n",
      "99200\n",
      "99300\n",
      "99400\n",
      "99500\n",
      "99600\n",
      "99700\n",
      "99800\n",
      "99900\n",
      "100000\n",
      "100100\n",
      "100200\n",
      "100300\n",
      "100400\n",
      "100500\n",
      "100600\n",
      "100700\n",
      "100800\n",
      "100900\n",
      "101000\n",
      "101100\n",
      "101200\n",
      "101300\n",
      "101400\n",
      "101500\n",
      "101600\n",
      "101700\n",
      "101800\n",
      "101900\n",
      "102000\n",
      "102100\n",
      "102200\n",
      "102300\n",
      "102400\n",
      "102500\n",
      "102600\n",
      "102700\n",
      "102800\n",
      "102900\n",
      "103000\n",
      "103100\n",
      "103200\n",
      "103300\n",
      "103400\n",
      "103500\n",
      "103600\n",
      "103700\n",
      "103800\n",
      "103900\n",
      "104000\n",
      "104100\n",
      "104200\n",
      "104300\n",
      "104400\n",
      "104500\n",
      "104600\n",
      "104700\n",
      "104800\n",
      "104900\n",
      "105000\n",
      "105100\n",
      "105200\n",
      "105300\n",
      "105400\n",
      "105500\n",
      "105600\n",
      "105700\n",
      "105800\n",
      "105900\n",
      "106000\n",
      "106100\n",
      "106200\n",
      "106300\n",
      "106400\n",
      "106500\n",
      "106600\n",
      "106700\n",
      "106800\n",
      "106900\n",
      "107000\n",
      "107100\n",
      "107200\n",
      "107300\n",
      "107400\n",
      "107500\n",
      "107600\n",
      "107700\n",
      "107800\n",
      "107900\n",
      "108000\n",
      "108100\n",
      "108200\n",
      "108300\n",
      "108400\n",
      "108500\n",
      "108600\n",
      "108700\n",
      "108800\n",
      "108900\n",
      "109000\n",
      "109100\n",
      "109200\n",
      "109300\n",
      "109400\n",
      "109500\n",
      "109600\n",
      "109700\n",
      "109800\n",
      "109900\n",
      "110000\n",
      "110100\n",
      "110200\n",
      "110300\n",
      "110400\n",
      "110500\n",
      "110600\n",
      "110700\n",
      "110800\n",
      "110900\n",
      "111000\n",
      "111100\n",
      "111200\n",
      "111300\n",
      "111400\n",
      "111500\n",
      "111600\n",
      "111700\n",
      "111800\n",
      "111900\n",
      "112000\n",
      "112100\n",
      "112200\n",
      "112300\n",
      "112400\n",
      "112500\n",
      "112600\n",
      "112700\n",
      "112800\n",
      "112900\n",
      "113000\n",
      "113100\n",
      "113200\n",
      "113300\n",
      "113400\n",
      "113500\n",
      "113600\n",
      "113700\n",
      "113800\n",
      "113900\n",
      "114000\n",
      "114100\n",
      "114200\n",
      "114300\n",
      "114400\n",
      "114500\n",
      "114600\n",
      "114700\n",
      "114800\n",
      "114900\n",
      "115000\n",
      "115100\n",
      "115200\n",
      "115300\n",
      "115400\n",
      "115500\n",
      "115600\n",
      "115700\n",
      "115800\n",
      "115900\n",
      "116000\n",
      "116100\n",
      "116200\n",
      "116300\n",
      "116400\n",
      "116500\n",
      "116600\n",
      "116700\n",
      "116800\n",
      "116900\n",
      "117000\n",
      "117100\n",
      "117200\n",
      "117300\n",
      "117400\n",
      "117500\n",
      "117600\n",
      "117700\n",
      "117800\n",
      "117900\n",
      "118000\n",
      "118100\n",
      "118200\n",
      "118300\n",
      "118400\n",
      "118500\n",
      "118600\n",
      "118700\n",
      "118800\n",
      "118900\n",
      "119000\n",
      "119100\n",
      "119200\n",
      "119300\n",
      "119400\n",
      "119500\n",
      "119600\n",
      "119700\n",
      "119800\n",
      "119900\n",
      "120000\n",
      "120100\n",
      "120200\n",
      "120300\n",
      "120400\n",
      "120500\n",
      "120600\n",
      "120700\n",
      "120800\n",
      "120900\n",
      "121000\n",
      "121100\n",
      "121200\n",
      "121300\n",
      "121400\n",
      "121500\n",
      "121600\n",
      "121700\n",
      "121800\n",
      "121900\n",
      "122000\n",
      "122100\n",
      "122200\n",
      "122300\n",
      "122400\n",
      "122500\n",
      "122600\n",
      "122700\n",
      "122800\n",
      "122900\n",
      "123000\n",
      "123100\n",
      "123200\n",
      "123300\n",
      "123400\n",
      "123500\n",
      "123600\n",
      "123700\n",
      "123800\n",
      "123900\n",
      "124000\n",
      "124100\n",
      "124200\n",
      "124300\n",
      "124400\n",
      "124500\n",
      "124600\n",
      "124700\n",
      "124800\n",
      "124900\n",
      "125000\n",
      "125100\n",
      "125200\n",
      "125300\n",
      "125400\n",
      "125500\n",
      "125600\n",
      "125700\n",
      "125800\n",
      "125900\n",
      "126000\n",
      "126100\n",
      "126200\n",
      "126300\n",
      "126400\n",
      "126500\n",
      "126600\n",
      "126700\n",
      "126800\n",
      "126900\n",
      "127000\n",
      "127100\n",
      "127200\n",
      "127300\n",
      "127400\n",
      "127500\n",
      "127600\n",
      "127700\n",
      "127800\n",
      "127900\n",
      "128000\n",
      "128100\n",
      "128200\n",
      "128300\n",
      "128400\n",
      "128500\n",
      "128600\n",
      "128700\n",
      "128800\n",
      "128900\n",
      "129000\n",
      "129100\n",
      "129200\n",
      "129300\n",
      "129400\n",
      "129500\n",
      "129600\n",
      "129700\n",
      "129800\n",
      "129900\n",
      "130000\n",
      "130100\n",
      "130200\n",
      "130300\n",
      "130400\n",
      "130500\n",
      "130600\n",
      "130700\n",
      "130800\n",
      "130900\n",
      "131000\n",
      "131100\n",
      "131200\n",
      "131300\n",
      "131400\n",
      "131500\n",
      "131600\n",
      "131700\n",
      "131800\n",
      "131900\n",
      "132000\n",
      "132100\n",
      "132200\n",
      "132300\n",
      "132400\n",
      "132500\n",
      "132600\n",
      "132700\n",
      "132800\n",
      "132900\n",
      "133000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133100\n",
      "133200\n",
      "133300\n",
      "133400\n",
      "133500\n",
      "133600\n",
      "133700\n",
      "133800\n",
      "133900\n",
      "134000\n",
      "134100\n",
      "134200\n",
      "134300\n",
      "134400\n",
      "134500\n",
      "134600\n",
      "134700\n",
      "134800\n",
      "134900\n",
      "135000\n",
      "135100\n",
      "135200\n",
      "135300\n",
      "135400\n",
      "135500\n",
      "135600\n",
      "135700\n",
      "135800\n",
      "135900\n",
      "136000\n",
      "136100\n",
      "136200\n",
      "136300\n",
      "136400\n",
      "136500\n",
      "136600\n",
      "136700\n",
      "136800\n",
      "136900\n",
      "137000\n",
      "137100\n",
      "137200\n",
      "137300\n",
      "137400\n",
      "137500\n",
      "137600\n",
      "137700\n",
      "137800\n",
      "137900\n",
      "138000\n",
      "138100\n",
      "138200\n",
      "138300\n",
      "138400\n",
      "138500\n",
      "138600\n",
      "138700\n",
      "138800\n",
      "138900\n",
      "139000\n",
      "139100\n",
      "139200\n",
      "139300\n",
      "139400\n",
      "139500\n",
      "139600\n",
      "139700\n",
      "139800\n",
      "139900\n",
      "140000\n",
      "140100\n",
      "140200\n",
      "140300\n",
      "140400\n",
      "140500\n",
      "140600\n",
      "140700\n",
      "140800\n",
      "140900\n"
     ]
    }
   ],
   "source": [
    "# initialize the lists\n",
    "text=[]\n",
    "deleted_ids=[]\n",
    "requests=0\n",
    "time_rate = datetime.datetime.now()\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        print(i)\n",
    "        \n",
    "    with open(str(file_list[i])) as f:\n",
    "        \n",
    "        obj = json.load(f)     \n",
    "    \n",
    "    try:\n",
    "    \n",
    "        text.append(obj['full_text'])\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        text.append('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_difference(x):\n",
    "    \n",
    "    a = x.split()\n",
    "    \n",
    "    if a[1] == 'Jan':\n",
    "        \n",
    "        a[1]=1\n",
    "        \n",
    "    if a[1] == 'Feb':\n",
    "        \n",
    "        a[1]=2\n",
    "        \n",
    "    if a[1] == 'Mar':\n",
    "        \n",
    "        a[1]=3\n",
    "        \n",
    "    if a[1] == 'Apr':\n",
    "        \n",
    "        a[1]=4\n",
    "        \n",
    "    if a[1] == 'May':\n",
    "        \n",
    "        a[1]=5\n",
    "        \n",
    "    if a[1] == 'Jun':\n",
    "        \n",
    "        a[1]=6\n",
    "        \n",
    "    if a[1] == 'Jul':\n",
    "        \n",
    "        a[1]=7\n",
    "        \n",
    "    if a[1] == 'Aug':\n",
    "        \n",
    "        a[1]=8\n",
    "        \n",
    "    if a[1] == 'Sep':\n",
    "        \n",
    "        a[1]=9\n",
    "        \n",
    "    if a[1] == 'Oct':\n",
    "        \n",
    "        a[1]=10\n",
    "        \n",
    "    if a[1] == 'Nov':\n",
    "        \n",
    "        a[1]=11\n",
    "        \n",
    "    if a[1] == 'Dec':\n",
    "        \n",
    "        a[1]=12\n",
    "    \n",
    "    time_now = datetime.datetime.now()\n",
    "    \n",
    "    my_date = datetime.datetime(int(a[5]), int(a[1]), int(a[2]), int(a[3].split(':')[0]), int(a[3].split(':')[1]), int(a[3].split(':')[2]))\n",
    "\n",
    "    time_difference = time_now-my_date # I count how much time has passed since then\n",
    "    \n",
    "    return time_difference.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        with open(\"counter_1.txt\", \"w\") as w:\n",
    "        \n",
    "            w.write(i +\"\\n\")\n",
    "        \n",
    "    with open(str(file_list[i])) as f:\n",
    "        \n",
    "        obj = json.load(f)\n",
    "        \n",
    "    if 'N_' in str(file_list[i]):\n",
    "\n",
    "        rumor.append(0.0)\n",
    "\n",
    "    else:\n",
    "\n",
    "        rumor.append(1.0)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        favourite_count.append(obj['favorite_count']) # I count how many users have favoured this tweet\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        favourite_count.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        tweet_age.append(time_difference(obj['created_at']))\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        tweet_age.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        retweet_count.append(obj['retweet_count']) # I count the number of re-tweets\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        retweet_count.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        profile_age.append(time_difference(obj['user']['created_at'])) # I store the time in days\n",
    "                \n",
    "    except:\n",
    "        \n",
    "        profile_age.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        description = obj['user']['description'] # I check if the user has a description for his/her profile or not\n",
    "    \n",
    "        if description == '' :\n",
    "        \n",
    "            user_description.append(0.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            user_description.append(1.0)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        user_description.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        followers.append(obj['user']['followers_count']) # I count the number of followers of the user\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        followers.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        following.append(obj['user']['friends_count'])  # I count the number of the account that the user is following\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        following.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        geo = obj['user']['geo_enabled']  # I check if the user has enabled the geo_location system of Twitter\n",
    "    \n",
    "        if geo is True:\n",
    "        \n",
    "            geo_enabled.append(1.0) \n",
    "        \n",
    "        else:\n",
    "        \n",
    "            geo_enabled.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        geo_enabled.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        extended = obj['user']['has_extended_profile'] # I check if the user has enabled an extended Twitter profile or not\n",
    "    \n",
    "        if extended is True:\n",
    "        \n",
    "            extended_profile.append(1.0) \n",
    "        \n",
    "        else:\n",
    "        \n",
    "            extended_profile.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        extended_profile.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        location = obj['user']['location']  # I check if the user has declared a location or not\n",
    "    \n",
    "        if location == 'NONE':\n",
    "        \n",
    "            user_location.append(0.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            user_location.append(1.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        user_location.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        statuses_count.append(obj['user']['statuses_count']) # I count the number of statuses that the user has published\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        statuses_count.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        user_notification = obj['user']['notifications']\n",
    "    \n",
    "        if user_notification is True:\n",
    "        \n",
    "            notifications.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            notifications.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        notifications.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        time_zone = obj['user']['time_zone'] # I check if the user has declared a timezone\n",
    "    \n",
    "        if time_zone == 'None':\n",
    "        \n",
    "            user_time_zone.append(0.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            user_time_zone.append(1.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        user_time_zone.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        verification = obj['user']['verified'] # I check if the user has verified his/her account or not\n",
    "    \n",
    "        if verification is True:\n",
    "        \n",
    "            verified.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            verified.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        verified.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        pic_default = obj['user']['default_profile_image'] # I check if the user has verified his/her account or not\n",
    "    \n",
    "        if pic_default is True:\n",
    "        \n",
    "            default_profile_picture.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            default_profile_picture.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        default_profile_picture.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        translation = obj['user']['is_translation_enabled']  # I check if the user has enabled the Twitter's translator\n",
    "    \n",
    "        if translation is True:\n",
    "        \n",
    "            is_translator_enabled.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            is_translator_enabled.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        is_translator_enabled.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        listed_count.append(obj['user']['listed_count'])  # I count the number of lists that the user has\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        listed_count.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        protection = obj['user']['protected']   # I check if the account of the user is protected or not\n",
    "    \n",
    "        if protection is True:\n",
    "        \n",
    "            protected.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            protected.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        protected.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        d = gender.Detector()\n",
    "    \n",
    "        name.append(obj['user']['name'])  # I extract the name of the user  \n",
    "    \n",
    "        sex = d.get_gender(str(name[i]).split()[0]) # I use the name of the user to define the user's gender\n",
    "    \n",
    "        if sex=='unknown':  # check if the name indicates a gender or not\n",
    "        \n",
    "            gender_binary.append(0.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            gender_binary.append(1.0)\n",
    "        \n",
    "        if sex is 'male' or 'mostly_male': # check if the user is male or not\n",
    "        \n",
    "            name_male.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            name_male.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        gender_binary.append(0.0)\n",
    "        \n",
    "        name_male.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        image=urllib.request.urlretrieve(obj['user']['profile_image_url'],'1.jpg')   # I download the profile picture of the user \n",
    "    \n",
    "        image = face_recognition.load_image_file(\"1.jpg\")  # I turn the picture into an object of the Face Recognition Library\n",
    "\n",
    "        face_locations=face_recognition.face_locations(image) # I use the face recognition library to locate if there are any clear faces in the picture\n",
    "    \n",
    "        if face_locations==[]:\n",
    "        \n",
    "            image_exists.append(0.0)\n",
    "    \n",
    "        else:\n",
    "        \n",
    "            image_exists.append(1.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        image_exists.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "    \n",
    "    language=obj['user']['lang'] # extract the language of the user    \n",
    "    \n",
    "    user_lang.append(language)\n",
    "\n",
    "    screen_name.append(obj['user']['screen_name'])  # I extract the screen name of the user\n",
    "    \n",
    "    text.append(obj['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_following_ratio=[]\n",
    "\n",
    "statuses_per_day=[]\n",
    "\n",
    "lists_per_day=[]\n",
    "\n",
    "following_per_day=[]\n",
    "\n",
    "followers_per_day=[]\n",
    "\n",
    "retweet_per_second=[]\n",
    "\n",
    "favourite_per_second = []\n",
    "\n",
    "for i in range(len(followers)):\n",
    "    \n",
    "    if tweet_age[i]==0:\n",
    "        \n",
    "        retweet_per_second.append(retweet_count[i])\n",
    "        \n",
    "        favourite_per_second.append(favourite_count[i])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        retweet_per_second.append(retweet_count[i]/tweet_age[i])\n",
    "        \n",
    "        favourite_per_second.append(favourite_count[i]/tweet_age[i])\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if following[i] == 0.0:\n",
    "        \n",
    "            following[i] = 1.0\n",
    "    \n",
    "        a=(followers[i] / following[i])\n",
    "    \n",
    "        followers_following_ratio.append(a)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        followers_following_ratio.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    if profile_age[i]==0:\n",
    "        \n",
    "        statuses_per_day.append(statuses_count[i])\n",
    "        \n",
    "        lists_per_day.append(listed_count[i])\n",
    "        \n",
    "        followers_per_day.append(followers[i])\n",
    "        \n",
    "        following_per_day.append(following[i])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        statuses_per_day.append(statuses_count[i] / profile_age[i])\n",
    "        \n",
    "        lists_per_day.append( listed_count[i] / profile_age[i] )\n",
    "        \n",
    "        followers_per_day.append(followers[i]/profile_age[i])\n",
    "        \n",
    "        following_per_day.append(following[i]/profile_age[i])\n",
    "        \n",
    "retweet_per_follower = [ retweet_count[i] / following[i] for i in range(len(followers))]\n",
    "\n",
    "favourite_per_follower = [ favourite_count[i] / following[i] for i in range(len(following))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.Series(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters=df2.str.len()             # I count the number of characters within a tweet.\n",
    "\n",
    "exclamation_mark = df2.str.count('!')  # I count the number of exclamation marks.\n",
    "\n",
    "commas = df2.str.count(',')           # I count the number of commas.\n",
    "\n",
    "periods = df2.str.count('.')        # I count the number of periods.\n",
    "\n",
    "question_mark = df2.str.count('\\?')    # I count the number of question marks.\n",
    "\n",
    "a = obj['entities']\n",
    "\n",
    "hashtag = df2.str.count('#')          # I count the number of hashtags.\n",
    "\n",
    "url = df2.str.count('http')           # I count the number of urls.\n",
    "\n",
    "mentions = df2.str.count('@')          # I count the number of mentions.\n",
    "\n",
    "words = df2.str.count(' ')+1          # I count the number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_marks=[]\n",
    "\n",
    "for i in range(len(exclamation_mark)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        if exclamation_mark[i]>0 and question_mark[i]>0 : # check if the question marks and the exclamation marks are above zero\n",
    "        \n",
    "            multiple_marks.append(1.0) # in case there are write 1\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            multiple_marks.append(0.0) # in case there are not write 0\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        multiple_marks.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictation_rate=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        with open(\"counter_2.txt\", \"w\") as w:\n",
    "        \n",
    "            w.write(i +\"\\n\")\n",
    "        \n",
    "    \n",
    "    try:\n",
    "    \n",
    "        dict_a=str(df2[i])        # define the tweet as a string variable\n",
    "        \n",
    "        dict_b=TextBlob(str((df2)[i]))  # turn the tweet into a textblob object\n",
    "    \n",
    "        dict_b = dict_b.correct()   # correct the dictation of the words\n",
    "        \n",
    "        dictation=SequenceMatcher(None, dict_a, dict_b).ratio()   # compare the matching of the two strings\n",
    "    \n",
    "        dictation_rate.append(dictation)  # append the matching to the dictation_rate list\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        dictation_rate.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = []\n",
    "\n",
    "with open(\"data/positive-words.txt\") as file:\n",
    "    \n",
    "    for line in file: \n",
    "        \n",
    "        line = line.strip() \n",
    "        \n",
    "        positive.append(line) # create a list with the positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = []\n",
    "\n",
    "with open(\"data/negative-words.txt\") as file:\n",
    "    \n",
    "    for line in file: \n",
    "        \n",
    "        line = line.strip() \n",
    "        \n",
    "        negative.append(line) # create a list with the negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        test=(str(df2[i]))\n",
    "    \n",
    "        positives = [char for char in test if char in positive] # I create a list of the matching words\n",
    "    \n",
    "        positive_words.append(len(positives)) # I append the length of the list created\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        positive_words.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        test=(str(df2[i]))\n",
    "    \n",
    "        negatives = [char for char in test if char in negative]   # I create a list of the matching words\n",
    "    \n",
    "        negative_words.append(len(negatives))   # I append the length of the list created\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        negative_words.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        test=TextBlob(str(df2[i])) # I turn the text of the tweet into a textblob object\n",
    "    \n",
    "        subjectivity.append(test.sentiment.subjectivity) # I append the subjectivity score to the subjectivity list\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        subjectivity.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        test=TextBlob(str(df2[i])) # I turn the text of the tweet into a textblob object\n",
    "    \n",
    "        polarity.append(test.sentiment.polarity) # I append the polarity score to the polarity list\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        polarity.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_letters=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        a=(str(df2[i])).split() # I break the tweet string into words\n",
    " \n",
    "        count = 0.0\n",
    "\n",
    "        for word in a:  \n",
    "        \n",
    "            for letter in word:  # With a double loop I check each letter of the string\n",
    "            \n",
    "                if letter.isupper():  # if a letter is uppercase\n",
    "            \n",
    "                    count = count + 1.0\n",
    "            \n",
    "        uppercase_letters.append(count)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        uppercase_letters.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "places=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        a=GeoText(str(df2[i])) # I turn the string of the tweet into a Geotext object\n",
    "    \n",
    "        a=a.cities # I create a dictionary with the cities/places that are mentioned in the text\n",
    "    \n",
    "        places.append(len(a)) # I append the length of the dictionary to the places list\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        places.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pronoun=[]\n",
    "\n",
    "first = ['i','me','myself','mine','we','us','ours','ourselves'] # a list of the first person pronouns\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        a = str(df2[i]).split() # I break the tweet into words\n",
    "    \n",
    "        for i in range(len(a)):\n",
    "        \n",
    "            if a[i].lower() in first: #if a word is a first person pronoun\n",
    "            \n",
    "                count = count + 1.0\n",
    "            \n",
    "            first_pronoun.append(count)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        first_pronoun.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pronoun=[]\n",
    "\n",
    "second = ['you','yours','yourself','yourselves']\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        a = str(df2[i]).split(' ')\n",
    "    \n",
    "        for i in range(len(a)):\n",
    "        \n",
    "            if a[i].lower() in second:\n",
    "            \n",
    "                count = count + 1.0\n",
    "            \n",
    "            second_pronoun.append(count)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        second_pronoun.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_pronoun=[]\n",
    "\n",
    "third = ['he','she','it','him','her','his','hers','himself','herself','itself','they','them','theirs','themselves']\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        a = str(df2[i]).split(' ')\n",
    "    \n",
    "        for i in range(len(a)):\n",
    "        \n",
    "            if a[i].lower() in third:\n",
    "            \n",
    "                count = count + 1.0\n",
    "            \n",
    "            third_pronoun.append(count)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        third_pronoun.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "witness_claim=[]\n",
    "\n",
    "witness_words=['see','saw','seen', 'attend', 'attended', 'notice', 'noticed', 'watch', 'watched',\n",
    "              'bystander', 'eyewitness', 'observer', 'recognize', 'recognise', 'recognized', 'recognised',\n",
    "              'witness', 'witnessed', 'follow', 'followed', 'observe', 'observed'] # words that indicate that the author of the tweet is/was a witness of the event\n",
    "\n",
    "for i in range(len(df2)):  # the process is the same as before with me counting the matching words of the tweet to a list of words\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        a=str(df2[i]).split(' ')\n",
    "    \n",
    "        for i in range(len(a)):     \n",
    "        \n",
    "            if a[i].lower() in witness_words:\n",
    "            \n",
    "                    count = count + 1.0\n",
    "            \n",
    "            witness_claim.append(count)  \n",
    "            \n",
    "    except:\n",
    "        \n",
    "        witness_claim.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_match=[]\n",
    "\n",
    "text_lang=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        with open(\"counter_3.txt\", \"w\") as w:\n",
    "        \n",
    "            w.write(i +\"\\n\")\n",
    "        \n",
    "    \n",
    "    try:\n",
    "    \n",
    "        a = TextBlob(str(df2[i]))\n",
    "    \n",
    "        text_lang.append(a.detect_language())\n",
    "\n",
    "        for i in range(len(user_lang)): \n",
    "    \n",
    "            if user_lang[i] == text_lang[i]: # check if the language of the text and the user match\n",
    "        \n",
    "                lang_match.append(1.0)\n",
    "        \n",
    "            else:\n",
    "        \n",
    "                lang_match.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        lang_match.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_shaper=[]\n",
    "\n",
    "for i in range(len(name)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        b=str(screen_name[i]).lower()\n",
    "        \n",
    "        opinion=['news','breaking','news','report','report','daily','times', 'feed', 'radar', 'net']\n",
    "            \n",
    "        for i in range(len(opinion)):\n",
    "            \n",
    "            if opinion[i] in b:\n",
    "        \n",
    "                count = count +1.0\n",
    "    \n",
    "        if count>0:\n",
    "        \n",
    "            opinion_shaper.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            opinion_shaper.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        opinion_shaper.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacontent_features = pd.DataFrame(list(zip(favourite_count, tweet_age, retweet_count, mention, \n",
    "                                         retweet_per_second, favourite_per_second,\n",
    "                                        retweet_per_follower, favourite_per_follower)),\n",
    "                            columns = ['favourite_count', 'tweet_age', 'retweet_count', 'mentions', 'retweet_per_second', \n",
    "                                       'favourite_per_second','retweet_per_follower', 'favourite_per_follower'])\n",
    "\n",
    "user_features = pd.DataFrame(list(zip(profile_age, user_description, geo_enabled, opinion_shaper,extended_profile,\n",
    "                                      user_location, statuses_count, user_time_zone, verified, is_translator_enabled,\n",
    "                                      listed_count, protected, notifications, default_profile_picture, image_exists, \n",
    "                                      gender_binary, name_male, statuses_per_day,lists_per_day, followers, \n",
    "                                      following, followers_per_day, following_per_day, followers_following_ratio)),\n",
    "                             columns = ['profile_age', 'profile_description', 'geolocation', 'opinion_shaper',\n",
    "                                        'extended_profile','user_location', 'statuses_count', 'user_timezone', \n",
    "                                        'verified_account','text_translator', 'user_lists', 'account_protection', \n",
    "                                        'notifications','default_profile_picture', 'profile_picture', 'gender', \n",
    "                                        'male', 'statuses_per_day', 'lists_per_day','followers', \n",
    "                                        'following', 'followers_per_day', 'following_per_day', 'followers_following_ratio'])\n",
    "\n",
    "linguistic_features = pd.DataFrame(list(zip(characters, exclamation_mark, question_mark, hashtag, url, words,\n",
    "                                      commas, periods, multiple_marks,lang_match, dictation_rate, subjectivity, polarity, \n",
    "                                      positive_words, negative_words, uppercase_letters, places, first_pronoun, \n",
    "                                      second_pronoun, third_pronoun, witness_claim)),\n",
    "                             columns = ['characters', 'exclamation_marks', 'question_marks', 'hashtags', 'urls',\n",
    "                                        'words', 'commas', 'periods', 'multiple_marks','lang_match', \n",
    "                                        'dictation_rate', 'subjectivity', 'polarity', 'positive_words', 'negative_words',\n",
    "                                       'uppercase_letters', 'places', 'first_person', 'second_person', 'third_person', \n",
    "                                       'witness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = metacontent_features.values\n",
    "\n",
    "y = user_features.values\n",
    "\n",
    "z = linguistic_features.values\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "y_scaled = min_max_scaler.fit_transform(y)\n",
    "\n",
    "z_scaled = min_max_scaler.fit_transform(z)\n",
    "\n",
    "metacontent_feaures = pd.DataFrame(x_scaled, \n",
    "                               columns = ['favourite_count', 'tweet_age', 'retweet_count',\n",
    "                                      'mentions', 'retweet_per_second', 'favoutire_per_second',\n",
    "                                      'retweet_per_follower', 'favourite_per_follower'])\n",
    "\n",
    "user_features = pd.DataFrame(list(zip(profile_age, user_description, geo_enabled, opinion_shaper,extended_profile,\n",
    "                                      user_location, statuses_count, user_time_zone, verified, is_translator_enabled,\n",
    "                                      listed_count, protected, notifications, default_profile_picture, image_exists, \n",
    "                                      gender_binary, name_male, statuses_per_day,lists_per_day, followers, \n",
    "                                      following, followers_per_day, following_per_day, followers_following_ratio)),\n",
    "                             columns = ['profile_age', 'profile_description', 'geolocation', 'opinion_shaper',\n",
    "                                        'extended_profile','user_location', 'statuses_count', 'user_timezone', \n",
    "                                        'verified_account','text_translator', 'user_lists', 'account_protection', \n",
    "                                        'notifications','default_profile_picture', 'profile_picture', 'gender', \n",
    "                                        'male', 'statuses_per_day', 'lists_per_day','followers', \n",
    "                                        'following', 'followers_per_day', 'following_per_day', 'followers_following_ratio'])\n",
    "\n",
    "linguistic_features = pd.DataFrame(list(zip(characters, exclamation_mark, question_mark, hashtag, url, words,\n",
    "                                      commas, periods, multiple_marks,lang_match, dictation_rate, subjectivity, polarity, \n",
    "                                      positive_words, negative_words, uppercase_letters, places, first_pronoun, \n",
    "                                      second_pronoun, third_pronoun, witness_claim)),\n",
    "                             columns = ['characters', 'exclamation_marks', 'question_marks', 'hashtags', 'urls',\n",
    "                                        'words', 'commas', 'periods', 'multiple_marks','lang_match', \n",
    "                                        'dictation_rate', 'subjectivity', 'polarity', 'positive_words', 'negative_words',\n",
    "                                       'uppercase_letters', 'places', 'first_person', 'second_person', 'third_person', \n",
    "                                       'witness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([metacontent_feaures ,user_features, linguistic_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(features, columns = ['favourite_count', 'tweet_age', 'retweet_count','mentions', 'retweet_per_second', \n",
    "                                'favoutire_per_second','retweet_per_follower', 'favourite_per_follower',\n",
    "                               'profile_age', 'profile_description', 'geolocation', 'opinion_shaper',\n",
    "                                        'extended_profile','user_location', 'statuses_count', 'user_timezone', \n",
    "                                        'verified_account','text_translator', 'user_lists', 'account_protection', \n",
    "                                        'notifications','default_profile_picture', 'profile_picture', 'gender', \n",
    "                                        'male', 'statuses_per_day', 'lists_per_day','followers', \n",
    "                                        'following', 'followers_per_day', 'following_per_day', 'followers_following_ratio',\n",
    "                               'characters', 'exclamation_marks', 'question_marks', 'hashtags', 'urls',\n",
    "                                        'words', 'commas', 'periods', 'multiple_marks','lang_match', \n",
    "                                        'dictation_rate', 'subjectivity', 'polarity', 'positive_words', 'negative_words',\n",
    "                                       'uppercase_letters', 'places', 'first_person', 'second_person', 'third_person', \n",
    "                                       'witness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('generic_extracted.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
