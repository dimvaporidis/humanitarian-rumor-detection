{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from geotext import GeoText\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "import tweepy\n",
    "from tweepy import API\n",
    "import datetime\n",
    "import urllib\n",
    "import face_recognition\n",
    "from difflib import SequenceMatcher\n",
    "import gender_guesser.detector as gender\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "favourite_count = []\n",
    "\n",
    "tweet_age = []\n",
    "\n",
    "retweet_count = []\n",
    "\n",
    "profile_age = []\n",
    "\n",
    "user_description = []\n",
    "\n",
    "followers = []\n",
    "\n",
    "friends = []\n",
    "\n",
    "following = []\n",
    "\n",
    "geo_enabled = []\n",
    "\n",
    "extended_profile = []\n",
    "\n",
    "user_location = []\n",
    "\n",
    "name = []\n",
    "\n",
    "profile_image = []\n",
    "\n",
    "statuses_count = []\n",
    "\n",
    "user_time_zone = []\n",
    "\n",
    "verified = []\n",
    "\n",
    "is_translator_enabled = []\n",
    "\n",
    "listed_count = []\n",
    "\n",
    "user_id = []\n",
    "\n",
    "protected = [] \n",
    "\n",
    "screen_name = []\n",
    "\n",
    "time_now = datetime.datetime.now()\n",
    "\n",
    "time_rate = time_now\n",
    "\n",
    "image_exists = []\n",
    "\n",
    "gender_binary = []\n",
    "\n",
    "name_male = []\n",
    "\n",
    "user_lang = []\n",
    "\n",
    "deleted_tweets = []\n",
    "\n",
    "deleted_ids = []\n",
    "\n",
    "notifications = []\n",
    "\n",
    "text=[]\n",
    "\n",
    "default_profile_picture = []\n",
    "\n",
    "requests = 0\n",
    "\n",
    "error_objects = []\n",
    "\n",
    "rumor = []\n",
    "\n",
    "event=[]\n",
    "\n",
    "text=[]\n",
    "\n",
    "rumor=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = Path('pheme-rnr-dataset')\n",
    "    \n",
    "file_list_all = [f for f in rootdir.resolve().glob('**/*') if f.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=[]\n",
    "\n",
    "for i in range(len(file_list_all)):\n",
    "    \n",
    "    if 'source-tweet' in str(file_list_all[i]):\n",
    "        \n",
    "        file_list.append(file_list_all[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting only the Text of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the lists\n",
    "text=[]\n",
    "deleted_ids=[]\n",
    "requests=0\n",
    "time_rate = datetime.datetime.now()\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        print(i)\n",
    "        \n",
    "    with open(str(file_list[i])) as f:\n",
    "        \n",
    "        obj = json.load(f)     \n",
    "    \n",
    "    try:\n",
    "    \n",
    "        text.append(obj['full_text'])\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        text.append('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testing_text.txt\", \"w\") as f:\n",
    "    for t in text:\n",
    "        f.write(str(t) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_difference(x):\n",
    "    \n",
    "    a = x.split()\n",
    "    \n",
    "    if a[1] == 'Jan':\n",
    "        \n",
    "        a[1]=1\n",
    "        \n",
    "    if a[1] == 'Feb':\n",
    "        \n",
    "        a[1]=2\n",
    "        \n",
    "    if a[1] == 'Mar':\n",
    "        \n",
    "        a[1]=3\n",
    "        \n",
    "    if a[1] == 'Apr':\n",
    "        \n",
    "        a[1]=4\n",
    "        \n",
    "    if a[1] == 'May':\n",
    "        \n",
    "        a[1]=5\n",
    "        \n",
    "    if a[1] == 'Jun':\n",
    "        \n",
    "        a[1]=6\n",
    "        \n",
    "    if a[1] == 'Jul':\n",
    "        \n",
    "        a[1]=7\n",
    "        \n",
    "    if a[1] == 'Aug':\n",
    "        \n",
    "        a[1]=8\n",
    "        \n",
    "    if a[1] == 'Sep':\n",
    "        \n",
    "        a[1]=9\n",
    "        \n",
    "    if a[1] == 'Oct':\n",
    "        \n",
    "        a[1]=10\n",
    "        \n",
    "    if a[1] == 'Nov':\n",
    "        \n",
    "        a[1]=11\n",
    "        \n",
    "    if a[1] == 'Dec':\n",
    "        \n",
    "        a[1]=12\n",
    "    \n",
    "    time_now = datetime.datetime.now()\n",
    "    \n",
    "    my_date = datetime.datetime(int(a[5]), int(a[1]), int(a[2]), int(a[3].split(':')[0]), int(a[3].split(':')[1]), \n",
    "                                int(a[3].split(':')[2]))\n",
    "\n",
    "    time_difference = time_now-my_date # I count how much time has passed since then\n",
    "    \n",
    "    return time_difference.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_list)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        with open(\"counter_1.txt\", \"w\") as w:\n",
    "        \n",
    "            w.write(str(i))\n",
    "        \n",
    "    with open(str(file_list[i])) as f:\n",
    "        \n",
    "        obj = json.load(f)\n",
    "        \n",
    "    if 'non' in str(file_list[i]):\n",
    "\n",
    "        rumor.append(0.0)\n",
    "\n",
    "    else:\n",
    "\n",
    "        rumor.append(1.0)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        favourite_count.append(obj['favorite_count']) # I count how many users have favoured this tweet\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        favourite_count.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        tweet_age.append(time_difference(obj['created_at']))\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        tweet_age.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        retweet_count.append(obj['retweet_count']) # I count the number of re-tweets\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        retweet_count.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        profile_age.append(time_difference(obj['user']['created_at'])) # I store the time in days\n",
    "                \n",
    "    except:\n",
    "        \n",
    "        profile_age.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        description = obj['user']['description'] # I check if the user has a description for his/her profile or not\n",
    "    \n",
    "        if description == '' :\n",
    "        \n",
    "            user_description.append(0.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            user_description.append(1.0)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        user_description.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        followers.append(obj['user']['followers_count']) # I count the number of followers of the user\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        followers.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        following.append(obj['user']['friends_count'])  # I count the number of the account that the user is following\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        following.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        geo = obj['user']['geo_enabled']  # I check if the user has enabled the geo_location system of Twitter\n",
    "    \n",
    "        if geo is True:\n",
    "        \n",
    "            geo_enabled.append(1.0) \n",
    "        \n",
    "        else:\n",
    "        \n",
    "            geo_enabled.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        geo_enabled.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        extended = obj['user']['has_extended_profile'] # I check if the user has enabled an extended Twitter \n",
    "                                                        # profile or not\n",
    "    \n",
    "        if extended is True:\n",
    "        \n",
    "            extended_profile.append(1.0) \n",
    "        \n",
    "        else:\n",
    "        \n",
    "            extended_profile.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        extended_profile.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        location = obj['user']['location']  # I check if the user has declared a location or not\n",
    "    \n",
    "        if location == 'NONE':\n",
    "        \n",
    "            user_location.append(0.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            user_location.append(1.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        user_location.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        statuses_count.append(obj['user']['statuses_count']) # I count the number of statuses that \n",
    "                                                                # the user has published\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        statuses_count.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        user_notification = obj['user']['notifications']\n",
    "    \n",
    "        if user_notification is True:\n",
    "        \n",
    "            notifications.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            notifications.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        notifications.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        time_zone = obj['user']['time_zone'] # I check if the user has declared a timezone\n",
    "    \n",
    "        if time_zone == 'None':\n",
    "        \n",
    "            user_time_zone.append(0.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            user_time_zone.append(1.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        user_time_zone.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        verification = obj['user']['verified'] # I check if the user has verified his/her account or not\n",
    "    \n",
    "        if verification is True:\n",
    "        \n",
    "            verified.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            verified.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        verified.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        pic_default = obj['user']['default_profile_image'] # I check if the user has verified his/her account or not\n",
    "    \n",
    "        if pic_default is True:\n",
    "        \n",
    "            default_profile_picture.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            default_profile_picture.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        default_profile_picture.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        translation = obj['user']['is_translation_enabled']  # I check if the user has enabled the Twitter's translator\n",
    "    \n",
    "        if translation is True:\n",
    "        \n",
    "            is_translator_enabled.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            is_translator_enabled.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        is_translator_enabled.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        listed_count.append(obj['user']['listed_count'])  # I count the number of lists that the user has\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        listed_count.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "    \n",
    "        protection = obj['user']['protected']   # I check if the account of the user is protected or not\n",
    "    \n",
    "        if protection is True:\n",
    "        \n",
    "            protected.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            protected.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        protected.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        d = gender.Detector()\n",
    "    \n",
    "        name.append(obj['user']['name'])  # I extract the name of the user  \n",
    "    \n",
    "        sex = d.get_gender(str(name[i]).split()[0]) # I use the name of the user to define the user's gender\n",
    "    \n",
    "        if sex=='unknown':  # check if the name indicates a gender or not\n",
    "        \n",
    "            gender_binary.append(0.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            gender_binary.append(1.0)\n",
    "        \n",
    "        if sex is 'male' or 'mostly_male': # check if the user is male or not\n",
    "        \n",
    "            name_male.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            name_male.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        gender_binary.append(0.0)\n",
    "        \n",
    "        name_male.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        image=urllib.request.urlretrieve(obj['user']['profile_image_url'],'1.jpg')   # I download the profile \n",
    "                                                                                        # picture of the user \n",
    "    \n",
    "        image = face_recognition.load_image_file(\"1.jpg\")  # I turn the picture into an object of the Face \n",
    "                                                            # Recognition Library\n",
    "\n",
    "        face_locations=face_recognition.face_locations(image) # I use the face recognition library to locate if \n",
    "                                                                #there are any clear faces in the picture\n",
    "    \n",
    "        if face_locations==[]:\n",
    "        \n",
    "            image_exists.append(0.0)\n",
    "    \n",
    "        else:\n",
    "        \n",
    "            image_exists.append(1.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        image_exists.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "    \n",
    "    language=obj['user']['lang'] # extract the language of the user    \n",
    "    \n",
    "    user_lang.append(language)\n",
    "\n",
    "    screen_name.append(obj['user']['screen_name'])  # I extract the screen name of the user\n",
    "    \n",
    "    text.append(obj['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_following_ratio=[]\n",
    "\n",
    "statuses_per_day=[]\n",
    "\n",
    "lists_per_day=[]\n",
    "\n",
    "following_per_day=[]\n",
    "\n",
    "followers_per_day=[]\n",
    "\n",
    "retweet_per_second=[]\n",
    "\n",
    "favourite_per_second = []\n",
    "\n",
    "for i in range(len(followers)):\n",
    "    \n",
    "    if tweet_age[i]==0:\n",
    "        \n",
    "        retweet_per_second.append(retweet_count[i])\n",
    "        \n",
    "        favourite_per_second.append(favourite_count[i])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        retweet_per_second.append(retweet_count[i]/tweet_age[i])\n",
    "        \n",
    "        favourite_per_second.append(favourite_count[i]/tweet_age[i])\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if following[i] == 0.0:\n",
    "        \n",
    "            following[i] = 1.0\n",
    "    \n",
    "        a=(followers[i] / following[i])\n",
    "    \n",
    "        followers_following_ratio.append(a)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        followers_following_ratio.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)\n",
    "        \n",
    "    if profile_age[i]==0:\n",
    "        \n",
    "        statuses_per_day.append(statuses_count[i])\n",
    "        \n",
    "        lists_per_day.append(listed_count[i])\n",
    "        \n",
    "        followers_per_day.append(followers[i])\n",
    "        \n",
    "        following_per_day.append(following[i])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        statuses_per_day.append(statuses_count[i] / profile_age[i])\n",
    "        \n",
    "        lists_per_day.append( listed_count[i] / profile_age[i] )\n",
    "        \n",
    "        followers_per_day.append(followers[i]/profile_age[i])\n",
    "        \n",
    "        following_per_day.append(following[i]/profile_age[i])\n",
    "        \n",
    "retweet_per_follower = [ retweet_count[i] / following[i] for i in range(len(followers))]\n",
    "\n",
    "favourite_per_follower = [ favourite_count[i] / following[i] for i in range(len(following))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.Series(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters=df2.str.len()             # I count the number of characters within a tweet.\n",
    "\n",
    "exclamation_mark = df2.str.count('!')  # I count the number of exclamation marks.\n",
    "\n",
    "commas = df2.str.count(',')           # I count the number of commas.\n",
    "\n",
    "periods = df2.str.count('.')        # I count the number of periods.\n",
    "\n",
    "question_mark = df2.str.count('\\?')    # I count the number of question marks.\n",
    "\n",
    "a = obj['entities']\n",
    "\n",
    "hashtag = df2.str.count('#')          # I count the number of hashtags.\n",
    "\n",
    "url = df2.str.count('http')           # I count the number of urls.\n",
    "\n",
    "mentions = df2.str.count('@')          # I count the number of mentions.\n",
    "\n",
    "words = df2.str.count(' ')+1          # I count the number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_marks=[]\n",
    "\n",
    "for i in range(len(exclamation_mark)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        if exclamation_mark[i]>0 and question_mark[i]>0 : # check if the question marks and the exclamation\n",
    "                                                           # marks are above zero\n",
    "        \n",
    "            multiple_marks.append(1.0) # in case there are write 1\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            multiple_marks.append(0.0) # in case there are not write 0\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        multiple_marks.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictation_rate=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        \n",
    "        print(i)\n",
    "        \n",
    "        #with open(\"counter_2.txt\", \"w\") as w:\n",
    "        \n",
    "         #   w.write(i +\"\\n\")\n",
    "        \n",
    "    \n",
    "    try:\n",
    "    \n",
    "        dict_a=str(df2[i])        # define the tweet as a string variable\n",
    "        \n",
    "        dict_b=TextBlob(str((df2)[i]))  # turn the tweet into a textblob object\n",
    "    \n",
    "        dict_b = dict_b.correct()   # correct the dictation of the words\n",
    "        \n",
    "        dictation=SequenceMatcher(None, dict_a, dict_b).ratio()   # compare the matching of the two strings\n",
    "    \n",
    "        dictation_rate.append(dictation)  # append the matching to the dictation_rate list\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        dictation_rate.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = []\n",
    "\n",
    "with open(\"positive-words.txt\") as file:\n",
    "    \n",
    "    for line in file: \n",
    "        \n",
    "        line = line.strip() \n",
    "        \n",
    "        positive.append(line) # create a list with the positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = []\n",
    "\n",
    "with open(\"negative-words.txt\") as file:\n",
    "    \n",
    "    for line in file: \n",
    "        \n",
    "        line = line.strip() \n",
    "        \n",
    "        negative.append(line) # create a list with the negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        test=(str(df2[i]))\n",
    "    \n",
    "        positives = [char for char in test if char in positive] # I create a list of the matching words\n",
    "    \n",
    "        positive_words.append(len(positives)) # I append the length of the list created\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        positive_words.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        test=(str(df2[i]))\n",
    "    \n",
    "        negatives = [char for char in test if char in negative]   # I create a list of the matching words\n",
    "    \n",
    "        negative_words.append(len(negatives))   # I append the length of the list created\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        negative_words.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        test=TextBlob(str(df2[i])) # I turn the text of the tweet into a textblob object\n",
    "    \n",
    "        subjectivity.append(test.sentiment.subjectivity) # I append the subjectivity score to the subjectivity list\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        subjectivity.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        test=TextBlob(str(df2[i])) # I turn the text of the tweet into a textblob object\n",
    "    \n",
    "        polarity.append(test.sentiment.polarity) # I append the polarity score to the polarity list\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        polarity.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_letters=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        a=(str(df2[i])).split() # I break the tweet string into words\n",
    " \n",
    "        count = 0.0\n",
    "\n",
    "        for word in a:  \n",
    "        \n",
    "            for letter in word:  # With a double loop I check each letter of the string\n",
    "            \n",
    "                if letter.isupper():  # if a letter is uppercase\n",
    "            \n",
    "                    count = count + 1.0\n",
    "            \n",
    "        uppercase_letters.append(count)\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        uppercase_letters.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "places=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        a=GeoText(str(df2[i])) # I turn the string of the tweet into a Geotext object\n",
    "    \n",
    "        a=a.cities # I create a dictionary with the cities/places that are mentioned in the text\n",
    "    \n",
    "        places.append(len(a)) # I append the length of the dictionary to the places list\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        places.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pronoun=[]\n",
    "\n",
    "first = ['i','me','myself','mine','we','us','ours','ourselves'] # a list of the first person pronouns\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        a = str(df2[i]).split() # I break the tweet into words\n",
    "    \n",
    "        for i in range(len(a)):\n",
    "        \n",
    "            if a[i].lower() in first: #if a word is a first person pronoun\n",
    "            \n",
    "                count = count + 1.0\n",
    "            \n",
    "            first_pronoun.append(count)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        first_pronoun.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pronoun=[]\n",
    "\n",
    "second = ['you','yours','yourself','yourselves']\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        a = str(df2[i]).split(' ')\n",
    "    \n",
    "        for i in range(len(a)):\n",
    "        \n",
    "            if a[i].lower() in second:\n",
    "            \n",
    "                count = count + 1.0\n",
    "            \n",
    "            second_pronoun.append(count)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        second_pronoun.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_pronoun=[]\n",
    "\n",
    "third = ['he','she','it','him','her','his','hers','himself','herself','itself','they','them','theirs','themselves']\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        a = str(df2[i]).split(' ')\n",
    "    \n",
    "        for i in range(len(a)):\n",
    "        \n",
    "            if a[i].lower() in third:\n",
    "            \n",
    "                count = count + 1.0\n",
    "            \n",
    "            third_pronoun.append(count)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        third_pronoun.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "witness_claim=[]\n",
    "\n",
    "witness_words=['see','saw','seen', 'attend', 'attended', 'notice', 'noticed', 'watch', 'watched',\n",
    "              'bystander', 'eyewitness', 'observer', 'recognize', 'recognise', 'recognized', 'recognised',\n",
    "              'witness', 'witnessed', 'follow', 'followed', 'observe', 'observed'] \n",
    "                # words that indicate that the author of the tweet is/was a witness of the event\n",
    "\n",
    "for i in range(len(df2)):  # the process is the same as before with me counting the matching words \n",
    "                           # of the tweet to a list of words\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        a=str(df2[i]).split(' ')\n",
    "    \n",
    "        for i in range(len(a)):     \n",
    "        \n",
    "            if a[i].lower() in witness_words:\n",
    "            \n",
    "                    count = count + 1.0\n",
    "            \n",
    "            witness_claim.append(count)  \n",
    "            \n",
    "    except:\n",
    "        \n",
    "        witness_claim.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_match=[]\n",
    "\n",
    "text_lang=[]\n",
    "\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        a = TextBlob(str(df2[i]))\n",
    "    \n",
    "        text_lang.append(a.detect_language())\n",
    "\n",
    "        for i in range(len(user_lang)): \n",
    "    \n",
    "            if user_lang[i] == text_lang[i]: # check if the language of the text and the user match\n",
    "        \n",
    "                lang_match.append(1.0)\n",
    "        \n",
    "            else:\n",
    "        \n",
    "                lang_match.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        lang_match.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_shaper=[]\n",
    "\n",
    "for i in range(len(name)):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        count=0.0\n",
    "    \n",
    "        b=str(screen_name[i]).lower()\n",
    "        \n",
    "        opinion=['news','breaking','news','report','report','daily','times', 'feed', 'radar', 'net']\n",
    "            \n",
    "        for i in range(len(opinion)):\n",
    "            \n",
    "            if opinion[i] in b:\n",
    "        \n",
    "                count = count +1.0\n",
    "    \n",
    "        if count>0:\n",
    "        \n",
    "            opinion_shaper.append(1.0)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            opinion_shaper.append(0.0)\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        opinion_shaper.append(0.0)\n",
    "        \n",
    "        error_objects.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "metacontent_features = pd.DataFrame(list(zip(favourite_count, tweet_age, retweet_count, mentions, \n",
    "                                         retweet_per_second, favourite_per_second,\n",
    "                                        retweet_per_follower, favourite_per_follower)),\n",
    "                            columns = ['favourite_count', 'tweet_age', 'retweet_count', 'mentions', \n",
    "                                       'retweet_per_second','favourite_per_second','retweet_per_follower', \n",
    "                                       'favourite_per_follower'])\n",
    "\n",
    "user_features = pd.DataFrame(list(zip(profile_age, user_description, geo_enabled, opinion_shaper,extended_profile,\n",
    "                                      user_location, statuses_count, user_time_zone, verified, is_translator_enabled,\n",
    "                                      listed_count, protected, notifications, default_profile_picture, image_exists, \n",
    "                                      gender_binary, name_male, statuses_per_day,lists_per_day, followers, \n",
    "                                      following, followers_per_day, following_per_day, followers_following_ratio)),\n",
    "                             columns = ['profile_age', 'profile_description', 'geolocation', 'opinion_shaper',\n",
    "                                        'extended_profile','user_location', 'statuses_count', 'user_timezone', \n",
    "                                        'verified_account','text_translator', 'user_lists', 'account_protection', \n",
    "                                        'notifications','default_profile_picture', 'profile_picture', 'gender', \n",
    "                                        'male', 'statuses_per_day', 'lists_per_day','followers', \n",
    "                                        'following', 'followers_per_day', 'following_per_day',\n",
    "                                        'followers_following_ratio'])\n",
    "\n",
    "linguistic_features = pd.DataFrame(list(zip(characters, exclamation_mark, question_mark, hashtag, url, words,\n",
    "                                      commas, periods, multiple_marks,lang_match, dictation_rate, subjectivity, \n",
    "                                            polarity, positive_words, negative_words, uppercase_letters, places,\n",
    "                                            first_pronoun, second_pronoun, third_pronoun, witness_claim)),\n",
    "                             columns = ['characters', 'exclamation_marks', 'question_marks', 'hashtags', 'urls',\n",
    "                                        'words', 'commas', 'periods', 'multiple_marks','lang_match', \n",
    "                                        'dictation_rate', 'subjectivity', 'polarity', 'positive_words', 'negative_words',\n",
    "                                       'uppercase_letters', 'places', 'first_person', 'second_person', 'third_person', \n",
    "                                       'witness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = metacontent_features.values\n",
    "\n",
    "y = user_features.values\n",
    "\n",
    "z = linguistic_features.values\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "y_scaled = min_max_scaler.fit_transform(y)\n",
    "\n",
    "z_scaled = min_max_scaler.fit_transform(z)\n",
    "\n",
    "metacontent_feaures = pd.DataFrame(x_scaled, \n",
    "                               columns = ['favourite_count', 'tweet_age', 'retweet_count',\n",
    "                                      'mentions', 'retweet_per_second', 'favoutire_per_second',\n",
    "                                      'retweet_per_follower', 'favourite_per_follower'])\n",
    "\n",
    "user_features = pd.DataFrame(list(zip(profile_age, user_description, geo_enabled, opinion_shaper,extended_profile,\n",
    "                                      user_location, statuses_count, user_time_zone, verified, is_translator_enabled,\n",
    "                                      listed_count, protected, notifications, default_profile_picture, image_exists, \n",
    "                                      gender_binary, name_male, statuses_per_day,lists_per_day, followers, \n",
    "                                      following, followers_per_day, following_per_day, followers_following_ratio)),\n",
    "                             columns = ['profile_age', 'profile_description', 'geolocation', 'opinion_shaper',\n",
    "                                        'extended_profile','user_location', 'statuses_count', 'user_timezone', \n",
    "                                        'verified_account','text_translator', 'user_lists', 'account_protection', \n",
    "                                        'notifications','default_profile_picture', 'profile_picture', 'gender', \n",
    "                                        'male', 'statuses_per_day', 'lists_per_day','followers', \n",
    "                                        'following', 'followers_per_day', 'following_per_day', \n",
    "                                        'followers_following_ratio'])\n",
    "\n",
    "linguistic_features = pd.DataFrame(list(zip(characters, exclamation_mark, question_mark, hashtag, url, words,\n",
    "                                      commas, periods, multiple_marks,lang_match, dictation_rate, subjectivity, \n",
    "                                            polarity,positive_words, negative_words, uppercase_letters, places, \n",
    "                                            first_pronoun, second_pronoun, third_pronoun, witness_claim)),\n",
    "                             columns = ['characters', 'exclamation_marks', 'question_marks', 'hashtags', 'urls',\n",
    "                                        'words', 'commas', 'periods', 'multiple_marks','lang_match', \n",
    "                                        'dictation_rate', 'subjectivity', 'polarity', 'positive_words', 'negative_words',\n",
    "                                       'uppercase_letters', 'places', 'first_person', 'second_person', 'third_person', \n",
    "                                       'witness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([metacontent_feaures ,user_features, linguistic_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(features, columns = ['favourite_count', 'tweet_age', 'retweet_count','mentions', \n",
    "                                             'retweet_per_second', \n",
    "                                        'favoutire_per_second','retweet_per_follower', 'favourite_per_follower',\n",
    "                                       'profile_age', 'profile_description', 'geolocation', 'opinion_shaper',\n",
    "                                        'extended_profile','user_location', 'statuses_count', 'user_timezone', \n",
    "                                        'verified_account','text_translator', 'user_lists', 'account_protection', \n",
    "                                        'notifications','default_profile_picture', 'profile_picture', 'gender', \n",
    "                                        'male', 'statuses_per_day', 'lists_per_day','followers', \n",
    "                                        'following', 'followers_per_day', 'following_per_day', \n",
    "                                             'followers_following_ratio',\n",
    "                                       'characters', 'exclamation_marks', 'question_marks', 'hashtags', 'urls',\n",
    "                                        'words', 'commas', 'periods', 'multiple_marks','lang_match', \n",
    "                                        'dictation_rate', 'subjectivity', 'polarity', 'positive_words', 'negative_words',\n",
    "                                       'uppercase_letters', 'places', 'first_person', 'second_person', 'third_person', \n",
    "                                       'witness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('testing_extracted.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
