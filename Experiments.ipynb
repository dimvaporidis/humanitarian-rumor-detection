{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import ast\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the first dataset\n",
    "X = pd.read_csv('normalized_generic.csv',sep='\\t')\n",
    "X = X.drop('Unnamed: 0',axis=1)\n",
    "#a = a.drop(0,axis=1)\n",
    "#a = a.drop(0, inplace=False)\n",
    "\n",
    "# Loading the second dataset\n",
    "#b = pd.read_csv('rumor_Truth_Estimator(46176).csv',sep='\\t', header=None, index_col=False, lineterminator='\\n')\n",
    "#b = b.drop(0,axis=1)\n",
    "#b=b.drop(0,inplace=False)\n",
    "\n",
    "# Merging the two datasets\n",
    "a=X.loc[X['rumor'] == 0.0]\n",
    "b=X.loc[X['rumor'] == 1.0]\n",
    "a=a[0:len(b)]\n",
    "X=pd.concat([a,b])\n",
    "X = shuffle(X)\n",
    "X= X.reset_index(drop=True)\n",
    "\n",
    "# Defining the last column of the dataframe as the output column of the model\n",
    "y=X['rumor']\n",
    "\n",
    "# Adjusting the values of the output column\n",
    "#y= y.reset_index(drop=True)\n",
    "#for i in range(len(y)):\n",
    "    \n",
    "#    y[i]=str(y[i])\n",
    "#    \n",
    "#    if y[i]=='True':\n",
    "        \n",
    "#        y[i]=1.0\n",
    "        \n",
    "#    else:\n",
    "        \n",
    "#        y[i]=0.0\n",
    "        \n",
    "#y=y.astype('int')\n",
    "\n",
    "# Deleting the last column of the Dataframe\n",
    "#X = X.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_age</th>\n",
       "      <th>profile_description</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>opinion_shaper</th>\n",
       "      <th>extended_profile</th>\n",
       "      <th>user_location</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>verified_account</th>\n",
       "      <th>text_translator</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>male</th>\n",
       "      <th>statuses_per_day</th>\n",
       "      <th>lists_per_day</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>followers_per_day</th>\n",
       "      <th>following_per_day</th>\n",
       "      <th>followers_following_ratio</th>\n",
       "      <th>rumor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.253168e-07</td>\n",
       "      <td>6.749242e-09</td>\n",
       "      <td>4.954027e-07</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4.333194e-09</td>\n",
       "      <td>7.989138e-08</td>\n",
       "      <td>1.312275e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.598722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.555898e-06</td>\n",
       "      <td>5.526448e-08</td>\n",
       "      <td>6.921483e-06</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>9.914482e-08</td>\n",
       "      <td>3.270289e-06</td>\n",
       "      <td>7.685058e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.441644e-05</td>\n",
       "      <td>7.623810e-08</td>\n",
       "      <td>8.888940e-06</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>3.512989e-07</td>\n",
       "      <td>2.722314e-05</td>\n",
       "      <td>3.274603e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.756040e-05</td>\n",
       "      <td>4.966257e-09</td>\n",
       "      <td>4.670940e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.012543e-09</td>\n",
       "      <td>1.370578e-08</td>\n",
       "      <td>8.661013e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.395630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.478817e-06</td>\n",
       "      <td>8.363397e-09</td>\n",
       "      <td>1.643321e-05</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>3.562296e-07</td>\n",
       "      <td>1.666105e-05</td>\n",
       "      <td>5.425107e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.123694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.469499e-05</td>\n",
       "      <td>8.560012e-07</td>\n",
       "      <td>1.967456e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.364125e-06</td>\n",
       "      <td>2.772056e-08</td>\n",
       "      <td>1.094437e-04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.961608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.251702e-06</td>\n",
       "      <td>7.570001e-08</td>\n",
       "      <td>4.571859e-06</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>4.077470e-08</td>\n",
       "      <td>8.790748e-07</td>\n",
       "      <td>1.171976e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.283047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.925049e-05</td>\n",
       "      <td>1.309274e-06</td>\n",
       "      <td>9.498993e-05</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>2.878159e-06</td>\n",
       "      <td>2.843834e-06</td>\n",
       "      <td>2.565051e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.386775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.008412e-05</td>\n",
       "      <td>1.284939e-05</td>\n",
       "      <td>3.859045e-04</td>\n",
       "      <td>0.024103</td>\n",
       "      <td>8.556918e-06</td>\n",
       "      <td>2.433204e-04</td>\n",
       "      <td>8.925126e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.513872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.573636e-05</td>\n",
       "      <td>9.014566e-08</td>\n",
       "      <td>6.327000e-06</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>1.055940e-07</td>\n",
       "      <td>5.981043e-06</td>\n",
       "      <td>4.477762e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.738238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.017060e-06</td>\n",
       "      <td>1.344611e-08</td>\n",
       "      <td>1.089886e-06</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.266138e-08</td>\n",
       "      <td>3.459041e-07</td>\n",
       "      <td>9.185923e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.086552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.179072e-05</td>\n",
       "      <td>1.529166e-06</td>\n",
       "      <td>1.551318e-05</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.537164e-06</td>\n",
       "      <td>7.229385e-06</td>\n",
       "      <td>5.393449e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.535631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.957462e-06</td>\n",
       "      <td>9.389646e-07</td>\n",
       "      <td>7.248449e-05</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>1.160581e-06</td>\n",
       "      <td>2.533024e-05</td>\n",
       "      <td>1.162657e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.580296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.043520e-06</td>\n",
       "      <td>1.938656e-07</td>\n",
       "      <td>1.217275e-05</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>1.799017e-07</td>\n",
       "      <td>4.486825e-06</td>\n",
       "      <td>1.016717e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.999988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.056188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.556664e-05</td>\n",
       "      <td>3.639730e-08</td>\n",
       "      <td>1.729522e-04</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>1.483294e-06</td>\n",
       "      <td>4.116365e-06</td>\n",
       "      <td>9.136572e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.919409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.760159e-06</td>\n",
       "      <td>3.411703e-06</td>\n",
       "      <td>1.628743e-04</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.519288e-06</td>\n",
       "      <td>2.769721e-07</td>\n",
       "      <td>1.372759e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.424947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.202411e-06</td>\n",
       "      <td>2.958832e-07</td>\n",
       "      <td>1.595197e-05</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>3.219405e-07</td>\n",
       "      <td>1.334747e-05</td>\n",
       "      <td>6.119725e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.111170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.369198e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.086376e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.695332e-08</td>\n",
       "      <td>3.128405e-08</td>\n",
       "      <td>3.385669e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.753701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.035281e-06</td>\n",
       "      <td>1.097520e-07</td>\n",
       "      <td>3.227195e-06</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>3.672167e-08</td>\n",
       "      <td>3.439187e-07</td>\n",
       "      <td>2.679391e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.097073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.023030e-05</td>\n",
       "      <td>3.408580e-08</td>\n",
       "      <td>2.335470e-06</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>2.063348e-07</td>\n",
       "      <td>8.057760e-06</td>\n",
       "      <td>6.495760e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.543189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.443368e-05</td>\n",
       "      <td>4.507670e-06</td>\n",
       "      <td>1.508714e-04</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>2.382056e-06</td>\n",
       "      <td>2.151287e-05</td>\n",
       "      <td>2.809682e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.208238e-07</td>\n",
       "      <td>2.712140e-08</td>\n",
       "      <td>1.995765e-06</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>4.676544e-08</td>\n",
       "      <td>1.578334e-06</td>\n",
       "      <td>7.501246e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.631118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.252472e-06</td>\n",
       "      <td>5.347623e-07</td>\n",
       "      <td>1.981611e-05</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>2.692798e-07</td>\n",
       "      <td>5.129576e-06</td>\n",
       "      <td>1.331293e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.401493e-04</td>\n",
       "      <td>3.252717e-06</td>\n",
       "      <td>1.249830e-05</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>1.170791e-05</td>\n",
       "      <td>1.777907e-04</td>\n",
       "      <td>1.671258e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.018704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.286333e-06</td>\n",
       "      <td>1.238331e-06</td>\n",
       "      <td>1.132349e-06</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>5.192110e-07</td>\n",
       "      <td>1.526764e-05</td>\n",
       "      <td>8.628655e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.769916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.698129e-05</td>\n",
       "      <td>8.595239e-09</td>\n",
       "      <td>2.788409e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.106056e-08</td>\n",
       "      <td>9.264847e-08</td>\n",
       "      <td>8.163730e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.745495</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.703086e-05</td>\n",
       "      <td>1.739810e-04</td>\n",
       "      <td>8.673069e-02</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>9.977562e-04</td>\n",
       "      <td>1.454013e-05</td>\n",
       "      <td>1.741093e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.927846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.179675e-05</td>\n",
       "      <td>7.560165e-07</td>\n",
       "      <td>3.515944e-05</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.249840e-07</td>\n",
       "      <td>4.247559e-08</td>\n",
       "      <td>1.778013e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.041702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.052650e-03</td>\n",
       "      <td>1.491674e-05</td>\n",
       "      <td>3.363077e-05</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>6.916357e-06</td>\n",
       "      <td>2.329738e-04</td>\n",
       "      <td>7.534349e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.492193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.678121e-06</td>\n",
       "      <td>2.131057e-06</td>\n",
       "      <td>1.675310e-04</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>2.919146e-06</td>\n",
       "      <td>9.773122e-05</td>\n",
       "      <td>7.580324e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88758</th>\n",
       "      <td>0.955763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.779179e-06</td>\n",
       "      <td>5.885319e-08</td>\n",
       "      <td>4.062302e-06</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>3.645172e-08</td>\n",
       "      <td>1.248836e-06</td>\n",
       "      <td>7.384761e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88759</th>\n",
       "      <td>0.172363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.737315e-05</td>\n",
       "      <td>3.455411e-07</td>\n",
       "      <td>2.706314e-05</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>1.346574e-06</td>\n",
       "      <td>5.234505e-05</td>\n",
       "      <td>6.528367e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88760</th>\n",
       "      <td>0.972951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.419097e-06</td>\n",
       "      <td>3.740875e-08</td>\n",
       "      <td>3.849987e-06</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>3.393630e-08</td>\n",
       "      <td>2.006902e-06</td>\n",
       "      <td>4.283265e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88761</th>\n",
       "      <td>0.707647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.273765e-05</td>\n",
       "      <td>2.150862e-07</td>\n",
       "      <td>9.143718e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.108160e-07</td>\n",
       "      <td>6.243970e-08</td>\n",
       "      <td>4.238647e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88762</th>\n",
       "      <td>0.850704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.377988e-06</td>\n",
       "      <td>4.278441e-08</td>\n",
       "      <td>7.643356e-06</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>7.705515e-08</td>\n",
       "      <td>1.716315e-06</td>\n",
       "      <td>1.136837e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88763</th>\n",
       "      <td>0.726420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.540433e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.344664e-06</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1.587530e-08</td>\n",
       "      <td>4.108461e-07</td>\n",
       "      <td>9.714241e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88764</th>\n",
       "      <td>0.065846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.388499e-04</td>\n",
       "      <td>4.321582e-06</td>\n",
       "      <td>3.279566e-05</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>4.271549e-06</td>\n",
       "      <td>7.623778e-05</td>\n",
       "      <td>1.421921e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88765</th>\n",
       "      <td>0.918865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.386534e-06</td>\n",
       "      <td>4.537226e-07</td>\n",
       "      <td>3.333352e-05</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>3.111185e-07</td>\n",
       "      <td>7.175668e-06</td>\n",
       "      <td>1.099789e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88766</th>\n",
       "      <td>0.455503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.221481e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.104765e-07</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>7.728466e-09</td>\n",
       "      <td>3.826449e-07</td>\n",
       "      <td>5.074129e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88767</th>\n",
       "      <td>0.549682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.045890e-07</td>\n",
       "      <td>1.143703e-07</td>\n",
       "      <td>5.916524e-06</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>9.231049e-08</td>\n",
       "      <td>2.024826e-06</td>\n",
       "      <td>1.154802e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88768</th>\n",
       "      <td>0.202005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.323439e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.369463e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.704193e-08</td>\n",
       "      <td>5.419743e-08</td>\n",
       "      <td>1.181047e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88769</th>\n",
       "      <td>0.063473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.121970e-05</td>\n",
       "      <td>1.042588e-07</td>\n",
       "      <td>2.604403e-06</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>3.518970e-07</td>\n",
       "      <td>9.736144e-06</td>\n",
       "      <td>9.169312e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88770</th>\n",
       "      <td>0.042084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.924672e-04</td>\n",
       "      <td>1.729733e-06</td>\n",
       "      <td>9.285262e-06</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>1.892236e-06</td>\n",
       "      <td>5.299327e-05</td>\n",
       "      <td>9.061602e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88771</th>\n",
       "      <td>0.211611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.272013e-07</td>\n",
       "      <td>7.818127e-08</td>\n",
       "      <td>1.091301e-05</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>4.422850e-07</td>\n",
       "      <td>2.902655e-05</td>\n",
       "      <td>3.866613e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88772</th>\n",
       "      <td>0.811815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.743767e-06</td>\n",
       "      <td>2.975345e-07</td>\n",
       "      <td>1.539995e-05</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>1.626891e-07</td>\n",
       "      <td>2.974772e-06</td>\n",
       "      <td>1.386170e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88773</th>\n",
       "      <td>0.976886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.285204e-06</td>\n",
       "      <td>8.467739e-08</td>\n",
       "      <td>4.798329e-06</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>4.212522e-08</td>\n",
       "      <td>3.165215e-07</td>\n",
       "      <td>3.336458e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88774</th>\n",
       "      <td>0.891133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.002060e-06</td>\n",
       "      <td>4.826944e-08</td>\n",
       "      <td>3.821678e-06</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>3.677966e-08</td>\n",
       "      <td>4.268404e-06</td>\n",
       "      <td>2.184877e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88775</th>\n",
       "      <td>0.727381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.030564e-07</td>\n",
       "      <td>4.548932e-08</td>\n",
       "      <td>8.648316e-06</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>1.019684e-07</td>\n",
       "      <td>3.680953e-06</td>\n",
       "      <td>7.023064e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88776</th>\n",
       "      <td>0.762428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188104e-05</td>\n",
       "      <td>6.075762e-08</td>\n",
       "      <td>4.586013e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.158611e-08</td>\n",
       "      <td>1.219242e-09</td>\n",
       "      <td>2.551062e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88777</th>\n",
       "      <td>0.991609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.087082e-07</td>\n",
       "      <td>6.673615e-09</td>\n",
       "      <td>8.988020e-06</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>7.773559e-08</td>\n",
       "      <td>2.643827e-06</td>\n",
       "      <td>7.451217e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88778</th>\n",
       "      <td>0.046389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.969143e-04</td>\n",
       "      <td>5.206853e-06</td>\n",
       "      <td>5.600881e-05</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>1.035461e-05</td>\n",
       "      <td>1.910440e-04</td>\n",
       "      <td>1.375542e-07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88779</th>\n",
       "      <td>0.524844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.064512e-06</td>\n",
       "      <td>3.152181e-07</td>\n",
       "      <td>2.387841e-05</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>3.901857e-07</td>\n",
       "      <td>1.398216e-05</td>\n",
       "      <td>7.080407e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88780</th>\n",
       "      <td>0.995764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.559769e-06</td>\n",
       "      <td>1.063323e-07</td>\n",
       "      <td>3.099805e-06</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>2.669773e-08</td>\n",
       "      <td>7.269733e-07</td>\n",
       "      <td>9.270586e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88781</th>\n",
       "      <td>0.920404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.424969e-06</td>\n",
       "      <td>6.823216e-06</td>\n",
       "      <td>7.989430e-04</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>7.444464e-06</td>\n",
       "      <td>3.800937e-06</td>\n",
       "      <td>4.965677e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88782</th>\n",
       "      <td>0.339576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.083051e-06</td>\n",
       "      <td>1.071834e-07</td>\n",
       "      <td>4.954027e-06</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>1.251175e-07</td>\n",
       "      <td>1.632319e-06</td>\n",
       "      <td>1.940688e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88783</th>\n",
       "      <td>0.477806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.723873e-05</td>\n",
       "      <td>9.086286e-05</td>\n",
       "      <td>2.938848e-02</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5.274986e-04</td>\n",
       "      <td>5.038171e-07</td>\n",
       "      <td>2.636763e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88784</th>\n",
       "      <td>0.910855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.599688e-07</td>\n",
       "      <td>7.265274e-09</td>\n",
       "      <td>7.926443e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.463200e-09</td>\n",
       "      <td>3.829468e-10</td>\n",
       "      <td>4.409243e-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88785</th>\n",
       "      <td>0.811688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.986073e-08</td>\n",
       "      <td>1.222936e-08</td>\n",
       "      <td>7.218725e-07</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>7.627246e-09</td>\n",
       "      <td>4.251236e-07</td>\n",
       "      <td>4.511866e-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88786</th>\n",
       "      <td>0.599521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.006612e-07</td>\n",
       "      <td>5.519087e-09</td>\n",
       "      <td>1.486208e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.126041e-08</td>\n",
       "      <td>2.613778e-09</td>\n",
       "      <td>8.267331e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88787</th>\n",
       "      <td>0.866526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.476752e-05</td>\n",
       "      <td>2.672931e-08</td>\n",
       "      <td>3.456495e-05</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>3.420980e-07</td>\n",
       "      <td>1.472132e-05</td>\n",
       "      <td>5.896182e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88788 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       profile_age  profile_description  geolocation  opinion_shaper  \\\n",
       "0         0.980497                  1.0          0.0             0.0   \n",
       "1         0.598722                  1.0          0.0             0.0   \n",
       "2         0.217005                  1.0          1.0             0.0   \n",
       "3         0.666258                  1.0          0.0             0.0   \n",
       "4         0.395630                  1.0          0.0             0.0   \n",
       "5         0.123694                  1.0          1.0             0.0   \n",
       "6         0.961608                  1.0          0.0             0.0   \n",
       "7         0.283047                  1.0          0.0             0.0   \n",
       "8         0.386775                  1.0          0.0             0.0   \n",
       "9         0.513872                  1.0          1.0             0.0   \n",
       "10        0.738238                  1.0          0.0             0.0   \n",
       "11        0.086552                  1.0          1.0             0.0   \n",
       "12        0.535631                  1.0          1.0             0.0   \n",
       "13        0.580296                  1.0          1.0             0.0   \n",
       "14        0.999988                  1.0          0.0             0.0   \n",
       "15        0.919409                  1.0          0.0             0.0   \n",
       "16        0.424947                  1.0          1.0             0.0   \n",
       "17        0.111170                  1.0          0.0             0.0   \n",
       "18        0.753701                  1.0          0.0             0.0   \n",
       "19        0.097073                  1.0          1.0             0.0   \n",
       "20        0.543189                  1.0          1.0             0.0   \n",
       "21        0.366000                  0.0          1.0             0.0   \n",
       "22        0.631118                  1.0          1.0             0.0   \n",
       "23        0.009155                  0.0          1.0             0.0   \n",
       "24        0.018704                  1.0          0.0             0.0   \n",
       "25        0.769916                  0.0          0.0             0.0   \n",
       "26        0.745495                  1.0          1.0             1.0   \n",
       "27        0.927846                  1.0          0.0             1.0   \n",
       "28        0.041702                  1.0          1.0             0.0   \n",
       "29        0.492193                  1.0          0.0             0.0   \n",
       "...            ...                  ...          ...             ...   \n",
       "88758     0.955763                  1.0          1.0             0.0   \n",
       "88759     0.172363                  1.0          0.0             1.0   \n",
       "88760     0.972951                  1.0          1.0             0.0   \n",
       "88761     0.707647                  1.0          1.0             0.0   \n",
       "88762     0.850704                  1.0          0.0             0.0   \n",
       "88763     0.726420                  0.0          0.0             0.0   \n",
       "88764     0.065846                  1.0          0.0             0.0   \n",
       "88765     0.918865                  1.0          1.0             0.0   \n",
       "88766     0.455503                  1.0          0.0             0.0   \n",
       "88767     0.549682                  1.0          0.0             0.0   \n",
       "88768     0.202005                  0.0          0.0             0.0   \n",
       "88769     0.063473                  1.0          0.0             0.0   \n",
       "88770     0.042084                  1.0          1.0             0.0   \n",
       "88771     0.211611                  1.0          0.0             0.0   \n",
       "88772     0.811815                  1.0          1.0             0.0   \n",
       "88773     0.976886                  1.0          1.0             0.0   \n",
       "88774     0.891133                  1.0          0.0             1.0   \n",
       "88775     0.727381                  1.0          1.0             0.0   \n",
       "88776     0.762428                  1.0          0.0             0.0   \n",
       "88777     0.991609                  1.0          0.0             0.0   \n",
       "88778     0.046389                  1.0          1.0             0.0   \n",
       "88779     0.524844                  1.0          1.0             0.0   \n",
       "88780     0.995764                  1.0          0.0             0.0   \n",
       "88781     0.920404                  1.0          0.0             0.0   \n",
       "88782     0.339576                  1.0          1.0             0.0   \n",
       "88783     0.477806                  1.0          1.0             0.0   \n",
       "88784     0.910855                  0.0          0.0             0.0   \n",
       "88785     0.811688                  1.0          0.0             0.0   \n",
       "88786     0.599521                  1.0          1.0             0.0   \n",
       "88787     0.866526                  0.0          0.0             0.0   \n",
       "\n",
       "       extended_profile  user_location  statuses_count  user_timezone  \\\n",
       "0                   0.0            1.0        0.000272            0.0   \n",
       "1                   0.0            1.0        0.005578            0.0   \n",
       "2                   1.0            1.0        0.006534            0.0   \n",
       "3                   0.0            1.0        0.014427            0.0   \n",
       "4                   0.0            1.0        0.000721            0.0   \n",
       "5                   0.0            1.0        0.014444            0.0   \n",
       "6                   0.0            1.0        0.001484            0.0   \n",
       "7                   0.0            1.0        0.024170            0.0   \n",
       "8                   0.0            1.0        0.038195            0.0   \n",
       "9                   1.0            1.0        0.016308            0.0   \n",
       "10                  0.0            1.0        0.000926            0.0   \n",
       "11                  0.0            1.0        0.001258            0.0   \n",
       "12                  0.0            1.0        0.006577            0.0   \n",
       "13                  0.0            1.0        0.004325            0.0   \n",
       "14                  0.0            1.0        0.056188            0.0   \n",
       "15                  0.0            1.0        0.003129            0.0   \n",
       "16                  0.0            1.0        0.002726            0.0   \n",
       "17                  0.0            1.0        0.000599            0.0   \n",
       "18                  1.0            1.0        0.008397            0.0   \n",
       "19                  0.0            1.0        0.001225            0.0   \n",
       "20                  0.0            1.0        0.016366            0.0   \n",
       "21                  0.0            1.0        0.000416            0.0   \n",
       "22                  0.0            1.0        0.006422            0.0   \n",
       "23                  0.0            1.0        0.007227            0.0   \n",
       "24                  0.0            1.0        0.000214            0.0   \n",
       "25                  0.0            1.0        0.035109            0.0   \n",
       "26                  0.0            1.0        0.061620            0.0   \n",
       "27                  0.0            1.0        0.013497            0.0   \n",
       "28                  0.0            0.0        0.054130            0.0   \n",
       "29                  0.0            1.0        0.002232            0.0   \n",
       "...                 ...            ...             ...            ...   \n",
       "88758               0.0            1.0        0.005633            0.0   \n",
       "88759               0.0            1.0        0.003693            0.0   \n",
       "88760               0.0            1.0        0.002902            0.0   \n",
       "88761               0.0            1.0        0.028567            0.0   \n",
       "88762               0.0            1.0        0.001446            0.0   \n",
       "88763               1.0            1.0        0.000317            0.0   \n",
       "88764               1.0            1.0        0.035632            0.0   \n",
       "88765               0.0            1.0        0.001571            0.0   \n",
       "88766               0.0            1.0        0.000035            0.0   \n",
       "88767               0.0            1.0        0.000478            0.0   \n",
       "88768               0.0            1.0        0.001326            0.0   \n",
       "88769               0.0            1.0        0.004009            0.0   \n",
       "88770               0.0            1.0        0.035935            0.0   \n",
       "88771               0.0            1.0        0.000190            0.0   \n",
       "88772               1.0            1.0        0.004749            0.0   \n",
       "88773               1.0            1.0        0.002753            0.0   \n",
       "88774               0.0            1.0        0.007694            0.0   \n",
       "88775               0.0            1.0        0.000092            0.0   \n",
       "88776               0.0            1.0        0.011170            0.0   \n",
       "88777               0.0            1.0        0.000500            0.0   \n",
       "88778               1.0            1.0        0.016984            0.0   \n",
       "88779               1.0            1.0        0.003278            0.0   \n",
       "88780               0.0            1.0        0.001915            0.0   \n",
       "88781               0.0            1.0        0.008427            0.0   \n",
       "88782               0.0            1.0        0.003803            0.0   \n",
       "88783               0.0            1.0        0.027832            0.0   \n",
       "88784               0.0            1.0        0.000404            0.0   \n",
       "88785               0.0            1.0        0.000100            0.0   \n",
       "88786               0.0            1.0        0.000666            0.0   \n",
       "88787               0.0            1.0        0.015779            0.0   \n",
       "\n",
       "       verified_account  text_translator  ...    gender  male  \\\n",
       "0                   0.0              0.0  ...       1.0   1.0   \n",
       "1                   0.0              0.0  ...       0.0   1.0   \n",
       "2                   0.0              0.0  ...       1.0   1.0   \n",
       "3                   0.0              0.0  ...       0.0   1.0   \n",
       "4                   0.0              0.0  ...       0.0   1.0   \n",
       "5                   0.0              0.0  ...       1.0   1.0   \n",
       "6                   0.0              0.0  ...       0.0   1.0   \n",
       "7                   0.0              0.0  ...       0.0   1.0   \n",
       "8                   0.0              0.0  ...       0.0   1.0   \n",
       "9                   0.0              0.0  ...       1.0   1.0   \n",
       "10                  0.0              0.0  ...       1.0   1.0   \n",
       "11                  0.0              0.0  ...       0.0   1.0   \n",
       "12                  0.0              0.0  ...       1.0   1.0   \n",
       "13                  0.0              0.0  ...       1.0   1.0   \n",
       "14                  0.0              0.0  ...       0.0   1.0   \n",
       "15                  0.0              0.0  ...       0.0   1.0   \n",
       "16                  0.0              0.0  ...       1.0   1.0   \n",
       "17                  0.0              0.0  ...       1.0   1.0   \n",
       "18                  0.0              0.0  ...       1.0   1.0   \n",
       "19                  0.0              0.0  ...       1.0   1.0   \n",
       "20                  0.0              0.0  ...       1.0   1.0   \n",
       "21                  0.0              0.0  ...       1.0   1.0   \n",
       "22                  0.0              0.0  ...       1.0   1.0   \n",
       "23                  0.0              0.0  ...       0.0   1.0   \n",
       "24                  0.0              0.0  ...       0.0   1.0   \n",
       "25                  0.0              0.0  ...       0.0   1.0   \n",
       "26                  1.0              0.0  ...       0.0   1.0   \n",
       "27                  0.0              0.0  ...       0.0   1.0   \n",
       "28                  0.0              0.0  ...       0.0   1.0   \n",
       "29                  0.0              0.0  ...       1.0   1.0   \n",
       "...                 ...              ...  ...       ...   ...   \n",
       "88758               0.0              0.0  ...       1.0   1.0   \n",
       "88759               0.0              0.0  ...       1.0   1.0   \n",
       "88760               0.0              0.0  ...       1.0   1.0   \n",
       "88761               0.0              0.0  ...       0.0   1.0   \n",
       "88762               0.0              0.0  ...       0.0   1.0   \n",
       "88763               0.0              0.0  ...       0.0   1.0   \n",
       "88764               0.0              0.0  ...       0.0   1.0   \n",
       "88765               0.0              0.0  ...       1.0   1.0   \n",
       "88766               0.0              0.0  ...       0.0   1.0   \n",
       "88767               0.0              0.0  ...       1.0   1.0   \n",
       "88768               0.0              0.0  ...       0.0   1.0   \n",
       "88769               0.0              0.0  ...       1.0   1.0   \n",
       "88770               0.0              0.0  ...       0.0   1.0   \n",
       "88771               0.0              0.0  ...       0.0   1.0   \n",
       "88772               0.0              0.0  ...       1.0   1.0   \n",
       "88773               0.0              0.0  ...       1.0   1.0   \n",
       "88774               0.0              0.0  ...       0.0   1.0   \n",
       "88775               0.0              0.0  ...       0.0   1.0   \n",
       "88776               0.0              0.0  ...       0.0   1.0   \n",
       "88777               0.0              0.0  ...       0.0   1.0   \n",
       "88778               0.0              0.0  ...       1.0   1.0   \n",
       "88779               0.0              0.0  ...       1.0   1.0   \n",
       "88780               0.0              0.0  ...       1.0   1.0   \n",
       "88781               1.0              0.0  ...       0.0   1.0   \n",
       "88782               0.0              0.0  ...       1.0   1.0   \n",
       "88783               1.0              0.0  ...       0.0   1.0   \n",
       "88784               0.0              0.0  ...       0.0   1.0   \n",
       "88785               0.0              0.0  ...       1.0   1.0   \n",
       "88786               0.0              0.0  ...       0.0   1.0   \n",
       "88787               0.0              0.0  ...       1.0   1.0   \n",
       "\n",
       "       statuses_per_day  lists_per_day     followers  following  \\\n",
       "0          2.253168e-07   6.749242e-09  4.954027e-07   0.000020   \n",
       "1          7.555898e-06   5.526448e-08  6.921483e-06   0.000501   \n",
       "2          2.441644e-05   7.623810e-08  8.888940e-06   0.001512   \n",
       "3          1.756040e-05   4.966257e-09  4.670940e-07   0.000002   \n",
       "4          1.478817e-06   8.363397e-09  1.643321e-05   0.001688   \n",
       "5          9.469499e-05   8.560012e-07  1.967456e-05   0.000000   \n",
       "6          1.251702e-06   7.570001e-08  4.571859e-06   0.000216   \n",
       "7          6.925049e-05   1.309274e-06  9.498993e-05   0.000205   \n",
       "8          8.008412e-05   1.284939e-05  3.859045e-04   0.024103   \n",
       "9          2.573636e-05   9.014566e-08  6.327000e-06   0.000787   \n",
       "10         1.017060e-06   1.344611e-08  1.089886e-06   0.000065   \n",
       "11         1.179072e-05   1.529166e-06  1.551318e-05   0.000159   \n",
       "12         9.957462e-06   9.389646e-07  7.248449e-05   0.003474   \n",
       "13         6.043520e-06   1.938656e-07  1.217275e-05   0.000666   \n",
       "14         4.556664e-05   3.639730e-08  1.729522e-04   0.001054   \n",
       "15         2.760159e-06   3.411703e-06  1.628743e-04   0.000065   \n",
       "16         5.202411e-06   2.958832e-07  1.595197e-05   0.001452   \n",
       "17         4.369198e-06   0.000000e+00  6.086376e-07   0.000000   \n",
       "18         9.035281e-06   1.097520e-07  3.227195e-06   0.000066   \n",
       "19         1.023030e-05   3.408580e-08  2.335470e-06   0.000199   \n",
       "20         2.443368e-05   4.507670e-06  1.508714e-04   0.002992   \n",
       "21         9.208238e-07   2.712140e-08  1.995765e-06   0.000147   \n",
       "22         8.252472e-06   5.347623e-07  1.981611e-05   0.000829   \n",
       "23         6.401493e-04   3.252717e-06  1.249830e-05   0.000416   \n",
       "24         9.286333e-06   1.238331e-06  1.132349e-06   0.000072   \n",
       "25         3.698129e-05   8.595239e-09  2.788409e-06   0.000018   \n",
       "26         6.703086e-05   1.739810e-04  8.673069e-02   0.002776   \n",
       "27         1.179675e-05   7.560165e-07  3.515944e-05   0.000010   \n",
       "28         1.052650e-03   1.491674e-05  3.363077e-05   0.002487   \n",
       "29         3.678121e-06   2.131057e-06  1.675310e-04   0.012320   \n",
       "...                 ...            ...           ...        ...   \n",
       "88758      4.779179e-06   5.885319e-08  4.062302e-06   0.000306   \n",
       "88759      1.737315e-05   3.455411e-07  2.706314e-05   0.002310   \n",
       "88760      2.419097e-06   3.740875e-08  3.849987e-06   0.000500   \n",
       "88761      3.273765e-05   2.150862e-07  9.143718e-06   0.000011   \n",
       "88762      1.377988e-06   4.278441e-08  7.643356e-06   0.000374   \n",
       "88763      3.540433e-07   0.000000e+00  1.344664e-06   0.000076   \n",
       "88764      4.388499e-04   4.321582e-06  3.279566e-05   0.001285   \n",
       "88765      1.386534e-06   4.537226e-07  3.333352e-05   0.001689   \n",
       "88766      6.221481e-08   0.000000e+00  4.104765e-07   0.000044   \n",
       "88767      7.045890e-07   1.143703e-07  5.916524e-06   0.000285   \n",
       "88768      5.323439e-06   0.000000e+00  6.369463e-07   0.000002   \n",
       "88769      5.121970e-05   1.042588e-07  2.604403e-06   0.000157   \n",
       "88770      6.924672e-04   1.729733e-06  9.285262e-06   0.000570   \n",
       "88771      7.272013e-07   7.818127e-08  1.091301e-05   0.001572   \n",
       "88772      4.743767e-06   2.975345e-07  1.539995e-05   0.000618   \n",
       "88773      2.285204e-06   8.467739e-08  4.798329e-06   0.000079   \n",
       "88774      7.002060e-06   4.826944e-08  3.821678e-06   0.000974   \n",
       "88775      1.030564e-07   4.548932e-08  8.648316e-06   0.000685   \n",
       "88776      1.188104e-05   6.075762e-08  4.586013e-06   0.000000   \n",
       "88777      4.087082e-07   6.673615e-09  8.988020e-06   0.000671   \n",
       "88778      2.969143e-04   5.206853e-06  5.600881e-05   0.002269   \n",
       "88779      5.064512e-06   3.152181e-07  2.387841e-05   0.001879   \n",
       "88780      1.559769e-06   1.063323e-07  3.099805e-06   0.000185   \n",
       "88781      7.424969e-06   6.823216e-06  7.989430e-04   0.000896   \n",
       "88782      9.083051e-06   1.071834e-07  4.954027e-06   0.000141   \n",
       "88783      4.723873e-05   9.086286e-05  2.938848e-02   0.000061   \n",
       "88784      3.599688e-07   7.265274e-09  7.926443e-07   0.000000   \n",
       "88785      9.986073e-08   1.222936e-08  7.218725e-07   0.000088   \n",
       "88786      9.006612e-07   5.519087e-09  1.486208e-06   0.000000   \n",
       "88787      1.476752e-05   2.672931e-08  3.456495e-05   0.003267   \n",
       "\n",
       "       followers_per_day  following_per_day  followers_following_ratio  rumor  \n",
       "0           4.333194e-09       7.989138e-08               1.312275e-07    1.0  \n",
       "1           9.914482e-08       3.270289e-06               7.685058e-08    1.0  \n",
       "2           3.512989e-07       2.722314e-05               3.274603e-08    0.0  \n",
       "3           6.012543e-09       1.370578e-08               8.661013e-07    0.0  \n",
       "4           3.562296e-07       1.666105e-05               5.425107e-08    0.0  \n",
       "5           1.364125e-06       2.772056e-08               1.094437e-04    1.0  \n",
       "6           4.077470e-08       8.790748e-07               1.171976e-07    0.0  \n",
       "7           2.878159e-06       2.843834e-06               2.565051e-06    0.0  \n",
       "8           8.556918e-06       2.433204e-04               8.925126e-08    0.0  \n",
       "9           1.055940e-07       5.981043e-06               4.477762e-08    0.0  \n",
       "10          1.266138e-08       3.459041e-07               9.185923e-08    0.0  \n",
       "11          1.537164e-06       7.229385e-06               5.393449e-07    1.0  \n",
       "12          1.160581e-06       2.533024e-05               1.162657e-07    0.0  \n",
       "13          1.799017e-07       4.486825e-06               1.016717e-07    1.0  \n",
       "14          1.483294e-06       4.116365e-06               9.136572e-07    1.0  \n",
       "15          1.519288e-06       2.769721e-07               1.372759e-05    0.0  \n",
       "16          3.219405e-07       1.334747e-05               6.119725e-08    1.0  \n",
       "17          4.695332e-08       3.128405e-08               3.385669e-06    1.0  \n",
       "18          3.672167e-08       3.439187e-07               2.679391e-07    0.0  \n",
       "19          2.063348e-07       8.057760e-06               6.495760e-08    0.0  \n",
       "20          2.382056e-06       2.151287e-05               2.809682e-07    1.0  \n",
       "21          4.676544e-08       1.578334e-06               7.501246e-08    1.0  \n",
       "22          2.692798e-07       5.129576e-06               1.331293e-07    0.0  \n",
       "23          1.170791e-05       1.777907e-04               1.671258e-07    0.0  \n",
       "24          5.192110e-07       1.526764e-05               8.628655e-08    1.0  \n",
       "25          3.106056e-08       9.264847e-08               8.163730e-07    0.0  \n",
       "26          9.977562e-04       1.454013e-05               1.741093e-04    0.0  \n",
       "27          3.249840e-07       4.247559e-08               1.778013e-05    0.0  \n",
       "28          6.916357e-06       2.329738e-04               7.534349e-08    1.0  \n",
       "29          2.919146e-06       9.773122e-05               7.580324e-08    0.0  \n",
       "...                  ...                ...                        ...    ...  \n",
       "88758       3.645172e-08       1.248836e-06               7.384761e-08    0.0  \n",
       "88759       1.346574e-06       5.234505e-05               6.528367e-08    1.0  \n",
       "88760       3.393630e-08       2.006902e-06               4.283265e-08    0.0  \n",
       "88761       1.108160e-07       6.243970e-08               4.238647e-06    0.0  \n",
       "88762       7.705515e-08       1.716315e-06               1.136837e-07    1.0  \n",
       "88763       1.587530e-08       4.108461e-07               9.714241e-08    0.0  \n",
       "88764       4.271549e-06       7.623778e-05               1.421921e-07    1.0  \n",
       "88765       3.111185e-07       7.175668e-06               1.099789e-07    1.0  \n",
       "88766       7.728466e-09       3.826449e-07               5.074129e-08    0.0  \n",
       "88767       9.231049e-08       2.024826e-06               1.154802e-07    0.0  \n",
       "88768       2.704193e-08       5.419743e-08               1.181047e-06    1.0  \n",
       "88769       3.518970e-07       9.736144e-06               9.169312e-08    1.0  \n",
       "88770       1.892236e-06       5.299327e-05               9.061602e-08    1.0  \n",
       "88771       4.422850e-07       2.902655e-05               3.866613e-08    1.0  \n",
       "88772       1.626891e-07       2.974772e-06               1.386170e-07    0.0  \n",
       "88773       4.212522e-08       3.165215e-07               3.336458e-07    0.0  \n",
       "88774       3.677966e-08       4.268404e-06               2.184877e-08    1.0  \n",
       "88775       1.019684e-07       3.680953e-06               7.023064e-08    1.0  \n",
       "88776       5.158611e-08       1.219242e-09               2.551062e-05    0.0  \n",
       "88777       7.773559e-08       2.643827e-06               7.451217e-08    0.0  \n",
       "88778       1.035461e-05       1.910440e-04               1.375542e-07    1.0  \n",
       "88779       3.901857e-07       1.398216e-05               7.080407e-08    0.0  \n",
       "88780       2.669773e-08       7.269733e-07               9.270586e-08    0.0  \n",
       "88781       7.444464e-06       3.800937e-06               4.965677e-06    0.0  \n",
       "88782       1.251175e-07       1.632319e-06               1.940688e-07    0.0  \n",
       "88783       5.274986e-04       5.038171e-07               2.636763e-03    0.0  \n",
       "88784       7.463200e-09       3.829468e-10               4.409243e-06    1.0  \n",
       "88785       7.627246e-09       4.251236e-07               4.511866e-08    1.0  \n",
       "88786       2.126041e-08       2.613778e-09               8.267331e-06    0.0  \n",
       "88787       3.420980e-07       1.472132e-05               5.896182e-08    0.0  \n",
       "\n",
       "[88788 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metacontent_features= X.iloc[:,:8]\n",
    "metacontent_features['rumor']=X.rumor\n",
    "metacontent_features.to_csv('metacontent_features.csv', sep='\\t')\n",
    "user_features= X.iloc[:,8:32]\n",
    "user_features['rumor']=X.rumor\n",
    "user_features.to_csv('user_features.csv', sep='\\t')\n",
    "linguistic_features= X.iloc[:,32:]\n",
    "linguistic_features.to_csv('linguistic_features.csv', sep='\\t')\n",
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>tweet_age</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>mentions</th>\n",
       "      <th>retweet_per_second</th>\n",
       "      <th>favoutire_per_second</th>\n",
       "      <th>retweet_per_follower</th>\n",
       "      <th>favourite_per_follower</th>\n",
       "      <th>profile_age</th>\n",
       "      <th>profile_description</th>\n",
       "      <th>...</th>\n",
       "      <th>polarity</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>uppercase_letters</th>\n",
       "      <th>places</th>\n",
       "      <th>first_person</th>\n",
       "      <th>second_person</th>\n",
       "      <th>third_person</th>\n",
       "      <th>witness</th>\n",
       "      <th>rumor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.903344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.467367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.373118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.889709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.726617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.887140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.779477</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.803285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.644521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.715541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.956087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.813424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88758</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88759</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88761</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.677010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88762</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88764</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88765</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88766</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88767</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.594648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88768</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.845519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88769</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88771</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.696073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88774</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.908807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88777</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88778</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.791838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.699962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.847822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.854755</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88784</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88785</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88786</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.822440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.745923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88788 rows  54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       favourite_count  tweet_age  retweet_count  mentions  \\\n",
       "0                  0.0   0.119087            0.0       0.0   \n",
       "1                  0.0   0.030938            0.0       0.0   \n",
       "2                  0.0   0.527240            0.0       0.0   \n",
       "3                  0.0   0.014294            0.0       0.0   \n",
       "4                  0.0   0.903344            0.0       0.1   \n",
       "5                  0.0   0.135985            0.0       0.0   \n",
       "6                  0.0   0.373118            0.0       0.1   \n",
       "7                  0.0   0.607125            0.0       0.1   \n",
       "8                  0.0   0.756259            0.0       0.0   \n",
       "9                  0.0   0.503501            0.0       0.0   \n",
       "10                 0.0   0.726617            0.0       0.1   \n",
       "11                 0.0   0.921156            0.0       0.0   \n",
       "12                 0.0   0.929386            0.0       0.0   \n",
       "13                 0.0   0.803285            0.0       0.2   \n",
       "14                 0.0   0.144122            0.0       0.2   \n",
       "15                 0.0   0.077536            0.0       0.2   \n",
       "16                 0.0   0.715541            0.0       0.0   \n",
       "17                 0.0   0.956087            0.0       0.0   \n",
       "18                 0.0   0.167872            0.0       0.0   \n",
       "19                 0.0   0.941296            0.0       0.1   \n",
       "20                 0.0   0.257515            0.0       0.0   \n",
       "21                 0.0   0.036181            0.0       0.0   \n",
       "22                 0.0   0.126228            0.0       0.0   \n",
       "23                 0.0   0.951851            0.0       0.1   \n",
       "24                 0.0   0.623653            0.0       0.0   \n",
       "25                 0.0   0.072605            0.0       0.0   \n",
       "26                 0.0   0.461116            0.0       0.0   \n",
       "27                 0.0   0.733782            0.0       0.0   \n",
       "28                 0.0   0.248568            0.0       0.0   \n",
       "29                 0.0   0.002523            0.0       0.2   \n",
       "...                ...        ...            ...       ...   \n",
       "88758              0.0   0.336578            0.0       0.0   \n",
       "88759              0.0   0.312585            0.0       0.0   \n",
       "88760              0.0   0.103740            0.0       0.1   \n",
       "88761              0.0   0.677010            0.0       0.0   \n",
       "88762              0.0   0.702485            0.0       0.0   \n",
       "88763              0.0   0.020764            0.0       0.0   \n",
       "88764              0.0   0.208752            0.0       0.0   \n",
       "88765              0.0   0.816190            0.0       0.0   \n",
       "88766              0.0   0.874466            0.0       0.0   \n",
       "88767              0.0   0.594648            0.0       0.0   \n",
       "88768              0.0   0.845519            0.0       0.0   \n",
       "88769              0.0   0.433315            0.0       0.0   \n",
       "88770              0.0   0.982963            0.0       0.1   \n",
       "88771              0.0   0.107906            0.0       0.0   \n",
       "88772              0.0   0.955532            0.0       0.0   \n",
       "88773              0.0   0.696073            0.0       0.0   \n",
       "88774              0.0   0.315802            0.0       0.0   \n",
       "88775              0.0   0.087304            0.0       0.0   \n",
       "88776              0.0   0.714939            0.0       0.2   \n",
       "88777              0.0   0.777810            0.0       0.1   \n",
       "88778              0.0   0.791838            0.0       0.2   \n",
       "88779              0.0   0.079110            0.0       0.0   \n",
       "88780              0.0   0.645343            0.0       0.0   \n",
       "88781              0.0   0.699962            0.0       0.0   \n",
       "88782              0.0   0.538837            0.0       0.0   \n",
       "88783              0.0   0.847822            0.0       0.0   \n",
       "88784              0.0   0.296323            0.0       0.0   \n",
       "88785              0.0   0.107467            0.0       0.0   \n",
       "88786              0.0   0.822440            0.0       0.0   \n",
       "88787              0.0   0.745923            0.0       0.0   \n",
       "\n",
       "       retweet_per_second  favoutire_per_second  retweet_per_follower  \\\n",
       "0                     0.0                   0.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "5                     0.0                   0.0                   0.0   \n",
       "6                     0.0                   0.0                   0.0   \n",
       "7                     0.0                   0.0                   0.0   \n",
       "8                     0.0                   0.0                   0.0   \n",
       "9                     0.0                   0.0                   0.0   \n",
       "10                    0.0                   0.0                   0.0   \n",
       "11                    0.0                   0.0                   0.0   \n",
       "12                    0.0                   0.0                   0.0   \n",
       "13                    0.0                   0.0                   0.0   \n",
       "14                    0.0                   0.0                   0.0   \n",
       "15                    0.0                   0.0                   0.0   \n",
       "16                    0.0                   0.0                   0.0   \n",
       "17                    0.0                   0.0                   0.0   \n",
       "18                    0.0                   0.0                   0.0   \n",
       "19                    0.0                   0.0                   0.0   \n",
       "20                    0.0                   0.0                   0.0   \n",
       "21                    0.0                   0.0                   0.0   \n",
       "22                    0.0                   0.0                   0.0   \n",
       "23                    0.0                   0.0                   0.0   \n",
       "24                    0.0                   0.0                   0.0   \n",
       "25                    0.0                   0.0                   0.0   \n",
       "26                    0.0                   0.0                   0.0   \n",
       "27                    0.0                   0.0                   0.0   \n",
       "28                    0.0                   0.0                   0.0   \n",
       "29                    0.0                   0.0                   0.0   \n",
       "...                   ...                   ...                   ...   \n",
       "88758                 0.0                   0.0                   0.0   \n",
       "88759                 0.0                   0.0                   0.0   \n",
       "88760                 0.0                   0.0                   0.0   \n",
       "88761                 0.0                   0.0                   0.0   \n",
       "88762                 0.0                   0.0                   0.0   \n",
       "88763                 0.0                   0.0                   0.0   \n",
       "88764                 0.0                   0.0                   0.0   \n",
       "88765                 0.0                   0.0                   0.0   \n",
       "88766                 0.0                   0.0                   0.0   \n",
       "88767                 0.0                   0.0                   0.0   \n",
       "88768                 0.0                   0.0                   0.0   \n",
       "88769                 0.0                   0.0                   0.0   \n",
       "88770                 0.0                   0.0                   0.0   \n",
       "88771                 0.0                   0.0                   0.0   \n",
       "88772                 0.0                   0.0                   0.0   \n",
       "88773                 0.0                   0.0                   0.0   \n",
       "88774                 0.0                   0.0                   0.0   \n",
       "88775                 0.0                   0.0                   0.0   \n",
       "88776                 0.0                   0.0                   0.0   \n",
       "88777                 0.0                   0.0                   0.0   \n",
       "88778                 0.0                   0.0                   0.0   \n",
       "88779                 0.0                   0.0                   0.0   \n",
       "88780                 0.0                   0.0                   0.0   \n",
       "88781                 0.0                   0.0                   0.0   \n",
       "88782                 0.0                   0.0                   0.0   \n",
       "88783                 0.0                   0.0                   0.0   \n",
       "88784                 0.0                   0.0                   0.0   \n",
       "88785                 0.0                   0.0                   0.0   \n",
       "88786                 0.0                   0.0                   0.0   \n",
       "88787                 0.0                   0.0                   0.0   \n",
       "\n",
       "       favourite_per_follower  profile_age  profile_description  ...    \\\n",
       "0                         0.0     0.032778                  1.0  ...     \n",
       "1                         0.0     0.072293                  1.0  ...     \n",
       "2                         0.0     0.457262                  1.0  ...     \n",
       "3                         0.0     0.250639                  0.0  ...     \n",
       "4                         0.0     0.437794                  1.0  ...     \n",
       "5                         0.0     0.467367                  1.0  ...     \n",
       "6                         0.0     0.889709                  1.0  ...     \n",
       "7                         0.0     0.547842                  1.0  ...     \n",
       "8                         0.0     0.650494                  1.0  ...     \n",
       "9                         0.0     0.543779                  1.0  ...     \n",
       "10                        0.0     0.612056                  1.0  ...     \n",
       "11                        0.0     0.887140                  1.0  ...     \n",
       "12                        0.0     0.779477                  1.0  ...     \n",
       "13                        0.0     0.984942                  0.0  ...     \n",
       "14                        0.0     0.881063                  1.0  ...     \n",
       "15                        0.0     0.644521                  1.0  ...     \n",
       "16                        0.0     0.318812                  1.0  ...     \n",
       "17                        0.0     0.363442                  1.0  ...     \n",
       "18                        0.0     0.678700                  1.0  ...     \n",
       "19                        0.0     0.474045                  1.0  ...     \n",
       "20                        0.0     0.817868                  1.0  ...     \n",
       "21                        0.0     0.016551                  1.0  ...     \n",
       "22                        0.0     0.578375                  1.0  ...     \n",
       "23                        0.0     0.149585                  0.0  ...     \n",
       "24                        0.0     0.137895                  0.0  ...     \n",
       "25                        0.0     0.917453                  1.0  ...     \n",
       "26                        0.0     0.724661                  1.0  ...     \n",
       "27                        0.0     0.813424                  1.0  ...     \n",
       "28                        0.0     0.710379                  1.0  ...     \n",
       "29                        0.0     0.999583                  1.0  ...     \n",
       "...                       ...          ...                  ...  ...     \n",
       "88758                     0.0     0.679661                  1.0  ...     \n",
       "88759                     0.0     0.026088                  1.0  ...     \n",
       "88760                     0.0     0.127571                  1.0  ...     \n",
       "88761                     0.0     0.703376                  0.0  ...     \n",
       "88762                     0.0     0.897175                  1.0  ...     \n",
       "88763                     0.0     0.033530                  0.0  ...     \n",
       "88764                     0.0     0.113601                  1.0  ...     \n",
       "88765                     0.0     0.548039                  1.0  ...     \n",
       "88766                     0.0     0.534427                  1.0  ...     \n",
       "88767                     0.0     0.030440                  1.0  ...     \n",
       "88768                     0.0     0.882695                  0.0  ...     \n",
       "88769                     0.0     0.875253                  1.0  ...     \n",
       "88770                     0.0     0.946411                  1.0  ...     \n",
       "88771                     0.0     0.795194                  1.0  ...     \n",
       "88772                     0.0     0.665181                  0.0  ...     \n",
       "88773                     0.0     0.886029                  1.0  ...     \n",
       "88774                     0.0     0.428616                  1.0  ...     \n",
       "88775                     0.0     0.908807                  1.0  ...     \n",
       "88776                     0.0     0.163520                  1.0  ...     \n",
       "88777                     0.0     0.500318                  0.0  ...     \n",
       "88778                     0.0     0.823343                  0.0  ...     \n",
       "88779                     0.0     0.892001                  1.0  ...     \n",
       "88780                     0.0     0.630632                  1.0  ...     \n",
       "88781                     0.0     0.669140                  0.0  ...     \n",
       "88782                     0.0     0.037454                  1.0  ...     \n",
       "88783                     0.0     0.854755                  1.0  ...     \n",
       "88784                     0.0     0.145245                  1.0  ...     \n",
       "88785                     0.0     0.868957                  1.0  ...     \n",
       "88786                     0.0     0.582252                  1.0  ...     \n",
       "88787                     0.0     0.240663                  1.0  ...     \n",
       "\n",
       "       polarity  positive_words  negative_words  uppercase_letters  places  \\\n",
       "0      0.500000             0.0             0.0           0.051282     0.0   \n",
       "1      0.450000             0.0             0.0           0.085470     0.0   \n",
       "2      0.593750             0.0             0.0           0.068376     0.0   \n",
       "3      0.500000             0.0             0.0           0.008547     0.0   \n",
       "4      0.500000             0.0             0.0           0.068376     0.0   \n",
       "5      0.500000             0.0             0.0           0.000000     0.0   \n",
       "6      0.890625             0.0             0.0           0.376068     0.0   \n",
       "7      0.722222             0.0             0.0           0.051282     0.0   \n",
       "8      0.525000             0.0             0.0           0.034188     0.0   \n",
       "9      0.500000             0.0             0.0           0.042735     0.0   \n",
       "10     0.500000             0.0             0.0           0.094017     0.0   \n",
       "11     0.500000             0.0             0.0           0.042735     0.0   \n",
       "12     0.500000             0.0             0.0           0.008547     0.0   \n",
       "13     0.900000             0.0             0.0           0.025641     0.0   \n",
       "14     0.700000             0.0             0.0           0.119658     0.0   \n",
       "15     1.000000             0.0             0.0           0.136752     0.0   \n",
       "16     0.656250             0.0             0.0           0.025641     0.0   \n",
       "17     0.100000             0.0             0.0           0.042735     0.0   \n",
       "18     0.500000             0.0             0.0           0.136752     0.0   \n",
       "19     0.500000             0.0             0.0           0.102564     0.0   \n",
       "20     0.650000             0.0             0.0           0.059829     0.0   \n",
       "21     0.500000             0.0             0.0           0.068376     0.0   \n",
       "22     0.593750             0.0             0.0           0.059829     0.0   \n",
       "23     0.550000             0.0             0.0           0.111111     0.0   \n",
       "24     0.500000             0.0             0.0           0.025641     0.0   \n",
       "25     0.800000             0.0             0.0           0.034188     0.0   \n",
       "26     0.100000             0.0             0.0           0.085470     0.0   \n",
       "27     0.600000             0.0             0.0           0.025641     0.0   \n",
       "28     0.500000             0.0             0.0           0.051282     0.0   \n",
       "29     0.100000             0.0             0.0           0.230769     0.2   \n",
       "...         ...             ...             ...                ...     ...   \n",
       "88758  0.684091             0.0             0.0           0.085470     0.0   \n",
       "88759  0.500000             0.0             0.0           0.025641     0.0   \n",
       "88760  0.500000             0.0             0.0           0.025641     0.0   \n",
       "88761  0.500000             0.0             0.0           0.034188     0.0   \n",
       "88762  0.516667             0.0             0.0           0.068376     0.0   \n",
       "88763  0.475000             0.0             0.0           0.051282     0.0   \n",
       "88764  0.700000             0.0             0.0           0.076923     0.0   \n",
       "88765  0.500000             0.0             0.0           0.025641     0.0   \n",
       "88766  0.484091             0.0             0.0           0.153846     0.0   \n",
       "88767  0.765104             0.0             0.0           0.085470     0.2   \n",
       "88768  0.625000             0.0             0.0           0.042735     0.0   \n",
       "88769  0.672727             0.0             0.0           0.051282     0.0   \n",
       "88770  0.437500             0.0             0.0           0.051282     0.0   \n",
       "88771  0.425000             0.0             0.0           0.085470     0.0   \n",
       "88772  0.750000             0.0             0.0           0.068376     0.0   \n",
       "88773  0.742614             0.0             0.0           0.068376     0.0   \n",
       "88774  0.375000             0.0             0.0           0.119658     0.2   \n",
       "88775  0.459375             0.0             0.0           0.008547     0.0   \n",
       "88776  0.500000             0.0             0.0           0.025641     0.0   \n",
       "88777  0.500000             0.0             0.0           0.059829     0.0   \n",
       "88778  0.350000             0.0             0.0           0.170940     0.0   \n",
       "88779  0.500000             0.0             0.0           0.034188     0.0   \n",
       "88780  0.500000             0.0             0.0           0.017094     0.0   \n",
       "88781  0.789286             0.0             0.0           0.042735     0.0   \n",
       "88782  0.575000             0.0             0.0           0.025641     0.0   \n",
       "88783  0.172412             0.0             0.0           0.000000     0.0   \n",
       "88784  0.500000             0.0             0.0           0.034188     0.0   \n",
       "88785  0.531250             0.0             0.0           0.017094     0.0   \n",
       "88786  0.750000             0.0             0.0           0.068376     0.0   \n",
       "88787  0.500000             0.0             0.0           0.076923     0.0   \n",
       "\n",
       "       first_person  second_person  third_person   witness  rumor  \n",
       "0               0.0       0.000000          0.00  0.000000    1.0  \n",
       "1               0.0       0.000000          0.00  0.000000    1.0  \n",
       "2               0.4       0.000000          0.00  0.000000    0.0  \n",
       "3               0.0       0.000000          0.00  0.000000    1.0  \n",
       "4               0.0       0.000000          0.00  0.000000    1.0  \n",
       "5               0.0       0.000000          0.00  0.000000    0.0  \n",
       "6               0.0       0.000000          0.00  0.000000    1.0  \n",
       "7               0.0       0.000000          0.00  0.000000    0.0  \n",
       "8               0.0       0.000000          0.00  0.000000    1.0  \n",
       "9               0.0       0.000000          0.00  0.000000    0.0  \n",
       "10              0.0       0.000000          0.50  0.000000    1.0  \n",
       "11              0.0       0.000000          0.25  0.000000    1.0  \n",
       "12              0.4       0.000000          0.25  0.000000    1.0  \n",
       "13              0.0       0.000000          0.00  0.000000    1.0  \n",
       "14              0.0       0.000000          0.00  0.000000    0.0  \n",
       "15              0.0       0.000000          0.00  0.000000    0.0  \n",
       "16              0.0       0.000000          0.00  0.000000    0.0  \n",
       "17              0.0       0.000000          0.00  0.000000    0.0  \n",
       "18              0.0       0.000000          0.00  0.000000    0.0  \n",
       "19              0.0       0.000000          0.00  0.000000    0.0  \n",
       "20              0.0       0.000000          0.00  0.000000    0.0  \n",
       "21              0.0       0.000000          0.00  0.000000    0.0  \n",
       "22              0.0       0.000000          0.00  0.000000    1.0  \n",
       "23              0.0       0.000000          0.00  0.000000    0.0  \n",
       "24              0.4       0.000000          0.00  0.333333    1.0  \n",
       "25              0.0       0.000000          0.00  0.000000    0.0  \n",
       "26              0.0       0.000000          0.00  0.000000    0.0  \n",
       "27              0.0       0.000000          0.25  0.000000    1.0  \n",
       "28              0.0       0.000000          0.00  0.000000    0.0  \n",
       "29              0.0       0.000000          0.00  0.000000    0.0  \n",
       "...             ...            ...           ...       ...    ...  \n",
       "88758           0.4       0.000000          0.00  0.000000    0.0  \n",
       "88759           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88760           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88761           0.0       0.666667          0.25  0.000000    1.0  \n",
       "88762           0.0       0.333333          0.00  0.000000    0.0  \n",
       "88763           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88764           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88765           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88766           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88767           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88768           0.0       0.000000          0.25  0.000000    1.0  \n",
       "88769           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88770           0.0       0.666667          0.00  0.000000    1.0  \n",
       "88771           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88772           0.0       0.333333          0.00  0.000000    1.0  \n",
       "88773           0.0       0.000000          0.25  0.000000    1.0  \n",
       "88774           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88775           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88776           0.8       0.666667          0.00  0.000000    1.0  \n",
       "88777           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88778           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88779           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88780           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88781           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88782           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88783           0.0       0.000000          0.25  0.000000    1.0  \n",
       "88784           0.0       0.000000          0.00  0.000000    0.0  \n",
       "88785           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88786           0.0       0.000000          0.00  0.000000    1.0  \n",
       "88787           0.0       0.000000          0.00  0.000000    1.0  \n",
       "\n",
       "[88788 rows x 54 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=X.loc[X['rumor'] == 0.0]\n",
    "b=X.loc[X['rumor'] == 1.0]\n",
    "a=a[0:len(b)]\n",
    "X=pd.concat([a,b])\n",
    "X = shuffle(X)\n",
    "X= X.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44394"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rumor Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desicion Tree Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [ 2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'max_features': ['auto', 'sqrt']},\n",
       "       pre_dispatch=8, refit='accuracy', return_train_score='warn',\n",
       "       scoring={'f1': 'f1', 'accuracy': 'accuracy', 'precision': 'precision', 'recall': 'recall'},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    " \n",
    "# Define multiple metrics to be stored during the GridSearch\n",
    "scoring = {'accuracy':'accuracy','precision':'precision', 'f1':'f1', 'recall':'recall'}\n",
    "\n",
    "# Random search of parameters, using 5 fold cross validation\n",
    "dt_random_truth = GridSearchCV(estimator=dt, param_grid=random_grid, cv=5, scoring= scoring, \n",
    "                               pre_dispatch=8, refit='accuracy')\n",
    "\n",
    "# Fit the random search model\n",
    "dt_random_truth.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_truth_dt = open('dt_truth_29_08.pkl', 'wb')\n",
    "\n",
    "pickle.dump(dt_random_truth.cv_results_, output_truth_dt)\n",
    "\n",
    "output_truth_dt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 40)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [ 2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Define multiple metrics to be stored during the GridSearch\n",
    "scoring = {'accuracy':'accuracy','precision':'precision', 'f1':'f1', 'recall':'recall'}\n",
    "\n",
    "# Random search of parameters, using 5 fold cross validation \n",
    "rf_random_truth = GridSearchCV(estimator=rf, param_grid=random_grid, cv=5, scoring= scoring, \n",
    "                               pre_dispatch=8, refit='accuracy')\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random_truth.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_truth_rf = open('rf_truth_29_08.pkl', 'wb')\n",
    "\n",
    "pickle.dump(rf_random_truth.cv_results_, output_truth_rf)\n",
    "\n",
    "output_truth_rf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the values of C in logarithmic progression\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Exploring the values of Gamma in logarithmic progression\n",
    "gammas = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "# Exploring the most suitable kernel\n",
    "kernel = ['rbf', 'linear']\n",
    "\n",
    "param_grid = {'C': Cs, 'gamma' : gammas, 'kernel': kernel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "svm = SVC(random_state = 42)\n",
    "\n",
    "# Define multiple performance metrics to be stored in the GridSearch\n",
    "scoring = {'accuracy':'accuracy','precision':'precision', 'f1':'f1', 'recall':'recall'}\n",
    "\n",
    "# Random search of parameters, using 5 fold cross validation \n",
    "grid_search_truth_svm = GridSearchCV(estimator=svm, param_grid=random_grid, cv=5, scoring= scoring, \n",
    "                                     pre_dispatch=8, refit='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search_truth_svm.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_truth_svm = open('rf_truth_29_08.pkl', 'wb')\n",
    "\n",
    "pickle.dump(grid_search_truth_svm.cv_results_, output_truth_svm)\n",
    "\n",
    "output_truth_svm.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humanitarian Relevancy Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv('generic_text_all.csv',sep='\\t', header=None, index_col=False, lineterminator='\\n')\n",
    "X1 = X1.drop(0,axis=1)\n",
    "X1 = X1.drop(0)\n",
    "X1 = X1.reset_index(drop=True)\n",
    "X1['crisis'] = 0.0 \n",
    "\n",
    "X2 = pd.read_csv('humanitarian_text.csv',sep='\\t', header=None, index_col=False, lineterminator='\\n')\n",
    "X2 = X2.drop(0,axis=1)\n",
    "X2 = X2.reset_index(drop=True)\n",
    "X2['crisis'] = 1.0\n",
    "\n",
    "X=pd.concat([X1, X2])\n",
    "X = shuffle(X)\n",
    "X= X.reset_index(drop=True)\n",
    "\n",
    "y = X['crisis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>crisis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Humans &amp; Non-Humans alike:  Watch District-9, ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@narendramodi This is not only the Peshawar At...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @350: Cyclone Pam first category 5 tropical...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Link: Iranian Protesters Rout Riot Police On V...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here's a nice diagnostic site that tells you i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thinks that everyone should see 'Charlie Wilso...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video apparently from today's protest#iranelec...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is Lady Gaga a Hermaphrodite?: Footage of Lady...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jaycee dugard photos, ataris pallidipennis sta...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @PMOIndia: PM @narendramodi reviewing the f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @MaheenUsmani: Thank you #India: #IndiaWith...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @seemagoswami: I wish all those who routine...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>No bird testing in Durham for West Nile virus....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NEWS: UK Gamers Earn Free Sony PSP Go | buildb...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT @ANI_news: Indian Airforce distributes reli...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>And Ebola has been trending for a week now *sigh*</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RT @marvi_memon: Todays's flood issues resolut...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Really upset that this flash flood warning wok...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Heard Kayne West wants to inherit the title \"K...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @JillStanek George Tiller has been found NO...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Komedie over incestvader Fritzl in Weens theat...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ridiculous! RT @eaterny: Japanese BBQ chain Gy...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>o psp GO ..  mais maneiro que o slim -&amp;gt; ht...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Slate: The Ebola Dilemma Expands: Slate asks t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RT @TehranBureau AN gets sworn in-Clashes &amp; Pr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NEWS: PS4 e Xbox 720, solo fantasie notturne h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I don't apply the stuff often, fortunately. I ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The manbirdpig virus will lead to a hamdemic o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PETA Has Some Words For Obama Over Fly Killing...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RT @timesofindia: Quake: More than 20 dead, do...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281238</th>\n",
       "      <td>...lady gaga is a hermaphrodite? k. still love...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281239</th>\n",
       "      <td>@deporitaz haha, very true. I'm still convince...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281240</th>\n",
       "      <td>Baseball players to be educated on West Nile V...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281241</th>\n",
       "      <td>RT @SarfarazA_54: We are united, we are tall, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281242</th>\n",
       "      <td>RT @btsdiary: [!!!]ARMYs,let's Pray for Philip...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281243</th>\n",
       "      <td>Do we have to be politically correct all the t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281244</th>\n",
       "      <td>Fantastic summary of the issues surrounding th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281245</th>\n",
       "      <td>Swine Flu may have originated in pigs - Now a ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281246</th>\n",
       "      <td>RT @_fawadakhan_: Killing innocent children is...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281247</th>\n",
       "      <td>fact or fiction: is Lady Gaga a hermaphrodite?...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281248</th>\n",
       "      <td>http://bit.ly/LuU3r\\n He's behind you, he's go...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281249</th>\n",
       "      <td>RT @PIB_India: PM Shri @narendramodi chairs hi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281250</th>\n",
       "      <td>Pro-life or pro-choice?  A powerful article ab...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281251</th>\n",
       "      <td>RT @CNN: Tropical Cyclone Pam destroyed many h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281252</th>\n",
       "      <td>Video of an Elephant painting a picture -AMAZI...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281253</th>\n",
       "      <td>RT @savechildrenuk: Our thoughts are with the ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281254</th>\n",
       "      <td>Death toll from Nepal quake jumps to 449: poli...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281255</th>\n",
       "      <td>A fly landed on my TV screen at the same momen...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281256</th>\n",
       "      <td>When will ppl learn u don't get swine flu from...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281257</th>\n",
       "      <td>wow! just found out heath ledger died today - ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281258</th>\n",
       "      <td>RT @allenhartwig Swine Flu Terms of the Day: S...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281259</th>\n",
       "      <td>Swine flu leaves a bloody mark on pork trade h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281260</th>\n",
       "      <td>RT @UNICEF_Pakistan: Attacking children and th...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281261</th>\n",
       "      <td>Pretty incredible video coming out of Iran. Gu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281262</th>\n",
       "      <td>Charlie wilsons war. Good or bad?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281263</th>\n",
       "      <td>RT @thekiranbedi: Hallmark of clear headed lea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281264</th>\n",
       "      <td>New Nikon D300s and Nikon D3000 confirmed .. h...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281265</th>\n",
       "      <td>Lady GaGa is a hermaphrodite? Didn't see that ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281266</th>\n",
       "      <td>Check this video out -- CNN: Video Of Women Sh...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281267</th>\n",
       "      <td>RT @JunaidJamshedPK: Please tell everyone to r...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281268 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        1  crisis\n",
       "0       Humans & Non-Humans alike:  Watch District-9, ...     0.0\n",
       "1       @narendramodi This is not only the Peshawar At...     1.0\n",
       "2       RT @350: Cyclone Pam first category 5 tropical...     1.0\n",
       "3       Link: Iranian Protesters Rout Riot Police On V...     0.0\n",
       "4       Here's a nice diagnostic site that tells you i...     0.0\n",
       "5       thinks that everyone should see 'Charlie Wilso...     0.0\n",
       "6       video apparently from today's protest#iranelec...     0.0\n",
       "7       Is Lady Gaga a Hermaphrodite?: Footage of Lady...     0.0\n",
       "8       jaycee dugard photos, ataris pallidipennis sta...     0.0\n",
       "9       RT @PMOIndia: PM @narendramodi reviewing the f...     1.0\n",
       "10      RT @MaheenUsmani: Thank you #India: #IndiaWith...     1.0\n",
       "11      RT @seemagoswami: I wish all those who routine...     1.0\n",
       "12      No bird testing in Durham for West Nile virus....     0.0\n",
       "13      NEWS: UK Gamers Earn Free Sony PSP Go | buildb...     0.0\n",
       "14      RT @ANI_news: Indian Airforce distributes reli...     1.0\n",
       "15      And Ebola has been trending for a week now *sigh*     1.0\n",
       "16      RT @marvi_memon: Todays's flood issues resolut...     1.0\n",
       "17      Really upset that this flash flood warning wok...     1.0\n",
       "18      Heard Kayne West wants to inherit the title \"K...     0.0\n",
       "19      RT @JillStanek George Tiller has been found NO...     0.0\n",
       "20      Komedie over incestvader Fritzl in Weens theat...     0.0\n",
       "21      Ridiculous! RT @eaterny: Japanese BBQ chain Gy...     0.0\n",
       "22      o psp GO ..  mais maneiro que o slim -&gt; ht...     0.0\n",
       "23      Slate: The Ebola Dilemma Expands: Slate asks t...     1.0\n",
       "24      RT @TehranBureau AN gets sworn in-Clashes & Pr...     0.0\n",
       "25      NEWS: PS4 e Xbox 720, solo fantasie notturne h...     0.0\n",
       "26      I don't apply the stuff often, fortunately. I ...     0.0\n",
       "27      The manbirdpig virus will lead to a hamdemic o...     0.0\n",
       "28      PETA Has Some Words For Obama Over Fly Killing...     0.0\n",
       "29      RT @timesofindia: Quake: More than 20 dead, do...     1.0\n",
       "...                                                   ...     ...\n",
       "281238  ...lady gaga is a hermaphrodite? k. still love...     0.0\n",
       "281239  @deporitaz haha, very true. I'm still convince...     0.0\n",
       "281240  Baseball players to be educated on West Nile V...     0.0\n",
       "281241  RT @SarfarazA_54: We are united, we are tall, ...     1.0\n",
       "281242  RT @btsdiary: [!!!]ARMYs,let's Pray for Philip...     1.0\n",
       "281243  Do we have to be politically correct all the t...     0.0\n",
       "281244  Fantastic summary of the issues surrounding th...     0.0\n",
       "281245  Swine Flu may have originated in pigs - Now a ...     0.0\n",
       "281246  RT @_fawadakhan_: Killing innocent children is...     1.0\n",
       "281247  fact or fiction: is Lady Gaga a hermaphrodite?...     0.0\n",
       "281248  http://bit.ly/LuU3r\\n He's behind you, he's go...     0.0\n",
       "281249  RT @PIB_India: PM Shri @narendramodi chairs hi...     1.0\n",
       "281250  Pro-life or pro-choice?  A powerful article ab...     0.0\n",
       "281251  RT @CNN: Tropical Cyclone Pam destroyed many h...     1.0\n",
       "281252  Video of an Elephant painting a picture -AMAZI...     0.0\n",
       "281253  RT @savechildrenuk: Our thoughts are with the ...     1.0\n",
       "281254  Death toll from Nepal quake jumps to 449: poli...     1.0\n",
       "281255  A fly landed on my TV screen at the same momen...     0.0\n",
       "281256  When will ppl learn u don't get swine flu from...     0.0\n",
       "281257  wow! just found out heath ledger died today - ...     0.0\n",
       "281258  RT @allenhartwig Swine Flu Terms of the Day: S...     0.0\n",
       "281259  Swine flu leaves a bloody mark on pork trade h...     0.0\n",
       "281260  RT @UNICEF_Pakistan: Attacking children and th...     1.0\n",
       "281261  Pretty incredible video coming out of Iran. Gu...     0.0\n",
       "281262                  Charlie wilsons war. Good or bad?     0.0\n",
       "281263  RT @thekiranbedi: Hallmark of clear headed lea...     1.0\n",
       "281264  New Nikon D300s and Nikon D3000 confirmed .. h...     0.0\n",
       "281265  Lady GaGa is a hermaphrodite? Didn't see that ...     0.0\n",
       "281266  Check this video out -- CNN: Video Of Women Sh...     0.0\n",
       "281267  RT @JunaidJamshedPK: Please tell everyone to r...     1.0\n",
       "\n",
       "[281268 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.reset_index(drop=True)\n",
    "for i in range(len(a)):\n",
    "    \n",
    "    a[1][i]=ast.literal_eval(a[1][i])\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[]\n",
    "    \n",
    "for i in range(len(K)):\n",
    "    \n",
    "    t= ','.join(map(str, K[1][i]))\n",
    "        \n",
    "    text.append(t)\n",
    "    \n",
    "    \n",
    "K['text']=text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Unigram and a Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_process, ngram_range=(1, 2)).fit(X[1])\n",
    "messages_bow = bow_transformer.transform(X[1])\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<281268x270775 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3155218 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "fit = [True, False]\n",
    "\n",
    "parameters = {'alpha': a, 'fit_prior': fit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "scoring = {'accuracy':'accuracy','precision':'precision', 'f1':'f1', 'recall':'recall'}\n",
    "grid_search2 = GridSearchCV(mnb, parameters, cv=5, scoring=scoring, pre_dispatch= 8)\n",
    "grid_search2.fit(messages_tfidf,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = open('mnb_hre_29_08.pkl', 'wb')\n",
    "\n",
    "pickle.dump(grid_search2.cv_results_, output1)\n",
    "\n",
    "output1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 40)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'max_features': ['auto', 'sqrt']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    " \n",
    "# Define multiple metrics to be stored in the GridSearch\n",
    "scoring = {'accuracy':'accuracy','precision':'precision', 'f1':'f1', 'recall':'recall'}\n",
    "\n",
    "# Random search of parameters, using 5 fold cross validation\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, scoring=scoring, cv=5, pre_dispatch=8\n",
    "                              , n_jobs=16)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(messages_tfidf,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ccb8168e1f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dt_truth_same_sample_5fold.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_random' is not defined"
     ]
    }
   ],
   "source": [
    "output2 = open('dt_truth_same_sample_5fold.pkl', 'wb')\n",
    "\n",
    "pickle.dump(rf_random.cv_results_, output2)\n",
    "\n",
    "output2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read python dict back from the file\n",
    "pkl_file = open('results/svm_rumor_5fold_linguistic2.pkl', 'rb')\n",
    "mydict2 = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_f1'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_precision'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/dimitris/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_recall'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 496.87876887,  591.36361556,  484.10120821,  587.10541139,\n",
       "         456.65220141,  580.35890069,  483.10279565,  565.49063702,\n",
       "         456.72648382,  593.81479235,  456.36582923,  590.47594461,\n",
       "         469.20165706,  564.13853059,  451.79648547,  582.90207596,\n",
       "         464.23456736,  576.34170227,  438.69485259,  579.52377858,\n",
       "         461.09340901, 1540.46340666,  416.932055  , 1523.15541477,\n",
       "         411.47865605, 1513.38642626,  418.09693065, 1496.87660866,\n",
       "         415.31701827, 1495.58935041,  414.7242754 , 1486.33606963,\n",
       "         411.17833204, 1493.67574191,  414.54143391, 1488.577211  ,\n",
       "         419.24721112, 1503.15273528,  419.65059662, 1526.08064733,\n",
       "         459.12530007, 4536.96341391,  493.93917036, 4500.89226665,\n",
       "         508.18490252, 4546.66293955,  529.70216379, 4505.21037979,\n",
       "         598.78322449, 4473.07366714,  634.54929681, 4589.85563564,\n",
       "         687.03211212, 4513.26431746,  730.72265611, 4557.45153923,\n",
       "         777.51671844, 4580.08600311,  860.23315606, 4567.08709908,\n",
       "         840.92856503, 6413.98207374, 1306.1527586 , 6339.49154029,\n",
       "        1797.90322528, 6241.72287726, 2422.01803355, 6446.71016746,\n",
       "        2930.17527261, 6477.37623262, 3126.51363115, 6393.69328132,\n",
       "        3541.07517505, 6463.87992206, 4478.12322898, 6217.66490455,\n",
       "        4768.76542654, 6532.76739712, 5212.42952027, 6098.67865672]),\n",
       " 'mean_score_time': array([204.55554404, 114.91394238, 201.01222324, 108.66846395,\n",
       "        200.21282096, 106.6593946 , 199.92484803, 100.27105341,\n",
       "        199.18038578, 100.61867824, 199.02089982, 104.70840387,\n",
       "        198.99122944, 100.23481393, 196.91735415, 100.13278866,\n",
       "        196.44654098, 100.32233391, 195.55355864, 100.96425109,\n",
       "        199.27735538,  95.9192872 , 193.9462575 ,  99.08334408,\n",
       "        192.3237421 ,  96.82272773, 191.45994081,  96.45789804,\n",
       "        191.68173418,  95.79555607, 190.10608039,  97.61661553,\n",
       "        189.54745431,  95.88213954, 188.99153862,  98.3775569 ,\n",
       "        188.21930823,  99.27384944, 187.95103779, 100.14405727,\n",
       "        193.34586167,  85.25565915, 188.71255288,  90.21936126,\n",
       "        186.88810515,  93.36952906, 184.57949724,  86.97911363,\n",
       "        182.82519331,  90.34250851, 182.23468299,  91.7033319 ,\n",
       "        181.84261804,  88.18774819, 180.15507364,  89.73676734,\n",
       "        181.14716363,  97.72161231, 180.59755626,  95.89147859,\n",
       "        185.5065094 ,  97.5297627 , 182.17179365,  96.85288043,\n",
       "        179.94718213,  98.28381405, 183.69558492,  99.95549922,\n",
       "        181.12407613, 102.46503687, 178.6843946 , 103.08400426,\n",
       "        176.41619973,  95.68300223, 181.58167844,  92.63170815,\n",
       "        179.7771759 ,  86.81911283, 174.32807822,  71.72354298]),\n",
       " 'mean_test_accuracy': array([0.63809299, 0.6380592 , 0.64357796, 0.6380592 , 0.6494684 ,\n",
       "        0.6380592 , 0.65478443, 0.6380592 , 0.6571834 , 0.6380592 ,\n",
       "        0.65874893, 0.6380592 , 0.6600892 , 0.6380592 , 0.66113664,\n",
       "        0.6380592 , 0.66181241, 0.6380592 , 0.66276974, 0.6380592 ,\n",
       "        0.65182232, 0.6380592 , 0.66043835, 0.6380592 , 0.66364824,\n",
       "        0.6380592 , 0.66671172, 0.6380592 , 0.66987656, 0.6380592 ,\n",
       "        0.67191512, 0.6380592 , 0.6745844 , 0.6380592 , 0.67708474,\n",
       "        0.6380592 , 0.67940487, 0.6380592 , 0.68126323, 0.6380592 ,\n",
       "        0.66385097, 0.6380592 , 0.67211785, 0.6380592 , 0.67910078,\n",
       "        0.6380592 , 0.68307654, 0.6380592 , 0.68566698, 0.6380592 ,\n",
       "        0.68825742, 0.6380592 , 0.69081407, 0.6380592 , 0.69169257,\n",
       "        0.6380592 , 0.69299905, 0.6380592 , 0.69400144, 0.6380592 ,\n",
       "        0.67735505, 0.63807046, 0.68710862, 0.63807046, 0.69106186,\n",
       "        0.63807046, 0.69417038, 0.63807046, 0.69515025, 0.63807046,\n",
       "        0.69632157, 0.63807046, 0.69762806, 0.63807046, 0.69795468,\n",
       "        0.63807046, 0.69938505, 0.63807046, 0.69989188, 0.63807046]),\n",
       " 'mean_test_f1': array([0.63010976, 0.6300795 , 0.637095  , 0.6300795 , 0.64154609,\n",
       "        0.6300795 , 0.64449453, 0.6300795 , 0.64563739, 0.6300795 ,\n",
       "        0.64655241, 0.6300795 , 0.64738444, 0.6300795 , 0.64822671,\n",
       "        0.6300795 , 0.64876335, 0.6300795 , 0.64964522, 0.6300795 ,\n",
       "        0.64314768, 0.6300795 , 0.64858733, 0.6300795 , 0.65115816,\n",
       "        0.6300795 , 0.65422318, 0.6300795 , 0.65791754, 0.6300795 ,\n",
       "        0.66058466, 0.6300795 , 0.66398352, 0.6300795 , 0.66740019,\n",
       "        0.6300795 , 0.67064546, 0.6300795 , 0.67324537, 0.6300795 ,\n",
       "        0.65154115, 0.6300795 , 0.66105931, 0.6300795 , 0.67068282,\n",
       "        0.6300795 , 0.67616127, 0.6300795 , 0.67984075, 0.6300795 ,\n",
       "        0.68318981, 0.6300795 , 0.68652946, 0.6300795 , 0.68786877,\n",
       "        0.6300795 , 0.68982217, 0.6300795 , 0.69100877, 0.6300795 ,\n",
       "        0.66903432, 0.6300953 , 0.68254937, 0.6300953 , 0.68795497,\n",
       "        0.6300953 , 0.69212702, 0.6300953 , 0.69405886, 0.6300953 ,\n",
       "        0.69539917, 0.6300953 , 0.69674167, 0.6300953 , 0.69709803,\n",
       "        0.6300953 , 0.69868771, 0.6300953 , 0.69924589, 0.6300953 ]),\n",
       " 'mean_test_precision': array([0.64431935, 0.64428049, 0.64889067, 0.64428049, 0.65637915,\n",
       "        0.64428049, 0.66429977, 0.64428049, 0.66814629, 0.64428049,\n",
       "        0.67052859, 0.64428049, 0.67253087, 0.64428049, 0.67390506,\n",
       "        0.64428049, 0.67480558, 0.64428049, 0.67595553, 0.64428049,\n",
       "        0.65959387, 0.64428049, 0.67205096, 0.64428049, 0.67628434,\n",
       "        0.64428049, 0.67971156, 0.64428049, 0.68266132, 0.64428049,\n",
       "        0.68421996, 0.64428049, 0.68634864, 0.64428049, 0.68804842,\n",
       "        0.64428049, 0.6894903 , 0.64428049, 0.69062316, 0.64428049,\n",
       "        0.67633047, 0.64428049, 0.68414825, 0.64428049, 0.68875925,\n",
       "        0.64428049, 0.69125387, 0.64428049, 0.69270175, 0.64428049,\n",
       "        0.69448834, 0.64428049, 0.69618506, 0.64428049, 0.69651709,\n",
       "        0.64428049, 0.69704243, 0.64428049, 0.69784625, 0.64428049,\n",
       "        0.68676254, 0.64428894, 0.69266065, 0.64428894, 0.69494258,\n",
       "        0.64428894, 0.69678512, 0.64428894, 0.69657134, 0.64428894,\n",
       "        0.69752666, 0.64428894, 0.6987975 , 0.64428894, 0.69908422,\n",
       "        0.64428894, 0.70031831, 0.64428894, 0.70076053, 0.64428894]),\n",
       " 'mean_test_recall': array([0.61652476, 0.61650223, 0.62573771, 0.61650223, 0.62738208,\n",
       "        0.61650223, 0.62585034, 0.61650223, 0.62461143, 0.61650223,\n",
       "        0.62425102, 0.61650223, 0.62407082, 0.61650223, 0.62445376,\n",
       "        0.61650223, 0.62467901, 0.61650223, 0.62533225, 0.61650223,\n",
       "        0.62751723, 0.61650223, 0.62672884, 0.61650223, 0.62785512,\n",
       "        0.61650223, 0.63060323, 0.61650223, 0.63492814, 0.61650223,\n",
       "        0.63855476, 0.61650223, 0.64305987, 0.61650223, 0.64799297,\n",
       "        0.61650223, 0.65283597, 0.61650223, 0.65675542, 0.61650223,\n",
       "        0.62853088, 0.61650223, 0.63950083, 0.61650223, 0.65355679,\n",
       "        0.61650223, 0.66173357, 0.61650223, 0.66747759, 0.61650223,\n",
       "        0.67227553, 0.61650223, 0.67716358, 0.61650223, 0.67946119,\n",
       "        0.61650223, 0.68277245, 0.61650223, 0.68432671, 0.61650223,\n",
       "        0.65222778, 0.61652476, 0.67274857, 0.61652476, 0.68112808,\n",
       "        0.61652476, 0.68754787, 0.61652476, 0.69157994, 0.61652476,\n",
       "        0.69329189, 0.61652476, 0.694711  , 0.61652476, 0.69513898,\n",
       "        0.61652476, 0.69707618, 0.61652476, 0.69775195, 0.61652476]),\n",
       " 'mean_train_accuracy': array([0.63810143, 0.63805919, 0.6438905 , 0.63805919, 0.64984852,\n",
       "        0.63805919, 0.65541514, 0.63805919, 0.6581689 , 0.63805919,\n",
       "        0.66005259, 0.63805919, 0.6614351 , 0.63805919, 0.66258672,\n",
       "        0.63805919, 0.66347085, 0.63805919, 0.66436061, 0.63805919,\n",
       "        0.65212923, 0.63805919, 0.66141258, 0.63805919, 0.66505046,\n",
       "        0.63805919, 0.66885728, 0.63805919, 0.67210096, 0.63805919,\n",
       "        0.6751222 , 0.63805919, 0.6782983 , 0.63805919, 0.68124352,\n",
       "        0.63805919, 0.6837326 , 0.63805919, 0.68572329, 0.63805919,\n",
       "        0.66520532, 0.63805919, 0.67445207, 0.63805919, 0.68263448,\n",
       "        0.63805919, 0.6877872 , 0.63805919, 0.69180801, 0.63805919,\n",
       "        0.69556978, 0.63805919, 0.69866705, 0.63805919, 0.70095058,\n",
       "        0.63805919, 0.70323411, 0.63805919, 0.70516286, 0.63805919,\n",
       "        0.680182  , 0.63807609, 0.69192908, 0.63807609, 0.69824469,\n",
       "        0.63807609, 0.70328479, 0.63807609, 0.70724929, 0.63807609,\n",
       "        0.71088998, 0.63807609, 0.71404075, 0.63807609, 0.71673536,\n",
       "        0.63807609, 0.71962427, 0.63807609, 0.72246531, 0.63807609]),\n",
       " 'mean_train_f1': array([0.63012244, 0.63008461, 0.63747235, 0.63008461, 0.64186623,\n",
       "        0.63008461, 0.64515918, 0.63008461, 0.64669142, 0.63008461,\n",
       "        0.64787295, 0.63008461, 0.64881855, 0.63008461, 0.64974625,\n",
       "        0.63008461, 0.65053105, 0.63008461, 0.65142444, 0.63008461,\n",
       "        0.64350892, 0.63008461, 0.64962252, 0.63008461, 0.65265172,\n",
       "        0.63008461, 0.65654154, 0.63008461, 0.66031651, 0.63008461,\n",
       "        0.66402899, 0.63008461, 0.66794717, 0.63008461, 0.67167239,\n",
       "        0.63008461, 0.67501295, 0.63008461, 0.67769161, 0.63008461,\n",
       "        0.6530346 , 0.63008461, 0.66376968, 0.63008461, 0.67429388,\n",
       "        0.63008461, 0.68092736, 0.63008461, 0.68608002, 0.63008461,\n",
       "        0.69075667, 0.63008461, 0.69437105, 0.63008461, 0.69718727,\n",
       "        0.63008461, 0.70000323, 0.63008461, 0.70219621, 0.63008461,\n",
       "        0.67207393, 0.63010827, 0.68745825, 0.63010827, 0.69518133,\n",
       "        0.63010827, 0.70115283, 0.63010827, 0.70602996, 0.63010827,\n",
       "        0.71002608, 0.63010827, 0.71334203, 0.63010827, 0.71609611,\n",
       "        0.63010827, 0.71910096, 0.63010827, 0.7221612 , 0.63010827]),\n",
       " 'mean_train_precision': array([0.64432809, 0.64427971, 0.64917172, 0.64427971, 0.65684005,\n",
       "        0.64427971, 0.66495012, 0.64427971, 0.66915842, 0.64427971,\n",
       "        0.67194689, 0.64427971, 0.67393214, 0.64427971, 0.6754509 ,\n",
       "        0.64427971, 0.67654416, 0.64427971, 0.67753785, 0.64427971,\n",
       "        0.65986151, 0.64427971, 0.67306061, 0.64427971, 0.67773928,\n",
       "        0.64427971, 0.6819037 , 0.64427971, 0.68493334, 0.64427971,\n",
       "        0.68750359, 0.64427971, 0.69015064, 0.64427971, 0.69246177,\n",
       "        0.64427971, 0.69414874, 0.64427971, 0.69546269, 0.64427971,\n",
       "        0.67767085, 0.64427971, 0.68629094, 0.64427971, 0.69249109,\n",
       "        0.64427971, 0.69622656, 0.64427971, 0.69907462, 0.64427971,\n",
       "        0.70185584, 0.64427971, 0.70441557, 0.64427971, 0.70607239,\n",
       "        0.64427971, 0.70770794, 0.64427971, 0.70933305, 0.64427971,\n",
       "        0.6895556 , 0.64429229, 0.69758548, 0.64429229, 0.70231303,\n",
       "        0.64429229, 0.70622875, 0.64429229, 0.70898568, 0.64429229,\n",
       "        0.71215736, 0.64429229, 0.71508991, 0.64429229, 0.71771804,\n",
       "        0.64429229, 0.7204483 , 0.64429229, 0.7229563 , 0.64429229]),\n",
       " 'mean_train_recall': array([0.61653038, 0.61650223, 0.62618822, 0.61650223, 0.62756228,\n",
       "        0.61650223, 0.62651484, 0.61650223, 0.62568703, 0.61650223,\n",
       "        0.6254674 , 0.61650223, 0.62551246, 0.61650223, 0.62592918,\n",
       "        0.61650223, 0.62644727, 0.61650223, 0.62725256, 0.61650223,\n",
       "        0.62795085, 0.61650223, 0.62776501, 0.61650223, 0.6293587 ,\n",
       "        0.61650223, 0.63300222, 0.61650223, 0.6374116 , 0.61650223,\n",
       "        0.64210818, 0.61650223, 0.64713138, 0.61650223, 0.65209826,\n",
       "        0.61650223, 0.65690747, 0.61650223, 0.66081002, 0.61650223,\n",
       "        0.6301302 , 0.61650223, 0.64268258, 0.61650223, 0.65703136,\n",
       "        0.61650223, 0.66628937, 0.61650223, 0.67356513, 0.61650223,\n",
       "        0.68000744, 0.61650223, 0.68461392, 0.61650223, 0.68852774,\n",
       "        0.61650223, 0.69246972, 0.61650223, 0.69520657, 0.61650223,\n",
       "        0.6554602 , 0.61653601, 0.67762536, 0.61653601, 0.68819549,\n",
       "        0.61653601, 0.69615264, 0.61653601, 0.70310178, 0.61653601,\n",
       "        0.70791098, 0.61653601, 0.71160518, 0.61653601, 0.71448281,\n",
       "        0.61653601, 0.71776028, 0.61653601, 0.72137001, 0.61653601]),\n",
       " 'param_C': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.1, 0.1, 0.2, 0.2, 0.3, 0.3, 0.4, 0.4, 0.5, 0.5, 0.6,\n",
       "                    0.6, 0.7, 0.7, 0.8, 0.8, 0.9, 0.9, 1.0, 1.0, 0.1, 0.1,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.4, 0.4, 0.5, 0.5, 0.6, 0.6, 0.7,\n",
       "                    0.7, 0.8, 0.8, 0.9, 0.9, 1.0, 1.0, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.3, 0.3, 0.4, 0.4, 0.5, 0.5, 0.6, 0.6, 0.7, 0.7, 0.8,\n",
       "                    0.8, 0.9, 0.9, 1.0, 1.0, 0.1, 0.1, 0.2, 0.2, 0.3, 0.3,\n",
       "                    0.4, 0.4, 0.5, 0.5, 0.6, 0.6, 0.7, 0.7, 0.8, 0.8, 0.9,\n",
       "                    0.9, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear', 'rbf', 'linear', 'rbf', 'linear',\n",
       "                    'rbf', 'linear'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.2, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.2, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.3, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.3, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.4, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.4, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.6, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.6, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.7, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.7, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.8, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.8, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.9, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.9, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1.0, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1.0, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.2, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.2, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.3, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.3, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.4, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.4, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.6, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.6, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.7, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.7, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.8, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.8, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.9, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.9, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1.0, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1.0, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.2, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.2, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.3, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.3, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.4, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.4, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.6, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.6, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.7, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.7, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.8, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.8, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.9, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.9, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 1.0, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1.0, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.2, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.2, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.3, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.3, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.4, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.4, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.5, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.5, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.6, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.6, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.7, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.7, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.8, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.8, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.9, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.9, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 1.0, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1.0, 'kernel': 'linear'}],\n",
       " 'rank_test_accuracy': array([40, 51, 39, 51, 38, 51, 36, 51, 35, 51, 34, 51, 33, 51, 31, 51, 30,\n",
       "        51, 29, 51, 37, 51, 32, 51, 28, 51, 26, 51, 25, 51, 24, 51, 22, 51,\n",
       "        21, 51, 18, 51, 17, 51, 27, 51, 23, 51, 19, 51, 16, 51, 15, 51, 13,\n",
       "        51, 12, 51, 10, 51,  9, 51,  8, 51, 20, 41, 14, 41, 11, 41,  7, 41,\n",
       "         6, 41,  5, 41,  4, 41,  3, 41,  2, 41,  1, 41], dtype=int32),\n",
       " 'rank_test_f1': array([40, 51, 39, 51, 38, 51, 36, 51, 35, 51, 34, 51, 33, 51, 32, 51, 30,\n",
       "        51, 29, 51, 37, 51, 31, 51, 28, 51, 26, 51, 25, 51, 24, 51, 22, 51,\n",
       "        21, 51, 19, 51, 17, 51, 27, 51, 23, 51, 18, 51, 16, 51, 15, 51, 13,\n",
       "        51, 12, 51, 11, 51,  9, 51,  8, 51, 20, 41, 14, 41, 10, 41,  7, 41,\n",
       "         6, 41,  5, 41,  4, 41,  3, 41,  2, 41,  1, 41], dtype=int32),\n",
       " 'rank_test_precision': array([40, 51, 39, 51, 38, 51, 36, 51, 35, 51, 34, 51, 32, 51, 31, 51, 30,\n",
       "        51, 29, 51, 37, 51, 33, 51, 28, 51, 26, 51, 25, 51, 23, 51, 22, 51,\n",
       "        20, 51, 18, 51, 17, 51, 27, 51, 24, 51, 19, 51, 16, 51, 14, 51, 13,\n",
       "        51, 11, 51, 10, 51,  7, 51,  5, 51, 21, 41, 15, 41, 12, 41,  8, 41,\n",
       "         9, 41,  6, 41,  4, 41,  3, 41,  2, 41,  1, 41], dtype=int32),\n",
       " 'rank_test_recall': array([40, 51, 33, 51, 30, 51, 32, 51, 36, 51, 38, 51, 39, 51, 37, 51, 35,\n",
       "        51, 34, 51, 29, 51, 31, 51, 28, 51, 26, 51, 25, 51, 24, 51, 22, 51,\n",
       "        21, 51, 19, 51, 17, 51, 27, 51, 23, 51, 18, 51, 16, 51, 15, 51, 14,\n",
       "        51, 12, 51, 11, 51,  9, 51,  8, 51, 20, 40, 13, 40, 10, 40,  7, 40,\n",
       "         6, 40,  5, 40,  4, 40,  3, 40,  2, 40,  1, 40], dtype=int32),\n",
       " 'split0_test_accuracy': array([0.63948643, 0.63948643, 0.644273  , 0.63948643, 0.65029846,\n",
       "        0.63948643, 0.65553553, 0.63948643, 0.6585201 , 0.63948643,\n",
       "        0.65992792, 0.63948643, 0.66144836, 0.63948643, 0.6625183 ,\n",
       "        0.63948643, 0.66370087, 0.63948643, 0.66482712, 0.63948643,\n",
       "        0.65215677, 0.63948643, 0.66049105, 0.63948643, 0.66392612,\n",
       "        0.63948643, 0.66809325, 0.63948643, 0.67158464, 0.63948643,\n",
       "        0.67333033, 0.63948643, 0.67530127, 0.63948643, 0.67811691,\n",
       "        0.63948643, 0.68020047, 0.63948643, 0.68160829, 0.63948643,\n",
       "        0.66353193, 0.63948643, 0.67287983, 0.63948643, 0.68025679,\n",
       "        0.63948643, 0.68402973, 0.63948643, 0.68662011, 0.63948643,\n",
       "        0.6901115 , 0.63948643, 0.69258926, 0.63948643, 0.69377182,\n",
       "        0.63948643, 0.69450389, 0.63948643, 0.69512332, 0.63948643,\n",
       "        0.67800428, 0.63948643, 0.68740849, 0.63948643, 0.69275819,\n",
       "        0.63948643, 0.69489807, 0.63948643, 0.69517964, 0.63948643,\n",
       "        0.69670008, 0.63948643, 0.69805158, 0.63948643, 0.69912152,\n",
       "        0.63948643, 0.69962834, 0.63948643, 0.70007884, 0.63948643]),\n",
       " 'split0_test_f1': array([0.63287074, 0.63287074, 0.63937889, 0.63287074, 0.64379947,\n",
       "        0.63287074, 0.64672249, 0.63287074, 0.64838223, 0.63287074,\n",
       "        0.64903818, 0.63287074, 0.65005821, 0.63287074, 0.65106259,\n",
       "        0.63287074, 0.65242696, 0.63287074, 0.65359097, 0.63287074,\n",
       "        0.64481628, 0.63287074, 0.65031031, 0.63287074, 0.65310393,\n",
       "        0.63287074, 0.65716612, 0.63287074, 0.66100907, 0.63287074,\n",
       "        0.66341746, 0.63287074, 0.66608756, 0.63287074, 0.67012927,\n",
       "        0.63287074, 0.67311345, 0.63287074, 0.67524411, 0.63287074,\n",
       "        0.65263647, 0.63287074, 0.66322685, 0.63287074, 0.67341539,\n",
       "        0.63287074, 0.67876567, 0.63287074, 0.68292405, 0.63287074,\n",
       "        0.687134  , 0.63287074, 0.69041003, 0.63287074, 0.69221191,\n",
       "        0.63287074, 0.69313875, 0.63287074, 0.69384755, 0.63287074,\n",
       "        0.67149259, 0.63287074, 0.68469185, 0.63287074, 0.69178624,\n",
       "        0.63287074, 0.69441624, 0.63287074, 0.69560817, 0.63287074,\n",
       "        0.69673423, 0.63287074, 0.69839127, 0.63287074, 0.69974712,\n",
       "        0.63287074, 0.70020234, 0.63287074, 0.70068562, 0.63287074]),\n",
       " 'split0_test_precision': array([0.64470148, 0.64470148, 0.64829822, 0.64470148, 0.65599065,\n",
       "        0.64470148, 0.66370318, 0.64470148, 0.66822039, 0.64470148,\n",
       "        0.67050913, 0.64470148, 0.67269004, 0.64470148, 0.67393925,\n",
       "        0.64470148, 0.67505721, 0.64470148, 0.67626159, 0.64470148,\n",
       "        0.65871711, 0.64470148, 0.67041378, 0.64470148, 0.67483483,\n",
       "        0.64470148, 0.67953807, 0.64470148, 0.683003  , 0.64470148,\n",
       "        0.68417903, 0.64470148, 0.68554059, 0.64470148, 0.68718192,\n",
       "        0.64470148, 0.68836826, 0.64470148, 0.68901653, 0.64470148,\n",
       "        0.67447729, 0.64470148, 0.68339307, 0.64470148, 0.68813918,\n",
       "        0.64470148, 0.69026549, 0.64470148, 0.69107472, 0.64470148,\n",
       "        0.69380023, 0.64470148, 0.69533927, 0.64470148, 0.69575606,\n",
       "        0.64470148, 0.69625   , 0.64470148, 0.6967632 , 0.64470148,\n",
       "        0.68535241, 0.64470148, 0.69069448, 0.64470148, 0.69398164,\n",
       "        0.64470148, 0.69551463, 0.64470148, 0.69463163, 0.64470148,\n",
       "        0.69665578, 0.64470148, 0.69760647, 0.64470148, 0.6982952 ,\n",
       "        0.64470148, 0.69886682, 0.64470148, 0.69927089, 0.64470148]),\n",
       " 'split0_test_recall': array([0.62146638, 0.62146638, 0.63070166, 0.62146638, 0.63205316,\n",
       "        0.62146638, 0.63058903, 0.62146638, 0.62968803, 0.62146638,\n",
       "        0.62889965, 0.62146638, 0.62889965, 0.62146638, 0.62968803,\n",
       "        0.62146638, 0.63126478, 0.62146638, 0.63239104, 0.62146638,\n",
       "        0.63149003, 0.62146638, 0.63137741, 0.62146638, 0.63272891,\n",
       "        0.62146638, 0.6362203 , 0.62146638, 0.64038743, 0.62146638,\n",
       "        0.64387882, 0.62146638, 0.64770808, 0.62146638, 0.65390247,\n",
       "        0.62146638, 0.6585201 , 0.62146638, 0.66201149, 0.62146638,\n",
       "        0.63216578, 0.62146638, 0.64421669, 0.62146638, 0.65930848,\n",
       "        0.62146638, 0.66764275, 0.62146638, 0.6749634 , 0.62146638,\n",
       "        0.68059466, 0.62146638, 0.68555017, 0.62146638, 0.68870368,\n",
       "        0.62146638, 0.69005519, 0.62146638, 0.69095619, 0.62146638,\n",
       "        0.65818223, 0.62146638, 0.67879266, 0.62146638, 0.68960469,\n",
       "        0.62146638, 0.69332132, 0.62146638, 0.69658745, 0.62146638,\n",
       "        0.6968127 , 0.62146638, 0.69917784, 0.62146638, 0.70120509,\n",
       "        0.62146638, 0.70154297, 0.62146638, 0.70210609, 0.62146638]),\n",
       " 'split0_train_accuracy': array([0.63777277, 0.63770238, 0.6436013 , 0.63770238, 0.64971139,\n",
       "        0.63770238, 0.65513163, 0.63770238, 0.65813037, 0.63770238,\n",
       "        0.66017176, 0.63770238, 0.66146699, 0.63770238, 0.66267774,\n",
       "        0.63770238, 0.66356469, 0.63770238, 0.66438125, 0.63770238,\n",
       "        0.65199212, 0.63770238, 0.66177671, 0.63770238, 0.6651978 ,\n",
       "        0.63770238, 0.66899901, 0.63770238, 0.67306772, 0.63770238,\n",
       "        0.67586935, 0.63770238, 0.67891032, 0.63770238, 0.68216247,\n",
       "        0.63770238, 0.68458398, 0.63770238, 0.68652682, 0.63770238,\n",
       "        0.66528228, 0.63770238, 0.67532029, 0.63770238, 0.68341546,\n",
       "        0.63770238, 0.68820217, 0.63770238, 0.69186259, 0.63770238,\n",
       "        0.69604393, 0.63770238, 0.69888779, 0.63770238, 0.70146417,\n",
       "        0.63770238, 0.70392792, 0.63770238, 0.70536393, 0.63770238,\n",
       "        0.6812896 , 0.63773054, 0.69211601, 0.63773054, 0.69898634,\n",
       "        0.63773054, 0.70416725, 0.63773054, 0.70758834, 0.63773054,\n",
       "        0.7115585 , 0.63773054, 0.71451499, 0.63773054, 0.71731663,\n",
       "        0.63773054, 0.72003379, 0.63773054, 0.72289174, 0.63773054]),\n",
       " 'split0_train_f1': array([0.62944133, 0.62938533, 0.63681621, 0.62938533, 0.64139631,\n",
       "        0.62938533, 0.64447025, 0.62938533, 0.64605652, 0.62938533,\n",
       "        0.64737334, 0.62938533, 0.64816224, 0.62938533, 0.64909197,\n",
       "        0.62938533, 0.64993774, 0.62938533, 0.65069527, 0.62938533,\n",
       "        0.64302116, 0.62938533, 0.64931539, 0.62938533, 0.65219744,\n",
       "        0.62938533, 0.65603558, 0.62938533, 0.66080453, 0.62938533,\n",
       "        0.664422  , 0.62938533, 0.66836312, 0.62938533, 0.67267877,\n",
       "        0.62938533, 0.67585868, 0.62938533, 0.67850645, 0.62938533,\n",
       "        0.65247833, 0.62938533, 0.66423039, 0.62938533, 0.67489771,\n",
       "        0.62938533, 0.68115003, 0.62938533, 0.68601432, 0.62938533,\n",
       "        0.69093564, 0.62938533, 0.69410755, 0.62938533, 0.69735246,\n",
       "        0.62938533, 0.70035906, 0.62938533, 0.70201617, 0.62938533,\n",
       "        0.67320129, 0.62942481, 0.68736687, 0.62942481, 0.69578703,\n",
       "        0.62942481, 0.70180368, 0.62942481, 0.70591567, 0.62942481,\n",
       "        0.71011376, 0.62942481, 0.71334464, 0.62942481, 0.71617782,\n",
       "        0.62942481, 0.7189814 , 0.62942481, 0.72206611, 0.62942481]),\n",
       " 'split0_train_precision': array([0.64425969, 0.64417323, 0.64917515, 0.64417323, 0.65699185,\n",
       "        0.64417323, 0.6650292 , 0.64417323, 0.66970869, 0.64417323,\n",
       "        0.6727085 , 0.64417323, 0.67467788, 0.64417323, 0.67633145,\n",
       "        0.64417323, 0.67737405, 0.64417323, 0.67835757, 0.64417323,\n",
       "        0.66003558, 0.64417323, 0.67415356, 0.64417323, 0.67854534,\n",
       "        0.64417323, 0.68277605, 0.64417323, 0.6865572 , 0.64417323,\n",
       "        0.68874652, 0.64417323, 0.69106327, 0.64417323, 0.69336761,\n",
       "        0.64417323, 0.69508675, 0.64417323, 0.6963222 , 0.64417323,\n",
       "        0.6784303 , 0.64417323, 0.68772046, 0.64417323, 0.69355797,\n",
       "        0.64417323, 0.69691256, 0.64417323, 0.69928638, 0.64417323,\n",
       "        0.70274599, 0.64417323, 0.70530446, 0.64417323, 0.70709117,\n",
       "        0.64417323, 0.70890421, 0.64417323, 0.7100844 , 0.64417323,\n",
       "        0.69073081, 0.6441942 , 0.69813567, 0.6441942 , 0.70326162,\n",
       "        0.6441942 , 0.70745594, 0.6441942 , 0.70997693, 0.6441942 ,\n",
       "        0.71368846, 0.6441942 , 0.71628105, 0.6441942 , 0.71907465,\n",
       "        0.6441942 , 0.72169423, 0.6441942 , 0.72422388, 0.6441942 ]),\n",
       " 'split0_train_recall': array([0.61528931, 0.61526116, 0.62491905, 0.61526116, 0.626524  ,\n",
       "        0.61526116, 0.62514431, 0.61526116, 0.62401802, 0.61526116,\n",
       "        0.62387723, 0.61526116, 0.62365198, 0.61526116, 0.62396171,\n",
       "        0.61526116, 0.62463748, 0.61526116, 0.62520062, 0.61526116,\n",
       "        0.62686189, 0.61526116, 0.62624243, 0.61526116, 0.62781923,\n",
       "        0.61526116, 0.63131071, 0.61526116, 0.63691398, 0.61526116,\n",
       "        0.641757  , 0.61526116, 0.64710686, 0.61526116, 0.65318879,\n",
       "        0.61526116, 0.65766578, 0.61526116, 0.66157961, 0.61526116,\n",
       "        0.62843869, 0.61526116, 0.64229199, 0.61526116, 0.65721526,\n",
       "        0.61526116, 0.66608475, 0.61526116, 0.67323666, 0.61526116,\n",
       "        0.6795157 , 0.61526116, 0.68326059, 0.61526116, 0.68787836,\n",
       "        0.61526116, 0.69201746, 0.61526116, 0.69412924, 0.61526116,\n",
       "        0.65653949, 0.61531747, 0.67692524, 0.61531747, 0.68846966,\n",
       "        0.61531747, 0.69624102, 0.61531747, 0.70190061, 0.61531747,\n",
       "        0.70657469, 0.61531747, 0.71043221, 0.61531747, 0.71330424,\n",
       "        0.61531747, 0.71628889, 0.61531747, 0.71992116, 0.61531747]),\n",
       " 'split1_test_accuracy': array([0.63396779, 0.63396779, 0.63959905, 0.63396779, 0.64551188,\n",
       "        0.63396779, 0.6509179 , 0.63396779, 0.65243834, 0.63396779,\n",
       "        0.65339565, 0.63396779, 0.65463453, 0.63396779, 0.65609866,\n",
       "        0.63396779, 0.65677441, 0.63396779, 0.65773173, 0.63396779,\n",
       "        0.64759545, 0.63396779, 0.65604235, 0.63396779, 0.65953373,\n",
       "        0.63396779, 0.66144836, 0.63396779, 0.66488343, 0.63396779,\n",
       "        0.66764275, 0.63396779, 0.67107782, 0.63396779, 0.67378083,\n",
       "        0.63396779, 0.67665278, 0.63396779, 0.67851109, 0.63396779,\n",
       "        0.65919586, 0.63396779, 0.66809325, 0.63396779, 0.6749634 ,\n",
       "        0.63396779, 0.67901791, 0.63396779, 0.68042572, 0.63396779,\n",
       "        0.68279085, 0.63396779, 0.68667643, 0.63396779, 0.68774637,\n",
       "        0.63396779, 0.68960469, 0.63396779, 0.69044937, 0.63396779,\n",
       "        0.67282352, 0.63396779, 0.68239667, 0.63396779, 0.68667643,\n",
       "        0.63396779, 0.69129406, 0.63396779, 0.69185719, 0.63396779,\n",
       "        0.69382813, 0.63396779, 0.69619327, 0.63396779, 0.69670008,\n",
       "        0.63396779, 0.69760108, 0.63396779, 0.69771371, 0.63396779]),\n",
       " 'split1_test_f1': array([0.62613597, 0.62613597, 0.63361575, 0.62613597, 0.63832232,\n",
       "        0.62613597, 0.64144832, 0.62613597, 0.6420784 , 0.62613597,\n",
       "        0.64271202, 0.62613597, 0.64345096, 0.62613597, 0.64454921,\n",
       "        0.62613597, 0.64504106, 0.62613597, 0.64605171, 0.62613597,\n",
       "        0.63997239, 0.62613597, 0.64546088, 0.62613597, 0.64861095,\n",
       "        0.62613597, 0.65087108, 0.62613597, 0.65475431, 0.62613597,\n",
       "        0.65813253, 0.62613597, 0.66246749, 0.62613597, 0.6662057 ,\n",
       "        0.62613597, 0.66950616, 0.62613597, 0.67191541, 0.62613597,\n",
       "        0.64887445, 0.62613597, 0.65879356, 0.62613597, 0.66774119,\n",
       "        0.62613597, 0.6729401 , 0.62613597, 0.67543609, 0.62613597,\n",
       "        0.67824299, 0.62613597, 0.68321567, 0.62613597, 0.68481783,\n",
       "        0.62613597, 0.68742203, 0.62613597, 0.6885023 , 0.62613597,\n",
       "        0.66593836, 0.62613597, 0.67852257, 0.62613597, 0.68397137,\n",
       "        0.62613597, 0.69007237, 0.62613597, 0.69168357, 0.62613597,\n",
       "        0.69363836, 0.62613597, 0.69627878, 0.62613597, 0.69673423,\n",
       "        0.62613597, 0.69756702, 0.62613597, 0.69791784, 0.62613597]),\n",
       " 'split1_test_precision': array([0.63982603, 0.63982603, 0.64431249, 0.63982603, 0.65153648,\n",
       "        0.63982603, 0.65933413, 0.63982603, 0.66180514, 0.63982603,\n",
       "        0.66315285, 0.63982603, 0.66498438, 0.63982603, 0.66694772,\n",
       "        0.63982603, 0.66787265, 0.63982603, 0.66887737, 0.63982603,\n",
       "        0.65412207, 0.63982603, 0.66594802, 0.63982603, 0.67010928,\n",
       "        0.63982603, 0.67186189, 0.63982603, 0.67516152, 0.63982603,\n",
       "        0.67751938, 0.63982603, 0.68027534, 0.63982603, 0.68204342,\n",
       "        0.63982603, 0.68463802, 0.63982603, 0.6859892 , 0.63982603,\n",
       "        0.66913964, 0.63982603, 0.6777844 , 0.63982603, 0.68291534,\n",
       "        0.63982603, 0.68592818, 0.63982603, 0.6861492 , 0.63982603,\n",
       "        0.68810848, 0.63982603, 0.69084629, 0.63982603, 0.69130135,\n",
       "        0.63982603, 0.69229012, 0.63982603, 0.6928604 , 0.63982603,\n",
       "        0.68025373, 0.63982603, 0.68690133, 0.63982603, 0.68992781,\n",
       "        0.63982603, 0.69281417, 0.63982603, 0.69207351, 0.63982603,\n",
       "        0.69406856, 0.63982603, 0.69608285, 0.63982603, 0.69665578,\n",
       "        0.63982603, 0.6976456 , 0.63982603, 0.69744686, 0.63982603]),\n",
       " 'split1_test_recall': array([0.61301948, 0.61301948, 0.62326839, 0.61301948, 0.62563352,\n",
       "        0.61301948, 0.62450726, 0.61301948, 0.62349364, 0.61301948,\n",
       "        0.62349364, 0.61301948, 0.62326839, 0.61301948, 0.62360626,\n",
       "        0.61301948, 0.62371889, 0.61301948, 0.62473251, 0.61301948,\n",
       "        0.62642189, 0.61301948, 0.62619664, 0.61301948, 0.62844915,\n",
       "        0.61301948, 0.63115216, 0.61301948, 0.63554454, 0.61301948,\n",
       "        0.6398243 , 0.61301948, 0.64556819, 0.61301948, 0.65108683,\n",
       "        0.61301948, 0.65502872, 0.61301948, 0.65840748, 0.61301948,\n",
       "        0.62980065, 0.61301948, 0.64083793, 0.61301948, 0.65322671,\n",
       "        0.61301948, 0.66043473, 0.61301948, 0.66505237, 0.61301948,\n",
       "        0.66865638, 0.61301948, 0.67575177, 0.61301948, 0.67845478,\n",
       "        0.61301948, 0.68262192, 0.61301948, 0.68419867, 0.61301948,\n",
       "        0.65221309, 0.61301948, 0.67034576, 0.61301948, 0.67811691,\n",
       "        0.61301948, 0.68735218, 0.61301948, 0.69129406, 0.61301948,\n",
       "        0.69320869, 0.61301948, 0.69647483, 0.61301948, 0.6968127 ,\n",
       "        0.61301948, 0.69748846, 0.61301948, 0.69838946, 0.61301948]),\n",
       " 'split1_train_accuracy': array([0.63911024, 0.63908208, 0.6447135 , 0.63908208, 0.6502323 ,\n",
       "        0.63908208, 0.65577925, 0.63908208, 0.65874982, 0.63908208,\n",
       "        0.66069267, 0.63908208, 0.66198789, 0.63908208, 0.66331128,\n",
       "        0.63908208, 0.66415599, 0.63908208, 0.66524004, 0.63908208,\n",
       "        0.65237224, 0.63908208, 0.66190342, 0.63908208, 0.66595805,\n",
       "        0.63908208, 0.66997044, 0.63908208, 0.67313811, 0.63908208,\n",
       "        0.67634802, 0.63908208, 0.68005068, 0.63908208, 0.68272561,\n",
       "        0.63908208, 0.68490779, 0.63908208, 0.68665353, 0.63908208,\n",
       "        0.66600028, 0.63908208, 0.67536252, 0.63908208, 0.6837815 ,\n",
       "        0.63908208, 0.68841335, 0.63908208, 0.69276362, 0.63908208,\n",
       "        0.69648036, 0.63908208, 0.69991553, 0.63908208, 0.70230888,\n",
       "        0.63908208, 0.7045333 , 0.63908208, 0.70636351, 0.63908208,\n",
       "        0.6808954 , 0.63909616, 0.69265099, 0.63909616, 0.69885964,\n",
       "        0.63909616, 0.70405462, 0.63909616, 0.70770097, 0.63909616,\n",
       "        0.71134732, 0.63909616, 0.71504998, 0.63909616, 0.71726031,\n",
       "        0.63909616, 0.72024497, 0.63909616, 0.72272279, 0.63909616]),\n",
       " 'split1_train_f1': array([0.63110177, 0.63107299, 0.63818317, 0.63107299, 0.64214105,\n",
       "        0.63107299, 0.64591902, 0.63107299, 0.6477248 , 0.63107299,\n",
       "        0.6491389 , 0.63107299, 0.65005029, 0.63107299, 0.65112547,\n",
       "        0.63107299, 0.65193983, 0.63107299, 0.65310886, 0.63107299,\n",
       "        0.64363238, 0.63107299, 0.65060451, 0.63107299, 0.6541909 ,\n",
       "        0.63107299, 0.65851882, 0.63107299, 0.66235221, 0.63107299,\n",
       "        0.666328  , 0.63107299, 0.67076174, 0.63107299, 0.67415633,\n",
       "        0.63107299, 0.67724212, 0.63107299, 0.6797047 , 0.63107299,\n",
       "        0.65437063, 0.63107299, 0.66540912, 0.63107299, 0.67640576,\n",
       "        0.63107299, 0.68229451, 0.63107299, 0.68811365, 0.63107299,\n",
       "        0.69245802, 0.63107299, 0.69642374, 0.63107299, 0.69952111,\n",
       "        0.63107299, 0.70231628, 0.63107299, 0.70442854, 0.63107299,\n",
       "        0.67378602, 0.63109269, 0.68895063, 0.63109269, 0.69634593,\n",
       "        0.63109269, 0.70250916, 0.63109269, 0.70702453, 0.63109269,\n",
       "        0.71097704, 0.63109269, 0.71495367, 0.63109269, 0.71683375,\n",
       "        0.63109269, 0.71983871, 0.63109269, 0.7225392 , 0.63109269]),\n",
       " 'split1_train_precision': array([0.64542431, 0.64539487, 0.65013291, 0.64539487, 0.65734761,\n",
       "        0.64539487, 0.66496705, 0.64539487, 0.66934999, 0.64539487,\n",
       "        0.67202194, 0.64539487, 0.67384866, 0.64539487, 0.67557668,\n",
       "        0.64539487, 0.67654897, 0.64539487, 0.67766643, 0.64539487,\n",
       "        0.66023155, 0.64539487, 0.67309892, 0.64539487, 0.67807723,\n",
       "        0.64539487, 0.68218996, 0.64539487, 0.68495458, 0.64539487,\n",
       "        0.68761608, 0.64539487, 0.69081794, 0.64539487, 0.69287009,\n",
       "        0.64539487, 0.69412912, 0.64539487, 0.6951198 , 0.64539487,\n",
       "        0.67797736, 0.64539487, 0.6864559 , 0.64539487, 0.69255959,\n",
       "        0.64539487, 0.69596158, 0.64539487, 0.69868818, 0.64539487,\n",
       "        0.70175794, 0.64539487, 0.70462274, 0.64539487, 0.70613381,\n",
       "        0.64539487, 0.70762591, 0.64539487, 0.70910128, 0.64539487,\n",
       "        0.68913946, 0.64540531, 0.69734641, 0.64540531, 0.70220746,\n",
       "        0.64540531, 0.70619701, 0.64540531, 0.70866454, 0.64540531,\n",
       "        0.71189024, 0.64540531, 0.7151954 , 0.64540531, 0.71791685,\n",
       "        0.64540531, 0.72088558, 0.64540531, 0.72301793, 0.64540531]),\n",
       " 'split1_train_recall': array([0.6174011 , 0.61737294, 0.62666479, 0.61737294, 0.62762213,\n",
       "        0.61737294, 0.62793186, 0.61737294, 0.62745319, 0.61737294,\n",
       "        0.62776292, 0.61737294, 0.62787555, 0.61737294, 0.62838237,\n",
       "        0.61737294, 0.62905814, 0.61737294, 0.6302689 , 0.61737294,\n",
       "        0.62784739, 0.61737294, 0.62956497, 0.61737294, 0.63193017,\n",
       "        0.61737294, 0.63643531, 0.61737294, 0.64119386, 0.61737294,\n",
       "        0.64631846, 0.61737294, 0.65183725, 0.61737294, 0.65642686,\n",
       "        0.61737294, 0.66115726, 0.61737294, 0.66495847, 0.61737294,\n",
       "        0.63235253, 0.61737294, 0.64561453, 0.61737294, 0.66098831,\n",
       "        0.61737294, 0.66915388, 0.61737294, 0.67785443, 0.61737294,\n",
       "        0.68340138, 0.61737294, 0.68841335, 0.61737294, 0.69303111,\n",
       "        0.61737294, 0.69708574, 0.61737294, 0.69981698, 0.61737294,\n",
       "        0.65910179, 0.6174011 , 0.68075461, 0.6174011 , 0.69058144,\n",
       "        0.6174011 , 0.69885964, 0.6174011 , 0.70539209, 0.6174011 ,\n",
       "        0.71006617, 0.6174011 , 0.71471209, 0.6174011 , 0.71575391,\n",
       "        0.6174011 , 0.71879488, 0.6174011 , 0.7220611 , 0.6174011 ]),\n",
       " 'split2_test_accuracy': array([0.63717761, 0.6371213 , 0.64179525, 0.6371213 , 0.6464692 ,\n",
       "        0.6371213 , 0.65277621, 0.6371213 , 0.65457822, 0.6371213 ,\n",
       "        0.65643654, 0.6371213 , 0.65745016, 0.6371213 , 0.65913954,\n",
       "        0.6371213 , 0.65970267, 0.6371213 , 0.66049105, 0.6371213 ,\n",
       "        0.64951008, 0.6371213 , 0.65846379, 0.6371213 , 0.6616173 ,\n",
       "        0.6371213 , 0.66443293, 0.6371213 , 0.66781169, 0.6371213 ,\n",
       "        0.67017682, 0.6371213 , 0.67254195, 0.6371213 , 0.6763149 ,\n",
       "        0.6371213 , 0.67834216, 0.6371213 , 0.68042572, 0.6371213 ,\n",
       "        0.66122311, 0.6371213 , 0.67079626, 0.6371213 , 0.67890528,\n",
       "        0.6371213 , 0.68408605, 0.6371213 , 0.68757743, 0.6371213 ,\n",
       "        0.69067463, 0.6371213 , 0.69247663, 0.6371213 , 0.69225138,\n",
       "        0.6371213 , 0.69349026, 0.6371213 , 0.69467282, 0.6371213 ,\n",
       "        0.67704696, 0.6371213 , 0.68937943, 0.6371213 , 0.69225138,\n",
       "        0.6371213 , 0.69354657, 0.6371213 , 0.6950107 , 0.6371213 ,\n",
       "        0.69698164, 0.6371213 , 0.69670008, 0.6371213 , 0.69692533,\n",
       "        0.6371213 , 0.69861471, 0.6371213 , 0.69951571, 0.6371213 ]),\n",
       " 'split2_test_f1': array([0.62711962, 0.62708333, 0.63284271, 0.62708333, 0.63643734,\n",
       "        0.62708333, 0.64042454, 0.62708333, 0.64099263, 0.62708333,\n",
       "        0.64202312, 0.62708333, 0.64244989, 0.62708333, 0.64396212,\n",
       "        0.62708333, 0.64434112, 0.62708333, 0.64495613, 0.62708333,\n",
       "        0.63868571, 0.62708333, 0.64421892, 0.62708333, 0.64704846,\n",
       "        0.62708333, 0.65019078, 0.62708333, 0.65403789, 0.62708333,\n",
       "        0.65670242, 0.62708333, 0.65964296, 0.62708333, 0.66401683,\n",
       "        0.62708333, 0.66689993, 0.62708333, 0.6695009 , 0.62708333,\n",
       "        0.64669955, 0.62708333, 0.65796864, 0.62708333, 0.66802515,\n",
       "        0.62708333, 0.67527205, 0.62708333, 0.67952865, 0.62708333,\n",
       "        0.68396525, 0.62708333, 0.68649176, 0.62708333, 0.68665788,\n",
       "        0.62708333, 0.68866899, 0.62708333, 0.6898879 , 0.62708333,\n",
       "        0.66627873, 0.62708333, 0.68320698, 0.62708333, 0.68783915,\n",
       "        0.62708333, 0.69005582, 0.62708333, 0.69300533, 0.62708333,\n",
       "        0.69548979, 0.62708333, 0.6946712 , 0.62708333, 0.69479415,\n",
       "        0.62708333, 0.69673617, 0.62708333, 0.69743706, 0.62708333]),\n",
       " 'split2_test_precision': array([0.645     , 0.64492322, 0.64906465, 0.64492322, 0.65502444,\n",
       "        0.64492322, 0.66404644, 0.64492322, 0.66723529, 0.64492322,\n",
       "        0.67013719, 0.64492322, 0.67187116, 0.64492322, 0.67397193,\n",
       "        0.64492322, 0.67480276, 0.64492322, 0.6758825 , 0.64492322,\n",
       "        0.65903918, 0.64492322, 0.67225759, 0.64492322, 0.67616008,\n",
       "        0.64492322, 0.67900932, 0.64492322, 0.68232991, 0.64492322,\n",
       "        0.68467367, 0.64492322, 0.68669266, 0.64492322, 0.69024183,\n",
       "        0.64492322, 0.69149837, 0.64492322, 0.69319826, 0.64492322,\n",
       "        0.67566573, 0.64492322, 0.68464629, 0.64492322, 0.69145474,\n",
       "        0.64492322, 0.69465285, 0.64492322, 0.69749792, 0.64492322,\n",
       "        0.69912962, 0.64492322, 0.7001171 , 0.64492322, 0.69936931,\n",
       "        0.64492322, 0.69967457, 0.64492322, 0.70087159, 0.64492322,\n",
       "        0.68926078, 0.64492322, 0.69705848, 0.64492322, 0.69784423,\n",
       "        0.64492322, 0.69800668, 0.64492322, 0.69759215, 0.64492322,\n",
       "        0.69893085, 0.64492322, 0.69934939, 0.64492322, 0.69971445,\n",
       "        0.64492322, 0.70110617, 0.64492322, 0.70229531, 0.64492322]),\n",
       " 'split2_test_recall': array([0.61020385, 0.61020385, 0.61741187, 0.61020385, 0.618876  ,\n",
       "        0.61020385, 0.6184255 , 0.61020385, 0.61673612, 0.61020385,\n",
       "        0.61617299, 0.61020385, 0.61549724, 0.61020385, 0.61651087,\n",
       "        0.61020385, 0.61651087, 0.61020385, 0.61673612, 0.61020385,\n",
       "        0.61955175, 0.61020385, 0.6184255 , 0.61020385, 0.62034013,\n",
       "        0.61020385, 0.62371889, 0.61020385, 0.62799865, 0.61020385,\n",
       "        0.63092691, 0.61020385, 0.63464354, 0.61020385, 0.63971168,\n",
       "        0.61020385, 0.64399144, 0.61020385, 0.6473702 , 0.61020385,\n",
       "        0.62011488, 0.61020385, 0.63329204, 0.61020385, 0.64613132,\n",
       "        0.61020385, 0.65694335, 0.61020385, 0.66246199, 0.61020385,\n",
       "        0.66944476, 0.61020385, 0.67338664, 0.61020385, 0.67440027,\n",
       "        0.61020385, 0.67800428, 0.61020385, 0.67924316, 0.61020385,\n",
       "        0.64477982, 0.61020385, 0.66989526, 0.61020385, 0.67811691,\n",
       "        0.61020385, 0.68228404, 0.61020385, 0.68847843, 0.61020385,\n",
       "        0.69208244, 0.61020385, 0.69005519, 0.61020385, 0.68994256,\n",
       "        0.61020385, 0.69242032, 0.61020385, 0.69264557, 0.61020385]),\n",
       " 'split2_train_accuracy': array([0.63834999, 0.63829368, 0.6445164 , 0.63829368, 0.6499648 ,\n",
       "        0.63829368, 0.65538505, 0.63829368, 0.65841194, 0.63829368,\n",
       "        0.6599465 , 0.63829368, 0.66160777, 0.63829368, 0.66269182,\n",
       "        0.63829368, 0.66364916, 0.63829368, 0.6640856 , 0.63829368,\n",
       "        0.65200619, 0.63829368, 0.660932  , 0.63829368, 0.664874  ,\n",
       "        0.63829368, 0.66760524, 0.63829368, 0.67049134, 0.63829368,\n",
       "        0.67343376, 0.63829368, 0.6757708 , 0.63829368, 0.6787273 ,\n",
       "        0.63829368, 0.68131775, 0.63829368, 0.68379558, 0.63829368,\n",
       "        0.66466282, 0.63829368, 0.67303956, 0.63829368, 0.68033225,\n",
       "        0.63829368, 0.68599183, 0.63829368, 0.6898916 , 0.63829368,\n",
       "        0.69380543, 0.63829368, 0.69677601, 0.63829368, 0.69898634,\n",
       "        0.63829368, 0.70101366, 0.63829368, 0.70306913, 0.63829368,\n",
       "        0.67771364, 0.63830776, 0.69029987, 0.63830776, 0.69640997,\n",
       "        0.63830776, 0.70116852, 0.63830776, 0.70585668, 0.63830776,\n",
       "        0.70979868, 0.63830776, 0.71226242, 0.63830776, 0.71497959,\n",
       "        0.63830776, 0.71802055, 0.63830776, 0.72117415, 0.63830776]),\n",
       " 'split2_train_f1': array([0.63088772, 0.63083024, 0.63870765, 0.63083024, 0.64288074,\n",
       "        0.63083024, 0.64589301, 0.63083024, 0.64771391, 0.63083024,\n",
       "        0.64842363, 0.63083024, 0.64961078, 0.63083024, 0.650402  ,\n",
       "        0.63083024, 0.65125173, 0.63083024, 0.6516178 , 0.63083024,\n",
       "        0.64442718, 0.63083024, 0.64991133, 0.63083024, 0.65324554,\n",
       "        0.63083024, 0.65579076, 0.63083024, 0.65899323, 0.63083024,\n",
       "        0.66226959, 0.63083024, 0.66512534, 0.63083024, 0.66886264,\n",
       "        0.63083024, 0.67228399, 0.63083024, 0.67533031, 0.63083024,\n",
       "        0.65328462, 0.63083024, 0.66282412, 0.63083024, 0.67168884,\n",
       "        0.63083024, 0.67942969, 0.63083024, 0.6843591 , 0.63083024,\n",
       "        0.68947301, 0.63083024, 0.69292843, 0.63083024, 0.69537094,\n",
       "        0.63083024, 0.69786169, 0.63083024, 0.69998151, 0.63083024,\n",
       "        0.66945824, 0.63084992, 0.68633434, 0.63084992, 0.69359743,\n",
       "        0.63084992, 0.69904152, 0.63084992, 0.70500529, 0.63084992,\n",
       "        0.7094346 , 0.63084992, 0.71169417, 0.63084992, 0.71458178,\n",
       "        0.63084992, 0.71787359, 0.63084992, 0.72117808, 0.63084992]),\n",
       " 'split2_train_precision': array([0.6441797 , 0.64412101, 0.64931778, 0.64412101, 0.65616021,\n",
       "        0.64412101, 0.66418732, 0.64412101, 0.6686552 , 0.64412101,\n",
       "        0.67116642, 0.64412101, 0.67348789, 0.64412101, 0.67499546,\n",
       "        0.64412101, 0.6761746 , 0.64412101, 0.67673551, 0.64412101,\n",
       "        0.65877474, 0.64412101, 0.67174494, 0.64412101, 0.67672713,\n",
       "        0.64412101, 0.67995888, 0.64412101, 0.68282005, 0.64412101,\n",
       "        0.6857117 , 0.64412101, 0.68770484, 0.64412101, 0.6900506 ,\n",
       "        0.64412101, 0.69189737, 0.64412101, 0.69390726, 0.64412101,\n",
       "        0.67622951, 0.64412101, 0.68420106, 0.64412101, 0.69035518,\n",
       "        0.64412101, 0.69393148, 0.64412101, 0.6967902 , 0.64412101,\n",
       "        0.69936856, 0.64412101, 0.70183394, 0.64412101, 0.70382441,\n",
       "        0.64412101, 0.70529706, 0.64412101, 0.70733671, 0.64412101,\n",
       "        0.68705729, 0.64413146, 0.69523644, 0.64413146, 0.70008318,\n",
       "        0.64413146, 0.70405278, 0.64413146, 0.70705183, 0.64413146,\n",
       "        0.71032575, 0.64413146, 0.71310247, 0.64413146, 0.71558053,\n",
       "        0.64413146, 0.71824793, 0.64413146, 0.72116792, 0.64413146]),\n",
       " 'split2_train_recall': array([0.61813318, 0.61807687, 0.62843869, 0.61807687, 0.63012811,\n",
       "        0.61807687, 0.62857947, 0.61807687, 0.62804449, 0.61807687,\n",
       "        0.62717162, 0.61807687, 0.62736872, 0.61807687, 0.62753766,\n",
       "        0.61807687, 0.6281008 , 0.61807687, 0.6282979 , 0.61807687,\n",
       "        0.63069126, 0.61807687, 0.62945234, 0.61807687, 0.63133887,\n",
       "        0.61807687, 0.63328171, 0.61807687, 0.63677319, 0.61807687,\n",
       "        0.64037731, 0.61807687, 0.64398142, 0.61807687, 0.64893707,\n",
       "        0.61807687, 0.65375194, 0.61807687, 0.65772209, 0.61807687,\n",
       "        0.6318457 , 0.61807687, 0.6427425 , 0.61807687, 0.65400535,\n",
       "        0.61807687, 0.66552161, 0.61807687, 0.67236379, 0.61807687,\n",
       "        0.67985358, 0.61807687, 0.68424609, 0.61807687, 0.68711812,\n",
       "        0.61807687, 0.69058144, 0.61807687, 0.6927777 , 0.61807687,\n",
       "        0.65273828, 0.61810503, 0.67765733, 0.61810503, 0.68723075,\n",
       "        0.61810503, 0.69410108, 0.61810503, 0.70297058, 0.61810503,\n",
       "        0.70854568, 0.61810503, 0.71029143, 0.61810503, 0.71358581,\n",
       "        0.61810503, 0.71749965, 0.61810503, 0.72118823, 0.61810503]),\n",
       " 'split3_test_accuracy': array([0.64517401, 0.64517401, 0.65131208, 0.64517401, 0.65756279,\n",
       "        0.64517401, 0.66285618, 0.64517401, 0.66544656, 0.64517401,\n",
       "        0.66662912, 0.64517401, 0.66826219, 0.64517401, 0.66916319,\n",
       "        0.64517401, 0.66972632, 0.64517401, 0.6705147 , 0.64517401,\n",
       "        0.66094155, 0.64517401, 0.66933213, 0.64517401, 0.67135939,\n",
       "        0.64517401, 0.67417502, 0.64517401, 0.67732853, 0.64517401,\n",
       "        0.67884897, 0.64517401, 0.68160829, 0.64517401, 0.68267823,\n",
       "        0.64517401, 0.68425498, 0.64517401, 0.68662011, 0.64517401,\n",
       "        0.67265458, 0.64517401, 0.67856741, 0.64517401, 0.68487442,\n",
       "        0.64517401, 0.68797162, 0.64517401, 0.69061831, 0.64517401,\n",
       "        0.69309607, 0.64517401, 0.6954612 , 0.64517401, 0.69619327,\n",
       "        0.64517401, 0.69788264, 0.64517401, 0.69917784, 0.64517401,\n",
       "        0.68419867, 0.64517401, 0.69270188, 0.64517401, 0.69675639,\n",
       "        0.64517401, 0.6999099 , 0.64517401, 0.70148665, 0.64517401,\n",
       "        0.70193716, 0.64517401, 0.70311972, 0.64517401, 0.70373916,\n",
       "        0.64517401, 0.70514698, 0.64517401, 0.70548485, 0.64517401]),\n",
       " 'split3_test_f1': array([0.63760281, 0.63760281, 0.64540144, 0.63760281, 0.6496918 ,\n",
       "        0.63760281, 0.65254483, 0.63760281, 0.65388873, 0.63760281,\n",
       "        0.65452848, 0.63760281, 0.65571854, 0.63760281, 0.65661348,\n",
       "        0.63760281, 0.65679677, 0.63760281, 0.65757593, 0.63760281,\n",
       "        0.6519452 , 0.63760281, 0.65764925, 0.63760281, 0.65879326,\n",
       "        0.63760281, 0.66155826, 0.63760281, 0.66534283, 0.63760281,\n",
       "        0.66787025, 0.63760281, 0.67127907, 0.63760281, 0.67308696,\n",
       "        0.63760281, 0.67576476, 0.63760281, 0.67915826, 0.63760281,\n",
       "        0.66019758, 0.63760281, 0.66740473, 0.63760281, 0.67679335,\n",
       "        0.63760281, 0.68124029, 0.63760281, 0.68472398, 0.63760281,\n",
       "        0.68796519, 0.63760281, 0.69097143, 0.63760281, 0.69176713,\n",
       "        0.63760281, 0.69442388, 0.63760281, 0.69588979, 0.63760281,\n",
       "        0.67587562, 0.63760281, 0.68793961, 0.63760281, 0.69352911,\n",
       "        0.63760281, 0.69774828, 0.63760281, 0.69954089, 0.63760281,\n",
       "        0.70043579, 0.63760281, 0.7016412 , 0.63760281, 0.70228057,\n",
       "        0.63760281, 0.70404703, 0.63760281, 0.7046199 , 0.63760281]),\n",
       " 'split3_test_precision': array([0.65150447, 0.65150447, 0.65653035, 0.65150447, 0.66497642,\n",
       "        0.65150447, 0.67313218, 0.65150447, 0.67728699, 0.65150447,\n",
       "        0.6791813 , 0.65150447, 0.68148688, 0.65150447, 0.68250304,\n",
       "        0.65150447, 0.68355664, 0.65150447, 0.68445419, 0.65150447,\n",
       "        0.66971496, 0.65150447, 0.68173577, 0.65150447, 0.6849848 ,\n",
       "        0.65150447, 0.68820737, 0.65150447, 0.69101055, 0.65150447,\n",
       "        0.69150989, 0.65150447, 0.6937868 , 0.65150447, 0.69406557,\n",
       "        0.65150447, 0.69443784, 0.65150447, 0.69572407, 0.65150447,\n",
       "        0.68631502, 0.65150447, 0.69141615, 0.65150447, 0.69460581,\n",
       "        0.65150447, 0.69626058, 0.65150447, 0.6980227 , 0.65150447,\n",
       "        0.69966228, 0.65150447, 0.70131075, 0.65150447, 0.70199443,\n",
       "        0.65150447, 0.70246601, 0.65150447, 0.70358006, 0.65150447,\n",
       "        0.69417072, 0.65150447, 0.69876859, 0.65150447, 0.70098942,\n",
       "        0.65150447, 0.70281079, 0.65150447, 0.70413053, 0.65150447,\n",
       "        0.7039818 , 0.65150447, 0.705153  , 0.65150447, 0.70575523,\n",
       "        0.65150447, 0.70668331, 0.65150447, 0.70669537, 0.65150447]),\n",
       " 'split3_test_recall': array([0.62428201, 0.62428201, 0.63464354, 0.62428201, 0.63509404,\n",
       "        0.62428201, 0.63317941, 0.62428201, 0.63205316, 0.62428201,\n",
       "        0.63160266, 0.62428201, 0.63182791, 0.62428201, 0.63261629,\n",
       "        0.62428201, 0.63205316, 0.62428201, 0.63272891, 0.62428201,\n",
       "        0.63509404, 0.62428201, 0.63520667, 0.62428201, 0.63453092,\n",
       "        0.62428201, 0.63689605, 0.62428201, 0.64151368, 0.62428201,\n",
       "        0.64579345, 0.62428201, 0.65018583, 0.62428201, 0.65333934,\n",
       "        0.62428201, 0.6580696 , 0.62428201, 0.66336299, 0.62428201,\n",
       "        0.63599504, 0.62428201, 0.64500507, 0.62428201, 0.65987161,\n",
       "        0.62428201, 0.66685438, 0.62428201, 0.67192251, 0.62428201,\n",
       "        0.67665278, 0.62428201, 0.68093254, 0.62428201, 0.68183354,\n",
       "        0.62428201, 0.6865638 , 0.62428201, 0.68836581, 0.62428201,\n",
       "        0.6585201 , 0.62428201, 0.67744115, 0.62428201, 0.68622593,\n",
       "        0.62428201, 0.69275819, 0.62428201, 0.6950107 , 0.62428201,\n",
       "        0.69692533, 0.62428201, 0.69816421, 0.62428201, 0.69883996,\n",
       "        0.62428201, 0.70143034, 0.62428201, 0.70255659, 0.62428201]),\n",
       " 'split3_train_accuracy': array([0.63632268, 0.63628044, 0.64226383, 0.63628044, 0.64941574,\n",
       "        0.63628044, 0.65482191, 0.63628044, 0.65708855, 0.63628044,\n",
       "        0.65873575, 0.63628044, 0.66035478, 0.63628044, 0.66142475,\n",
       "        0.63628044, 0.66233986, 0.63628044, 0.66381811, 0.63628044,\n",
       "        0.65210474, 0.63628044, 0.6605378 , 0.63628044, 0.66419823,\n",
       "        0.63628044, 0.66864705, 0.63628044, 0.67211038, 0.63628044,\n",
       "        0.67468675, 0.63628044, 0.67819231, 0.63628044, 0.68097987,\n",
       "        0.63628044, 0.68355624, 0.63628044, 0.68571026, 0.63628044,\n",
       "        0.66476137, 0.63628044, 0.67410953, 0.63628044, 0.68271153,\n",
       "        0.63628044, 0.68834295, 0.63628044, 0.69201746, 0.63628044,\n",
       "        0.69549486, 0.63628044, 0.69887372, 0.63628044, 0.70099958,\n",
       "        0.63628044, 0.70330846, 0.63628044, 0.70504012, 0.63628044,\n",
       "        0.67996621, 0.6363086 , 0.69166549, 0.6363086 , 0.69829649,\n",
       "        0.6363086 , 0.70319583, 0.6363086 , 0.70716599, 0.6363086 ,\n",
       "        0.71040405, 0.6363086 , 0.71407856, 0.6363086 , 0.71623258,\n",
       "        0.6363086 , 0.71918908, 0.6363086 , 0.72227228, 0.6363086 ]),\n",
       " 'split3_train_f1': array([0.62824166, 0.62820384, 0.63570937, 0.62820384, 0.6409125 ,\n",
       "        0.62820384, 0.64396492, 0.62820384, 0.64504   , 0.62820384,\n",
       "        0.64600736, 0.62820384, 0.64739327, 0.62820384, 0.64843213,\n",
       "        0.62820384, 0.64908995, 0.62820384, 0.65074374, 0.62820384,\n",
       "        0.64275491, 0.62820384, 0.64835934, 0.62820384, 0.65141905,\n",
       "        0.62820384, 0.65616783, 0.62820384, 0.6600794 , 0.62820384,\n",
       "        0.66351153, 0.62820384, 0.66784853, 0.62820384, 0.6711462 ,\n",
       "        0.62820384, 0.67448697, 0.62820384, 0.67738952, 0.62820384,\n",
       "        0.6523085 , 0.62820384, 0.66316463, 0.62820384, 0.674156  ,\n",
       "        0.62820384, 0.68135823, 0.62820384, 0.68588823, 0.62820384,\n",
       "        0.69038178, 0.62820384, 0.69456939, 0.62820384, 0.69714514,\n",
       "        0.62820384, 0.70005693, 0.62820384, 0.70214248, 0.62820384,\n",
       "        0.6714839 , 0.62824332, 0.68696311, 0.62824332, 0.69522428,\n",
       "        0.62824332, 0.70142194, 0.62824332, 0.70600707, 0.62824332,\n",
       "        0.70956173, 0.62824332, 0.71345326, 0.62824332, 0.71569623,\n",
       "        0.62824332, 0.71875353, 0.62824332, 0.7223231 , 0.62824332]),\n",
       " 'split3_train_precision': array([0.64251862, 0.64247027, 0.64757426, 0.64247027, 0.65684391,\n",
       "        0.64247027, 0.66487751, 0.64247027, 0.66852948, 0.64247027,\n",
       "        0.67103547, 0.64247027, 0.67307926, 0.64247027, 0.6743083 ,\n",
       "        0.64247027, 0.67560077, 0.64247027, 0.67707572, 0.64247027,\n",
       "        0.6605063 , 0.64247027, 0.67248525, 0.64247027, 0.67719   ,\n",
       "        0.64247027, 0.68184716, 0.64247027, 0.68522166, 0.64247027,\n",
       "        0.68711545, 0.64247027, 0.69002793, 0.64247027, 0.69249199,\n",
       "        0.64247027, 0.69438812, 0.64247027, 0.69581094, 0.64247027,\n",
       "        0.67747414, 0.64247027, 0.68621074, 0.64247027, 0.69283804,\n",
       "        0.64247027, 0.69697862, 0.64247027, 0.69981541, 0.64247027,\n",
       "        0.70217227, 0.64247027, 0.70464159, 0.64247027, 0.70624946,\n",
       "        0.64247027, 0.70781407, 0.64247027, 0.70910866, 0.64247027,\n",
       "        0.68976574, 0.64249132, 0.69760218, 0.64249132, 0.70237651,\n",
       "        0.64249132, 0.7056393 , 0.64249132, 0.70881226, 0.64249132,\n",
       "        0.7116316 , 0.64249132, 0.71501697, 0.64249132, 0.71705152,\n",
       "        0.64249132, 0.71987007, 0.64249132, 0.72219095, 0.64249132]),\n",
       " 'split3_train_recall': array([0.61458539, 0.61455723, 0.62427143, 0.61455723, 0.6257356 ,\n",
       "        0.61455723, 0.62432775, 0.61455723, 0.62314515, 0.61455723,\n",
       "        0.62277911, 0.61455723, 0.62359566, 0.61455723, 0.62446853,\n",
       "        0.61455723, 0.62458116, 0.61455723, 0.62638322, 0.61455723,\n",
       "        0.6259327 , 0.61455723, 0.62590455, 0.61455723, 0.62753766,\n",
       "        0.61455723, 0.63235253, 0.61455723, 0.63671688, 0.61455723,\n",
       "        0.64147543, 0.61455723, 0.64705054, 0.61455723, 0.65107701,\n",
       "        0.61455723, 0.65569478, 0.61455723, 0.65991834, 0.61455723,\n",
       "        0.62894552, 0.61455723, 0.64161622, 0.61455723, 0.65645502,\n",
       "        0.61455723, 0.66642264, 0.61455723, 0.67250458, 0.61455723,\n",
       "        0.67898071, 0.61455723, 0.68478108, 0.61455723, 0.68827256,\n",
       "        0.61455723, 0.69246797, 0.61455723, 0.69531184, 0.61455723,\n",
       "        0.65414614, 0.61461354, 0.67664367, 0.61461354, 0.68821625,\n",
       "        0.61461354, 0.69725468, 0.61461354, 0.70322399, 0.61461354,\n",
       "        0.70750387, 0.61461354, 0.71189638, 0.61461354, 0.71434605,\n",
       "        0.61461354, 0.71764043, 0.61461354, 0.7224553 , 0.61461354]),\n",
       " 'split4_test_accuracy': array([0.63465871, 0.63454607, 0.64091011, 0.63454607, 0.64749944,\n",
       "        0.63454607, 0.651836  , 0.63454607, 0.65493354, 0.63454607,\n",
       "        0.65735526, 0.63454607, 0.6586506 , 0.63454607, 0.65876323,\n",
       "        0.63454607, 0.65915747, 0.63454607, 0.66028385, 0.63454607,\n",
       "        0.64890741, 0.63454607, 0.65786213, 0.63454607, 0.66180446,\n",
       "        0.63454607, 0.66540888, 0.63454607, 0.66777427, 0.63454607,\n",
       "        0.66957648, 0.63454607, 0.67239243, 0.63454607, 0.67453255,\n",
       "        0.63454607, 0.67757378, 0.63454607, 0.67915071, 0.63454607,\n",
       "        0.66264925, 0.63454607, 0.67025231, 0.63454607, 0.67650372,\n",
       "        0.63454607, 0.68027709, 0.63454607, 0.68309304, 0.63454607,\n",
       "        0.68461365, 0.63454607, 0.68686641, 0.63454607, 0.68849966,\n",
       "        0.63454607, 0.6895134 , 0.63454607, 0.69058346, 0.63454607,\n",
       "        0.67470151, 0.63460239, 0.68365623, 0.63460239, 0.68686641,\n",
       "        0.63460239, 0.69120297, 0.63460239, 0.69221672, 0.63460239,\n",
       "        0.6921604 , 0.63460239, 0.69407524, 0.63460239, 0.69328678,\n",
       "        0.63460239, 0.69593377, 0.63460239, 0.69666592, 0.63460239]),\n",
       " 'split4_test_f1': array([0.62681931, 0.62670425, 0.63423589, 0.62670425, 0.63947929,\n",
       "        0.62670425, 0.6413321 , 0.62670425, 0.64284465, 0.62670425,\n",
       "        0.64446003, 0.62670425, 0.64524437, 0.62670425, 0.6449458 ,\n",
       "        0.62670425, 0.64521046, 0.62670425, 0.64605093, 0.62670425,\n",
       "        0.64031849, 0.62670425, 0.6452969 , 0.62670425, 0.64823385,\n",
       "        0.62670425, 0.6513293 , 0.62670425, 0.65444321, 0.62670425,\n",
       "        0.65680023, 0.62670425, 0.66044014, 0.62670425, 0.66356174,\n",
       "        0.62670425, 0.66794269, 0.62670425, 0.67040787, 0.62670425,\n",
       "        0.64929742, 0.62670425, 0.65790242, 0.62670425, 0.66743863,\n",
       "        0.62670425, 0.67258781, 0.62670425, 0.67659061, 0.62670425,\n",
       "        0.67864111, 0.62670425, 0.68155785, 0.62670425, 0.68388867,\n",
       "        0.62670425, 0.68545672, 0.62670425, 0.68691589, 0.62670425,\n",
       "        0.66558592, 0.62678325, 0.67838534, 0.62678325, 0.6826484 ,\n",
       "        0.62678325, 0.68834195, 0.62678325, 0.69045596, 0.62678325,\n",
       "        0.69069715, 0.62678325, 0.69272542, 0.62678325, 0.69193348,\n",
       "        0.62678325, 0.69488556, 0.62678325, 0.69556862, 0.62678325]),\n",
       " 'split4_test_precision': array([0.64056437, 0.6404468 , 0.64624737, 0.6404468 , 0.65436756,\n",
       "        0.6404468 , 0.6612826 , 0.6404468 , 0.6661834 , 0.6404468 ,\n",
       "        0.66966238, 0.6404468 , 0.67162179, 0.6404468 , 0.67216319,\n",
       "        0.6404468 , 0.67273839, 0.6404468 , 0.67430181, 0.6404468 ,\n",
       "        0.65637568, 0.6404468 , 0.66989938, 0.6404468 , 0.6753326 ,\n",
       "        0.6404468 , 0.67994118, 0.6404468 , 0.68180154, 0.6404468 ,\n",
       "        0.68321772, 0.6404468 , 0.68544772, 0.6404468 , 0.68670924,\n",
       "        0.6404468 , 0.68850891, 0.6404468 , 0.68918758, 0.6404468 ,\n",
       "        0.67605462, 0.6404468 , 0.68350127, 0.6404468 , 0.68668096,\n",
       "        0.6404468 , 0.68916204, 0.6404468 , 0.69076399, 0.6404468 ,\n",
       "        0.69174076, 0.6404468 , 0.69331158, 0.6404468 , 0.69416406,\n",
       "        0.6404468 , 0.69453116, 0.6404468 , 0.69515571, 0.6404468 ,\n",
       "        0.68477484, 0.64048907, 0.68988005, 0.64048907, 0.69196945,\n",
       "        0.64048907, 0.69477912, 0.64048907, 0.69442862, 0.64048907,\n",
       "        0.69399591, 0.64048907, 0.69579545, 0.64048907, 0.695     ,\n",
       "        0.64048907, 0.69728933, 0.64048907, 0.69809394, 0.64048907]),\n",
       " 'split4_test_recall': array([0.61365172, 0.61353909, 0.62266276, 0.61353909, 0.62525344,\n",
       "        0.61353909, 0.62255012, 0.61353909, 0.62108583, 0.61353909,\n",
       "        0.62108583, 0.61353909, 0.62086055, 0.61353909, 0.61984681,\n",
       "        0.61353909, 0.61984681, 0.61353909, 0.62007209, 0.61353909,\n",
       "        0.62502816, 0.61353909, 0.62243749, 0.61353909, 0.62322595,\n",
       "        0.61353909, 0.62502816, 0.61353909, 0.62919576, 0.61353909,\n",
       "        0.63234963, 0.61353909, 0.63719306, 0.61353909, 0.64192386,\n",
       "        0.61353909, 0.6485695 , 0.61353909, 0.65262446, 0.61353909,\n",
       "        0.62457761, 0.61353909, 0.63415184, 0.61353909, 0.64924533,\n",
       "        0.61353909, 0.65679207, 0.61353909, 0.66298716, 0.61353909,\n",
       "        0.66602838, 0.61353909, 0.67019599, 0.61353909, 0.67391304,\n",
       "        0.61353909, 0.67661636, 0.61353909, 0.67886911, 0.61353909,\n",
       "        0.64744312, 0.61365172, 0.6672674 , 0.61365172, 0.67357513,\n",
       "        0.61365172, 0.68202298, 0.61365172, 0.6865285 , 0.61365172,\n",
       "        0.6874296 , 0.61365172, 0.68968236, 0.61365172, 0.6888939 ,\n",
       "        0.61365172, 0.69249831, 0.61365172, 0.6930615 , 0.61365172]),\n",
       " 'split4_train_accuracy': array([0.63895146, 0.63893738, 0.64435747, 0.63893738, 0.64991835,\n",
       "        0.63893738, 0.65595788, 0.63893738, 0.65846379, 0.63893738,\n",
       "        0.6607163 , 0.63893738, 0.66175808, 0.63893738, 0.66282802,\n",
       "        0.63893738, 0.66364455, 0.63893738, 0.66427807, 0.63893738,\n",
       "        0.65217085, 0.63893738, 0.66191294, 0.63893738, 0.66502421,\n",
       "        0.63893738, 0.66906465, 0.63893738, 0.67169726, 0.63893738,\n",
       "        0.67527312, 0.63893738, 0.67856741, 0.63893738, 0.68162237,\n",
       "        0.63893738, 0.68429722, 0.63893738, 0.68593028, 0.63893738,\n",
       "        0.66531986, 0.63893738, 0.67442843, 0.63893738, 0.68293164,\n",
       "        0.63893738, 0.6879857 , 0.63893738, 0.69250479, 0.63893738,\n",
       "        0.69602433, 0.63893738, 0.69888219, 0.63893738, 0.70099392,\n",
       "        0.63893738, 0.70338721, 0.63893738, 0.70597759, 0.63893738,\n",
       "        0.68104516, 0.63893738, 0.69291305, 0.63893738, 0.69867102,\n",
       "        0.63893738, 0.70383771, 0.63893738, 0.70793445, 0.63893738,\n",
       "        0.71134137, 0.63893738, 0.71429778, 0.63893738, 0.71788771,\n",
       "        0.63893738, 0.72063295, 0.63893738, 0.72326557, 0.63893738]),\n",
       " 'split4_train_f1': array([0.6309397 , 0.63093062, 0.63794537, 0.63093062, 0.64200055,\n",
       "        0.63093062, 0.64554869, 0.63093062, 0.64692185, 0.63093062,\n",
       "        0.64842154, 0.63093062, 0.64887616, 0.63093062, 0.64967967,\n",
       "        0.63093062, 0.650436  , 0.63093062, 0.65095651, 0.63093062,\n",
       "        0.64370899, 0.63093062, 0.64992201, 0.63093062, 0.65220569,\n",
       "        0.63093062, 0.6561947 , 0.63093062, 0.65935318, 0.63093062,\n",
       "        0.66361383, 0.63093062, 0.66763713, 0.63093062, 0.671518  ,\n",
       "        0.63093062, 0.675193  , 0.63093062, 0.67752707, 0.63093062,\n",
       "        0.65273091, 0.63093062, 0.66322013, 0.63093062, 0.67432108,\n",
       "        0.63093062, 0.68040434, 0.63093062, 0.68602478, 0.63093062,\n",
       "        0.69053489, 0.63093062, 0.69382614, 0.63093062, 0.6965467 ,\n",
       "        0.63093062, 0.69942221, 0.63093062, 0.70241233, 0.63093062,\n",
       "        0.67244022, 0.63093062, 0.68767629, 0.63093062, 0.69495197,\n",
       "        0.63093062, 0.70098785, 0.63093062, 0.70619725, 0.63093062,\n",
       "        0.71004327, 0.63093062, 0.71326438, 0.63093062, 0.71719096,\n",
       "        0.63093062, 0.72005756, 0.63093062, 0.72269951, 0.63093062]),\n",
       " 'split4_train_precision': array([0.64525814, 0.64523915, 0.64965847, 0.64523915, 0.65685668,\n",
       "        0.64523915, 0.6656895 , 0.64523915, 0.66954871, 0.64523915,\n",
       "        0.67280213, 0.64523915, 0.674567  , 0.64523915, 0.67604262,\n",
       "        0.64523915, 0.67702242, 0.64523915, 0.67785399, 0.64523915,\n",
       "        0.65975938, 0.64523915, 0.67382039, 0.64523915, 0.67815673,\n",
       "        0.64523915, 0.68274645, 0.64523915, 0.68511323, 0.64523915,\n",
       "        0.68832819, 0.64523915, 0.69113924, 0.64523915, 0.69352855,\n",
       "        0.64523915, 0.69524236, 0.64523915, 0.69615327, 0.64523915,\n",
       "        0.67824292, 0.64523915, 0.68686655, 0.64523915, 0.69314466,\n",
       "        0.64523915, 0.69734859, 0.64523915, 0.70079295, 0.64523915,\n",
       "        0.70323447, 0.64523915, 0.7056751 , 0.64523915, 0.70706309,\n",
       "        0.64523915, 0.70889846, 0.64523915, 0.71103418, 0.64523915,\n",
       "        0.6910847 , 0.64523915, 0.6996067 , 0.64523915, 0.70363636,\n",
       "        0.64523915, 0.70779873, 0.64523915, 0.71042284, 0.64523915,\n",
       "        0.71325075, 0.64523915, 0.71585366, 0.64523915, 0.71896664,\n",
       "        0.64523915, 0.72154368, 0.64523915, 0.72418083, 0.64523915]),\n",
       " 'split4_train_recall': array([0.61724293, 0.61724293, 0.62664714, 0.61724293, 0.62780155,\n",
       "        0.61724293, 0.62659083, 0.61724293, 0.6257743 , 0.61724293,\n",
       "        0.62574614, 0.61724293, 0.62507039, 0.61724293, 0.62529564,\n",
       "        0.61724293, 0.62585877, 0.61724293, 0.62611217, 0.61724293,\n",
       "        0.62842099, 0.61724293, 0.62766077, 0.61724293, 0.62816759,\n",
       "        0.61724293, 0.63163081, 0.61724293, 0.63546007, 0.61724293,\n",
       "        0.64061268, 0.61724293, 0.64568082, 0.61724293, 0.65086158,\n",
       "        0.61724293, 0.6562676 , 0.61724293, 0.65987161, 0.61724293,\n",
       "        0.62906859, 0.61724293, 0.64114765, 0.61724293, 0.65649285,\n",
       "        0.61724293, 0.66426399, 0.61724293, 0.6718662 , 0.61724293,\n",
       "        0.67828584, 0.61724293, 0.68236851, 0.61724293, 0.68633855,\n",
       "        0.61724293, 0.69019597, 0.61724293, 0.69399707, 0.61724293,\n",
       "        0.65477531, 0.61724293, 0.67614596, 0.61724293, 0.68647933,\n",
       "        0.61724293, 0.69430679, 0.61724293, 0.70202162, 0.61724293,\n",
       "        0.70686451, 0.61724293, 0.71069377, 0.61724293, 0.71542403,\n",
       "        0.61724293, 0.71857754, 0.61724293, 0.72122424, 0.61724293]),\n",
       " 'std_fit_time': array([ 62.23092916,   8.81421787,  73.46741493,  12.6818756 ,\n",
       "          7.30001367,  41.81544498,  43.12208832,  19.05669899,\n",
       "          8.13254627,  14.35489672,   4.74941452,  21.6206988 ,\n",
       "         52.22059798,  26.77805128,   5.37600635,   7.63203859,\n",
       "         33.64419857,  20.43675013,   3.22980314,  11.34510045,\n",
       "         17.86211252,  71.57846531,   6.40006524, 126.85836999,\n",
       "         18.77214649,  56.00733059,   8.88673116,  67.44613873,\n",
       "         13.47802003,  75.90078669,   5.13354626,  70.8021658 ,\n",
       "          4.17958038,  68.83541176,   4.16055617,  76.06832116,\n",
       "          9.3716224 ,  58.21972051,   7.49589204,  70.28863257,\n",
       "         33.2886707 , 228.03251816,  34.9482233 , 242.28728966,\n",
       "         42.47874249, 358.41821196,  12.06634641, 216.70942173,\n",
       "         41.87642107, 231.4486477 ,  12.96132866, 281.02754962,\n",
       "         21.35562743, 222.94467717,  13.42527262, 321.66970595,\n",
       "          6.36729405, 148.96970411,  75.93244074, 206.79893302,\n",
       "         11.91969239, 620.29486343,  13.44148779, 242.86713152,\n",
       "        141.58319747, 276.17935328, 222.97302534, 620.67883908,\n",
       "        293.64782139, 687.61715061, 244.0669634 , 193.00909156,\n",
       "        265.49971089, 283.12784776, 316.12922833, 432.26355241,\n",
       "        457.36927712, 557.67205367, 352.05687732, 447.97494449]),\n",
       " 'std_score_time': array([ 1.20761996,  1.52291435,  2.16143064,  4.10162005,  1.70444184,\n",
       "        10.71882804,  1.82036671,  1.45401226,  0.49308272,  1.80162044,\n",
       "         0.81312763,  4.860967  ,  4.69340064,  1.91854114,  0.52386989,\n",
       "         2.25061733,  1.25493085,  1.73878777,  0.67035632,  2.31477691,\n",
       "         1.89062908,  1.88102007,  1.34940674,  5.30857409,  1.76909458,\n",
       "         2.85916693,  1.16204406,  1.30291498,  0.4296912 ,  0.79571467,\n",
       "         0.83345321,  0.81623185,  1.1218659 ,  1.74438127,  0.48488512,\n",
       "         1.50087247,  1.08035578,  6.28225752,  1.41889736,  5.25475685,\n",
       "         3.00266307,  3.21371226,  0.87197128,  2.22025606,  2.48806165,\n",
       "         7.08703779,  1.22637197,  2.87073486,  1.15803661,  4.53021014,\n",
       "         1.11120882,  5.54546192,  2.17599839,  3.22730023,  0.65252372,\n",
       "         2.19006668,  1.10516784,  8.25956195,  1.42160955,  8.07739728,\n",
       "         1.21016563,  8.1785467 ,  1.44010259, 11.5634701 ,  1.72265191,\n",
       "         9.86026896,  3.54292139,  8.63189311,  3.34550859,  9.9511783 ,\n",
       "         1.7121299 ,  9.7755061 ,  1.95062344,  9.61342128,  3.98416393,\n",
       "         1.75969437,  3.46298471,  4.63643995,  1.15269598,  4.25329064]),\n",
       " 'std_test_accuracy': array([0.00404308, 0.00406496, 0.0041576 , 0.00406496, 0.00435284,\n",
       "        0.00406496, 0.00432191, 0.00406496, 0.00457018, 0.00406496,\n",
       "        0.00445952, 0.00406496, 0.0046354 , 0.00406496, 0.00450198,\n",
       "        0.00406496, 0.00454046, 0.00406496, 0.00449383, 0.00406496,\n",
       "        0.00479548, 0.00406496, 0.00466829, 0.00406496, 0.00409863,\n",
       "        0.00406496, 0.00429429, 0.00406496, 0.00429105, 0.00406496,\n",
       "        0.00391985, 0.00406496, 0.00377153, 0.00406496, 0.00317411,\n",
       "        0.00406496, 0.00269122, 0.00406496, 0.00288285, 0.00406496,\n",
       "        0.00463956, 0.00406496, 0.00356659, 0.00406496, 0.00342265,\n",
       "        0.00406496, 0.00316857, 0.00406496, 0.00355445, 0.00406496,\n",
       "        0.00389496, 0.00406496, 0.0034703 , 0.00406496, 0.00318305,\n",
       "        0.00406496, 0.00316312, 0.00406496, 0.00324974, 0.00406496,\n",
       "        0.00387114, 0.00405527, 0.00375907, 0.00405527, 0.00383546,\n",
       "        0.00405527, 0.00319185, 0.00405527, 0.00345313, 0.00405527,\n",
       "        0.00333604, 0.00405527, 0.00302918, 0.00405527, 0.00344219,\n",
       "        0.00405527, 0.00312877, 0.00405527, 0.00305316, 0.00405527]),\n",
       " 'std_test_f1': array([0.0044571 , 0.00447913, 0.00474503, 0.00447913, 0.004737  ,\n",
       "        0.00447913, 0.00459603, 0.00447913, 0.00485098, 0.00447913,\n",
       "        0.00467846, 0.00447913, 0.00491956, 0.00447913, 0.00491644,\n",
       "        0.00447913, 0.00497984, 0.00447913, 0.00502566, 0.00447913,\n",
       "        0.00486165, 0.00447913, 0.00499546, 0.00447913, 0.00433616,\n",
       "        0.00447913, 0.00443479, 0.00447913, 0.0045127 , 0.00447913,\n",
       "        0.00439344, 0.00447913, 0.00427427, 0.00447913, 0.00367137,\n",
       "        0.00447913, 0.00331453, 0.00447913, 0.00354398, 0.00447913,\n",
       "        0.00472699, 0.00447913, 0.00373135, 0.00447913, 0.00376954,\n",
       "        0.00447913, 0.00336201, 0.00447913, 0.00356131, 0.00447913,\n",
       "        0.00410179, 0.00447913, 0.00375468, 0.00447913, 0.00348354,\n",
       "        0.00447913, 0.00341532, 0.00447913, 0.0033518 , 0.00447913,\n",
       "        0.00404763, 0.00446732, 0.0036778 , 0.00446732, 0.0042377 ,\n",
       "        0.00446732, 0.00345477, 0.00446732, 0.00323065, 0.00446732,\n",
       "        0.00323624, 0.00446732, 0.00307757, 0.00446732, 0.00363284,\n",
       "        0.00446732, 0.0031792 , 0.00446732, 0.00314676, 0.00446732]),\n",
       " 'std_test_precision': array([0.00415994, 0.0041789 , 0.00416399, 0.0041789 , 0.0045475 ,\n",
       "        0.0041789 , 0.00473696, 0.0041789 , 0.0050686 , 0.0041789 ,\n",
       "        0.0051025 , 0.0041789 , 0.00526212, 0.0041789 , 0.00500743,\n",
       "        0.0041789 , 0.00507909, 0.0041789 , 0.00500328, 0.0041789 ,\n",
       "        0.00536306, 0.0041789 , 0.00526111, 0.0041789 , 0.00483434,\n",
       "        0.0041789 , 0.00518411, 0.0041789 , 0.00503836, 0.0041789 ,\n",
       "        0.00445545, 0.0041789 , 0.0043312 , 0.0041789 , 0.00399056,\n",
       "        0.0041789 , 0.00329479, 0.0041789 , 0.00342833, 0.0041789 ,\n",
       "        0.00557414, 0.0041789 , 0.00434879, 0.0041789 , 0.0040076 ,\n",
       "        0.0041789 , 0.00375065, 0.0041789 , 0.00448677, 0.0041789 ,\n",
       "        0.0044054 , 0.0041789 , 0.00398018, 0.0041789 , 0.0037804 ,\n",
       "        0.0041789 , 0.00362941, 0.0041789 , 0.00388074, 0.0041789 ,\n",
       "        0.00467821, 0.00417117, 0.0045037 , 0.00417117, 0.00399738,\n",
       "        0.00417117, 0.00344117, 0.00417117, 0.00416579, 0.00417117,\n",
       "        0.00371009, 0.00417117, 0.00342045, 0.00417117, 0.00369053,\n",
       "        0.00417117, 0.00345135, 0.00417117, 0.0034026 , 0.00417117]),\n",
       " 'std_test_recall': array([0.00538688, 0.00539906, 0.00614541, 0.00539906, 0.00567871,\n",
       "        0.00539906, 0.00536649, 0.00539906, 0.00560095, 0.00539906,\n",
       "        0.00550464, 0.00539906, 0.00579566, 0.00539906, 0.00598428,\n",
       "        0.00539906, 0.00614398, 0.00539906, 0.0064259 , 0.00539906,\n",
       "        0.00536727, 0.00539906, 0.00601879, 0.00539906, 0.00541439,\n",
       "        0.00539906, 0.00547591, 0.00539906, 0.00555753, 0.00539906,\n",
       "        0.00598404, 0.00539906, 0.00606517, 0.00539906, 0.00597481,\n",
       "        0.00539906, 0.00567342, 0.00539906, 0.00598606, 0.00539906,\n",
       "        0.00560353, 0.00539906, 0.00492918, 0.00539906, 0.0054184 ,\n",
       "        0.00539906, 0.00469452, 0.00539906, 0.00503978, 0.00539906,\n",
       "        0.00544987, 0.00539906, 0.00546523, 0.00539906, 0.00544902,\n",
       "        0.00539906, 0.00506096, 0.00539906, 0.00481472, 0.00539906,\n",
       "        0.00553922, 0.00538688, 0.00452788, 0.00538688, 0.00588251,\n",
       "        0.00538688, 0.0048734 , 0.00538688, 0.00379637, 0.00538688,\n",
       "        0.00350519, 0.00538688, 0.00404849, 0.00538688, 0.00488464,\n",
       "        0.00538688, 0.00404263, 0.00538688, 0.00425499, 0.00538688]),\n",
       " 'std_train_accuracy': array([0.00100737, 0.00101624, 0.00089631, 0.00101624, 0.00027268,\n",
       "        0.00101624, 0.00041481, 0.00101624, 0.00057483, 0.00101624,\n",
       "        0.00072246, 0.00101624, 0.00056707, 0.00101624, 0.00062493,\n",
       "        0.00101624, 0.00060321, 0.00101624, 0.0004797 , 0.00101624,\n",
       "        0.00013807, 0.00101624, 0.00056922, 0.00101624, 0.00056631,\n",
       "        0.00101624, 0.00076341, 0.00101624, 0.00097614, 0.00101624,\n",
       "        0.00101233, 0.00101624, 0.00140835, 0.00101624, 0.00138459,\n",
       "        0.00101624, 0.00128742, 0.00101624, 0.00102665, 0.00101624,\n",
       "        0.000478  , 0.00101624, 0.00085974, 0.00101624, 0.00120996,\n",
       "        0.00101624, 0.00090949, 0.00101624, 0.00101175, 0.00101624,\n",
       "        0.00093585, 0.00101624, 0.00102688, 0.00101624, 0.00109282,\n",
       "        0.00101624, 0.00119404, 0.00101624, 0.00114408, 0.00101624,\n",
       "        0.00131302, 0.00100791, 0.00092175, 0.00100791, 0.00094645,\n",
       "        0.00100791, 0.00111028, 0.00100791, 0.00073956, 0.00100791,\n",
       "        0.0006763 , 0.00100791, 0.00094587, 0.00100791, 0.00102732,\n",
       "        0.00100791, 0.00093078, 0.00100791, 0.00072013, 0.00100791]),\n",
       " 'std_train_f1': array([0.0011148 , 0.00112026, 0.00107644, 0.00112026, 0.0006713 ,\n",
       "        0.00112026, 0.00079605, 0.00112026, 0.00102924, 0.00112026,\n",
       "        0.00108967, 0.00112026, 0.00096024, 0.00112026, 0.00094781,\n",
       "        0.00112026, 0.00099417, 0.00112026, 0.00090429, 0.00112026,\n",
       "        0.00058394, 0.00112026, 0.00075198, 0.00112026, 0.000964  ,\n",
       "        0.00112026, 0.00099893, 0.00112026, 0.00119311, 0.00112026,\n",
       "        0.00133981, 0.00112026, 0.00179797, 0.00112026, 0.00175375,\n",
       "        0.00112026, 0.00163956, 0.00112026, 0.00144295, 0.00112026,\n",
       "        0.00074517, 0.00112026, 0.00094469, 0.00112026, 0.00152516,\n",
       "        0.00112026, 0.00096134, 0.00112026, 0.0011951 , 0.00112026,\n",
       "        0.00097613, 0.00112026, 0.00115762, 0.00112026, 0.00135538,\n",
       "        0.00112026, 0.00144246, 0.00112026, 0.00141211, 0.00112026,\n",
       "        0.00151831, 0.0011082 , 0.0008708 , 0.0011082 , 0.00092589,\n",
       "        0.0011082 , 0.00116795, 0.0011082 , 0.00064508, 0.0011082 ,\n",
       "        0.00054365, 0.0011082 , 0.00103259, 0.0011082 , 0.0009168 ,\n",
       "        0.0011082 , 0.0007875 , 0.0011082 , 0.00053562, 0.0011082 ]),\n",
       " 'std_train_precision': array([0.00103611, 0.00104639, 0.00086418, 0.00104639, 0.00038552,\n",
       "        0.00104639, 0.00047757, 0.00104639, 0.00047762, 0.00104639,\n",
       "        0.00074256, 0.00104639, 0.00061496, 0.00104639, 0.0007286 ,\n",
       "        0.00104639, 0.00062354, 0.00104639, 0.00057371, 0.00104639,\n",
       "        0.00059573, 0.00104639, 0.00087582, 0.00104639, 0.00067296,\n",
       "        0.00104639, 0.00103331, 0.00104639, 0.00120157, 0.00104639,\n",
       "        0.00105821, 0.00104639, 0.00128472, 0.00104639, 0.00126015,\n",
       "        0.00104639, 0.00120018, 0.00104639, 0.00088021, 0.00104639,\n",
       "        0.00078919, 0.00104639, 0.00116414, 0.00104639, 0.00111826,\n",
       "        0.00104639, 0.00123554, 0.00104639, 0.00133523, 0.00104639,\n",
       "        0.00134084, 0.00104639, 0.00135169, 0.00104639, 0.0011923 ,\n",
       "        0.00104639, 0.00131748, 0.00104639, 0.00122864, 0.00104639,\n",
       "        0.00142675, 0.00104061, 0.00141163, 0.00104061, 0.001236  ,\n",
       "        0.00104061, 0.00134567, 0.00104061, 0.00117652, 0.00104061,\n",
       "        0.00120352, 0.00104061, 0.00109256, 0.00104061, 0.00130016,\n",
       "        0.00104061, 0.00127432, 0.00104061, 0.00117423, 0.00104061]),\n",
       " 'std_train_recall': array([0.00135337, 0.00134978, 0.00146882, 0.00134978, 0.00148722,\n",
       "        0.00134978, 0.00160861, 0.00134978, 0.00189374, 0.00134978,\n",
       "        0.00189774, 0.00134978, 0.00180891, 0.00134978, 0.0017327 ,\n",
       "        0.00134978, 0.0018251 , 0.00134978, 0.00181426, 0.00134978,\n",
       "        0.00161247, 0.00134978, 0.00154126, 0.00134978, 0.00187821,\n",
       "        0.00134978, 0.00184544, 0.00134978, 0.00196223, 0.00134978,\n",
       "        0.00216714, 0.00134978, 0.00261453, 0.00134978, 0.00254918,\n",
       "        0.00134978, 0.00246873, 0.00134978, 0.00240886, 0.00134978,\n",
       "        0.00162932, 0.00134978, 0.00156497, 0.00134978, 0.002257  ,\n",
       "        0.00134978, 0.00160976, 0.00134978, 0.00218908, 0.00134978,\n",
       "        0.00177777, 0.00134978, 0.0020723 , 0.00134978, 0.0023472 ,\n",
       "        0.00134978, 0.00245958, 0.00134978, 0.0024409 , 0.00134978,\n",
       "        0.00219229, 0.00133346, 0.00163925, 0.00133346, 0.00138883,\n",
       "        0.00133346, 0.00179812, 0.00133346, 0.00125596, 0.00133346,\n",
       "        0.00127234, 0.00133346, 0.00165349, 0.00133346, 0.00097097,\n",
       "        0.00133346, 0.00089281, 0.00133346, 0.0008728 , 0.00133346])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 8]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-e21c8661cafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Fit the random search model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdt_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages_tfidf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ztdl/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "scoring = {'accuracy':'accuracy','precision':'precision', 'f1':'f1', 'recall':'recall'}\n",
    "dt_random = GridSearchCV(estimator=dt, param_grid=random_grid, cv=5, scoring= scoring, \n",
    "                                     pre_dispatch=8, refit='accuracy')\n",
    "\n",
    "# Fit the random search model\n",
    "dt_random.fit(messages_tfidf,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_random.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3 = open('dt_hre_29_08.pkl', 'wb')\n",
    "\n",
    "pickle.dump(dt_random.cv_results_, output3)\n",
    "\n",
    "output3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "gammas = [ 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "\n",
    "kernel = ['rbf', 'linear']\n",
    "\n",
    "param_grid = {'C': Cs, 'gamma' : gammas, 'kernel': kernel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.001, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(random_state = 42)\n",
    "scoring = {'accuracy':'accuracy','precision':'precision', 'f1':'f1', 'recall':'recall'}\n",
    "grid_search = GridSearchCV(svm, param_grid, scoring=scoring, cv=5, pre_dispatch=8)\n",
    "grid_search.fit(messages_tfidf,y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "output4 = open('svm_hre_29_08.pkl', 'wb')\n",
    "\n",
    "pickle.dump(grid_search.cv_results_, output4)\n",
    "\n",
    "output4.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
